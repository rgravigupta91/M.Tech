{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17c24672-6676-4233-b499-a4c0e909d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20282d-08da-46d4-84ce-5929cd3a6fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosenblat's Perceptron included a way to adjust the weights and find the appropriate combinations to overcome the need to modify thresholds\n",
    "# for each gate seperately, it used a bias term using which the tresholds in the neuron can be modified to implement multiple boolean functions\n",
    "# in one code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8dc4f06b-1994-4186-bee6-504ab4e1f74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24787614 0.7661357  0.33355738]\n",
      "[0 0 1]: 33.233557377076856 -> 0\n",
      "[0 1 1]: 66.89969307996412 -> 0\n",
      "[1 0 1]: 66.38143351264566 -> 0\n",
      "[1 1 1]: 100.04756921553292 -> 1\n",
      "[33.14787614 33.6661357  33.23355738]\n"
     ]
    }
   ],
   "source": [
    "step_function = lambda x: 0 if x < 100 else 1         # step function with threshold of 100. Any thing below is 0\n",
    "\n",
    "# AND Gate\n",
    "training_data = [\n",
    "    (np.array([0, 0, 1]), 0),\n",
    "    (np.array([0, 1, 1]), 0),\n",
    "    (np.array([1, 0, 1]), 0),\n",
    "    (np.array([1, 1, 1]), 1),\n",
    "]\n",
    "\n",
    "w = np.random.rand(3)\n",
    "print(w)\n",
    "\n",
    "errors = []\n",
    "eta = 0.1\n",
    "n = 10000\n",
    "\n",
    "for i in range(n):\n",
    "    x, expected = random.choice(training_data)\n",
    "\n",
    "    result = np.dot(w, x)\n",
    "    error = expected - step_function(result) # irrespective of what threshold we set, the algo will find the approp weights\n",
    "    errors.append(error)                     # that is the beauty of bias. The 'AND' pattern is learnt from data\n",
    "    w += eta * error * x\n",
    "\n",
    "\n",
    "for x, _ in training_data:\n",
    "    result = np.dot(w, x)\n",
    "    print(\"{}: {} -> {}\".format(x, result, step_function(result)))\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5ed53066-315e-4538-b76d-a803b08ef203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82880545 0.40301511 0.78088618]\n",
      "[0 0 1]: 61.980886179132376 -> 0\n",
      "[0 1 1]: 100.6839012888509 -> 1\n",
      "[1 0 1]: 100.10969162497213 -> 1\n",
      "[1 1 1]: 138.81270673469064 -> 1\n",
      "[38.12880545 38.70301511 61.98088618]\n"
     ]
    }
   ],
   "source": [
    "step_function = lambda x: 0 if x < 100 else 1         # step function with threshold of 100. Any thing below is 0\n",
    "\n",
    "# OR Gate\n",
    "training_data = [\n",
    "    (np.array([0, 0, 1]), 0),\n",
    "    (np.array([0, 1, 1]), 1),\n",
    "    (np.array([1, 0, 1]), 1),\n",
    "    (np.array([1, 1, 1]), 1),\n",
    "]\n",
    "\n",
    "w = np.random.rand(3)\n",
    "print(w)\n",
    "\n",
    "errors = []\n",
    "eta = 0.1\n",
    "n = 10000\n",
    "\n",
    "for i in range(n):\n",
    "    x, expected = random.choice(training_data)\n",
    "\n",
    "    result = np.dot(w, x)\n",
    "    error = expected - step_function(result) # irrespective of what threshold we set, the algo will find the approp weights\n",
    "    errors.append(error)                     # that is the beauty of bias. The 'AND' pattern is learnt from data\n",
    "    w += eta * error * x\n",
    "\n",
    "\n",
    "for x, _ in training_data:\n",
    "    result = np.dot(w, x)\n",
    "    print(\"{}: {} -> {}\".format(x, result, step_function(result)))\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01c5e004-ccb7-4c9e-a471-b4425ad41e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9673341  0.19305423 0.84086284]\n",
      "[0 0 1]: 99.84086283680469 -> 0\n",
      "[0 1 1]: 99.833917066734 -> 0\n",
      "[1 0 1]: 99.80819693438204 -> 0\n",
      "[1 1 1]: 99.80125116431137 -> 0\n",
      "[-3.26659024e-02 -6.94577007e-03  9.98408628e+01]\n"
     ]
    }
   ],
   "source": [
    "step_function = lambda x: 0 if x < 100 else 0 if x > 200 else 1         # step function with threshold of 100. Any thing below is 0\n",
    "\n",
    "# XOR Gate\n",
    "training_data = [\n",
    "    (np.array([0, 0, 1]), 0),\n",
    "    (np.array([0, 1, 1]), 1),\n",
    "    (np.array([1, 0, 1]), 1),\n",
    "    (np.array([1, 1, 1]), 0),\n",
    "]\n",
    "\n",
    "w = np.random.rand(3)\n",
    "print(w)\n",
    "\n",
    "errors = []\n",
    "eta = 0.1\n",
    "n = 10000\n",
    "\n",
    "for i in range(n):\n",
    "    x, expected = random.choice(training_data)\n",
    "\n",
    "    result = np.dot(w, x)\n",
    "    error = expected - step_function(result) # irrespective of what threshold we set, the algo will find the approp weights\n",
    "    errors.append(error)                     # that is the beauty of bias. The 'AND' pattern is learnt from data\n",
    "    w += eta * error * x\n",
    "\n",
    "\n",
    "for x, _ in training_data:\n",
    "    result = np.dot(w, x)\n",
    "    print(\"{}: {} -> {}\".format(x, result, step_function(result)))\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "06667d6a-e388-4b3d-8d47-14eb4e0b2627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_function(201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a43fb8-b8e7-4ed0-afcb-d0ea5e9bf9da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
