{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"WtPKZPpFxD6g"},"source":["# Objective\n","\n","Build a model to automatically predict tags for a given a StackExchange question by using the text of the question.\n","![alt text](https://cdn.sstatic.net/Sites/stackoverflow/company/img/logos/se/se-logo.svg?v=d29f0785ebb7)\n","\n","__Dataset Specs__: Over 85,000 questions\n","\n","[Download Link](https://www.kaggle.com/stackoverflow/statsquestions#Questions.csv)\n","\n","__License__\n","\n","All Stack Exchange user contributions are licensed under [CC-BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0/) with [attribution required](http://blog.stackoverflow.com/2009/06/attribution-required/).\n","\n","<br>\n","\n","***"]},{"cell_type":"code","metadata":{"id":"L_axH7-PrUFT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9f2b26cc-6e1d-409f-fbfd-b1a4f0aa493b","executionInfo":{"status":"ok","timestamp":1713499765999,"user_tz":-330,"elapsed":30134,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# mount Google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"HfaOlnHpy-Va"},"source":["# Steps to Follow\n","\n","\n","\n","1. Load Data and Import Libraries\n","2. Text Cleaning\n","3. Merge Tags with Questions\n","4. Dataset Preparation\n","5. Text Representation\n","6. Model Building\n","    1. Define Model Architecture\n","    2. Train the Model\n","7. Model Predictions\n","8. Model Evaluation\n","\n"]},{"cell_type":"markdown","metadata":{"id":"uVFrjcv4H_pa"},"source":["# Load Data and Import Libraries"]},{"cell_type":"code","metadata":{"id":"gitKl0VQbmBN","executionInfo":{"status":"ok","timestamp":1713499833416,"user_tz":-330,"elapsed":955,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# for string matching\n","import re\n","\n","# for reading data\n","import pandas as pd\n","\n","# for handling html data\n","from bs4 import BeautifulSoup\n","# Numpy\n","import numpy as np\n","# for visualization\n","import matplotlib.pyplot as plt\n","\n","pd.set_option('display.max_colwidth', 200)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"AhQkcqvqMVeK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7ac5ccb3-115f-42a9-bec3-a26e999172f0","executionInfo":{"status":"ok","timestamp":1713499880946,"user_tz":-330,"elapsed":9338,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# extract data from the ZIP file\n","!unzip '/content/drive/MyDrive/CNN_RNN_SIT/RNN_LSTM_GRU_Data.zip'"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/CNN_RNN_SIT/RNN_LSTM_GRU_Data.zip\n","  inflating: Answers.csv             \n","  inflating: Questions.csv           \n","  inflating: Tags.csv                \n","  inflating: database.sqlite         \n"]}]},{"cell_type":"code","metadata":{"id":"qLXg0bRfclmw","executionInfo":{"status":"ok","timestamp":1713499925093,"user_tz":-330,"elapsed":2511,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# load the stackoverflow questions dataset\n","questions_df = pd.read_csv('Questions.csv',encoding='latin-1')\n","\n","# load the tags dataset\n","tags_df = pd.read_csv('Tags.csv')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"YIcoG3xVZiOs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c540a45a-d477-45f2-cf87-d27396dc3e59","executionInfo":{"status":"ok","timestamp":1713499930185,"user_tz":-330,"elapsed":555,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["questions_df.shape, tags_df.shape"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((85085, 6), (244228, 2))"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"ZIXWgYbPaswH","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"b71160e5-d041-421e-dc1f-e0680bda181b","executionInfo":{"status":"ok","timestamp":1713499957522,"user_tz":-330,"elapsed":355,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["tags_df.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Id            Tag\n","0   1       bayesian\n","1   1          prior\n","2   1    elicitation\n","3   2  distributions\n","4   2      normality"],"text/html":["\n","  <div id=\"df-3fdd7d63-3531-460a-a91f-81dc3fd2d5db\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>bayesian</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>prior</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>elicitation</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>distributions</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>normality</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fdd7d63-3531-460a-a91f-81dc3fd2d5db')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3fdd7d63-3531-460a-a91f-81dc3fd2d5db button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3fdd7d63-3531-460a-a91f-81dc3fd2d5db');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-888b8d5f-5b2c-4e5b-a4f1-052382ad6789\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-888b8d5f-5b2c-4e5b-a4f1-052382ad6789')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-888b8d5f-5b2c-4e5b-a4f1-052382ad6789 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"tags_df"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"9w-hQccRCMgY"},"source":["### Data Dictionary\n","\n","1. Id: Question ID\n","2. OwnerUserId: User ID\n","3. CreationDate: Date of posting question\n","4. Score: Count of Upvotes received by the question\n","5. Title: Title of the question\n","6. Body: Text body of the question"]},{"cell_type":"code","metadata":{"id":"8pxycLMRKvO4","outputId":"59771aca-1351-478d-af5f-400820e2e8f4","colab":{"base_uri":"https://localhost:8080/","height":362},"executionInfo":{"status":"ok","timestamp":1713500032512,"user_tz":-330,"elapsed":1652,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["#print first 5 rows\n","questions_df.head()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Id  OwnerUserId          CreationDate  Score  \\\n","0   6          5.0  2010-07-19T19:14:44Z    272   \n","1  21         59.0  2010-07-19T19:24:36Z      4   \n","2  22         66.0  2010-07-19T19:25:39Z    208   \n","3  31         13.0  2010-07-19T19:28:44Z    138   \n","4  36          8.0  2010-07-19T19:31:47Z     58   \n","\n","                                                                Title  \\\n","0                  The Two Cultures: statistics vs. machine learning?   \n","1                                      Forecasting demographic census   \n","2                 Bayesian and frequentist reasoning in plain English   \n","3  What is the meaning of p values and t values in statistical tests?   \n","4          Examples for teaching: Correlation does not mean causation   \n","\n","                                                                                                                                                                                                      Body  \n","0  <p>Last year, I read a blog post from <a href=\"http://anyall.org/\">Brendan O'Connor</a> entitled <a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\">\"Statistics vs. Mach...  \n","1  <p>What are some of the ways to forecast demographic census with some validation and calibration techniques?</p>\\n\\n<p>Some of the concerns:</p>\\n\\n<ul>\\n<li>Census blocks vary in sizes as rural\\n...  \n","2                                                                               <p>How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?</p>\\n  \n","3  <p>After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....  \n","4  <p>There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:</p>\\n\\n<ol>\\n<li>number of storks and birth ...  "],"text/html":["\n","  <div id=\"df-fcdfde5f-4d97-40a3-8e7d-90df1ff60264\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>OwnerUserId</th>\n","      <th>CreationDate</th>\n","      <th>Score</th>\n","      <th>Title</th>\n","      <th>Body</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>5.0</td>\n","      <td>2010-07-19T19:14:44Z</td>\n","      <td>272</td>\n","      <td>The Two Cultures: statistics vs. machine learning?</td>\n","      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=\"http://anyall.org/\"&gt;Brendan O'Connor&lt;/a&gt; entitled &lt;a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\"&gt;\"Statistics vs. Mach...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>21</td>\n","      <td>59.0</td>\n","      <td>2010-07-19T19:24:36Z</td>\n","      <td>4</td>\n","      <td>Forecasting demographic census</td>\n","      <td>&lt;p&gt;What are some of the ways to forecast demographic census with some validation and calibration techniques?&lt;/p&gt;\\n\\n&lt;p&gt;Some of the concerns:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Census blocks vary in sizes as rural\\n...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>22</td>\n","      <td>66.0</td>\n","      <td>2010-07-19T19:25:39Z</td>\n","      <td>208</td>\n","      <td>Bayesian and frequentist reasoning in plain English</td>\n","      <td>&lt;p&gt;How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?&lt;/p&gt;\\n</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>31</td>\n","      <td>13.0</td>\n","      <td>2010-07-19T19:28:44Z</td>\n","      <td>138</td>\n","      <td>What is the meaning of p values and t values in statistical tests?</td>\n","      <td>&lt;p&gt;After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>36</td>\n","      <td>8.0</td>\n","      <td>2010-07-19T19:31:47Z</td>\n","      <td>58</td>\n","      <td>Examples for teaching: Correlation does not mean causation</td>\n","      <td>&lt;p&gt;There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;number of storks and birth ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcdfde5f-4d97-40a3-8e7d-90df1ff60264')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fcdfde5f-4d97-40a3-8e7d-90df1ff60264 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fcdfde5f-4d97-40a3-8e7d-90df1ff60264');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-baec1f84-acc6-42df-b01b-38af99753508\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-baec1f84-acc6-42df-b01b-38af99753508')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-baec1f84-acc6-42df-b01b-38af99753508 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"questions_df","summary":"{\n  \"name\": \"questions_df\",\n  \"rows\": 85085,\n  \"fields\": [\n    {\n      \"column\": \"Id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 70656,\n        \"min\": 1,\n        \"max\": 241481,\n        \"num_unique_values\": 85085,\n        \"samples\": [\n          182860,\n          113691,\n          11232\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OwnerUserId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 38425.57404103773,\n        \"min\": 5.0,\n        \"max\": 135593.0,\n        \"num_unique_values\": 38738,\n        \"samples\": [\n          108040.0,\n          48591.0,\n          31240.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CreationDate\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 85058,\n        \"samples\": [\n          \"2016-10-04T16:18:43Z\",\n          \"2013-12-08T19:46:47Z\",\n          \"2016-08-29T00:43:05Z\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": -13,\n        \"max\": 435,\n        \"num_unique_values\": 141,\n        \"samples\": [\n          116,\n          118,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85047,\n        \"samples\": [\n          \"Prediction using epsilon-Support Vector Regression\",\n          \"R: product of dummy variables when using factor in a linear regression\",\n          \"A question on Monte Carlo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85076,\n        \"samples\": [\n          \"<p>I've read a paper where they compute an $F$-test for the hypothesis that the autocorrelations of two groups are equal. Specifically, they estimate the autocorrelations of two time series $x_t$ and $y_t$ via OLS:\\n$$y_t = a_1 + b_1y_{t-1} + e_t$$\\n$$x_t = a_2 + b_2x_{t-1} + e_t$$</p>\\n\\n<p>Now they test the null hypothesis that $b_1 = b_2$ with an $F$-test. My question is, how can I do that, and which particular test statistic do I have to use?</p>\\n\\n<p>Best regards,<br>\\nChristian</p>\\n\",\n          \"<p>I have been attempting to do an ARIMA modelling in SAS. The series is not stationary but when I estimate the ACF and PACF p-values I don't get appropriate answers to find out if my model is adequate or not.Can anyone help me as may be I have been choosing the wrong p and q values. year age-group members.For stationarity I have used Sas which shows me that series is stationary with constant mean and variance.<img src=\\\"http://i.stack.imgur.com/GwpIk.png\\\" alt=\\\" model showing Stationary series for members\\\"></p>\\n\\n<p>year    age-group   members</p>\\n\\n<p>1997    16to21      21.1</p>\\n\\n<p>1997    22to29      47.5</p>\\n\\n<p>1997    30to39      61.7</p>\\n\\n<p>1997    40to49      65.1</p>\\n\\n<p>1997    50to54      64.1</p>\\n\\n<p>1997    55to59      58.7</p>\\n\\n<p>1997    60to64      48.2</p>\\n\\n<p>1997    65ANDOVER   12.2</p>\\n\\n<p>1998    16to21      18.6</p>\\n\\n<p>1998    22to29      46.3</p>\\n\\n<p>1998    30to39      61.1</p>\\n\\n<p>1998    40to49      65.4</p>\\n\\n<p>1998    50to54      64</p>\\n\\n<p>1998    55to59      59</p>\\n\\n<p>1998    60to64      45.4</p>\\n\\n<p>1998    65ANDOVER   12.5</p>\\n\\n<p>1999    16to21      19.6</p>\\n\\n<p>1999    22to29      47.3</p>\\n\\n<p>1999    30to39      61.6</p>\\n\\n<p>1999    40to49      65.8</p>\\n\\n<p>1999    50to54      64.8</p>\\n\\n<p>1999    55to59      58.5</p>\\n\\n<p>1999    60to64      45.2</p>\\n\\n<p>1999    65ANDOVER   10.1</p>\\n\\n<p>2000    16to21      20.9</p>\\n\\n<p>2000    22to29      47.6</p>\\n\\n<p>2000    30to39      61.5</p>\\n\\n<p>2000    40to49      65.8</p>\\n\\n<p>2000    50to54      64.6</p>\\n\\n<p>2000    55to59      58.8</p>\\n\\n<p>2000    60to64      44</p>\\n\\n<p>2000    65ANDOVER   10.7</p>\\n\\n<p>2001    16to21      20.7</p>\\n\\n<p>2001    22to29      47.1</p>\\n\\n<p>2001    30to39      61.7</p>\\n\\n<p>2001    40to49      65.7</p>\\n\\n<p>2001    50to54      64.5</p>\\n\\n<p>2001    55to59      59.2</p>\\n\\n<p>2001    60to64      42.6</p>\\n\\n<p>2001    65ANDOVER   11.7</p>\\n\\n<p>2002    16to21      19.4</p>\\n\\n<p>2002    22to29      49.2</p>\\n\\n<p>2002    30to39      62.8</p>\\n\\n<p>2002    40to49      67.1</p>\\n\\n<p>2002    50to54      65.8</p>\\n\\n<p>2002    55to59      61.2 </p>\\n\\n<p>2002    60to64      45.2</p>\\n\\n<p>2002    65ANDOVER   10.1</p>\\n\\n<p>2003    16to21      17.3</p>\\n\\n<p>2003    22to29      45.2</p>\\n\\n<p>2003    30to39      59.7</p>\\n\\n<p>2003    40to49      65.1</p>\\n\\n<p>2003    50to54      64.9</p>\\n\\n<p>2003    55to59      59.1</p>\\n\\n<p>2003    60to64      44.5</p>\\n\\n<p>2003    65ANDOVER   10.7</p>\\n\\n<p>2004    16to21      14.1</p>\\n\\n<p>2004    22to29      44</p>\\n\\n<p>2004    30to39      60.5</p>\\n\\n<p>2004    40to49      66.2</p>\\n\\n<p>2004    50to54      66.3</p>\\n\\n<p>2004    55to59      61.4</p>\\n\\n<p>2004    60to64      45.9</p>\\n\\n<p>2004    65ANDOVER   12.1</p>\\n\\n<p>2005    16to21      11.4</p>\\n\\n<p>2005    22to29      38.7</p>\\n\\n<p>2005    30to39      56.1</p>\\n\\n<p>2005    40to49      62.3</p>\\n\\n<p>2005    50to54      63.2</p>\\n\\n<p>2005    55to59      58</p>\\n\\n<p>2005    60to64      42.7</p>\\n\\n<p>2005    65ANDOVER   6.8</p>\\n\\n<p>2006    16to21      11.7</p>\\n\\n<p>2006    22to29      38.1</p>\\n\\n<p>2006    30to39      56</p>\\n\\n<p>2006    40to49      62.1</p>\\n\\n<p>2006    50to54      62.8</p>\\n\\n<p>2006    55to59      58.8</p>\\n\\n<p>2006    60to64      44.7</p>\\n\\n<p>2006    65ANDOVER   10</p>\\n\\n<p>2007    16to21      11.4</p>\\n\\n<p>2007    22to29      36.9</p>\\n\\n<p>2007    30to39      54.8</p>\\n\\n<p>2007    40to49      60.7</p>\\n\\n<p>2007    50to54      62.3</p>\\n\\n<p>2007    55to59      58.7</p>\\n\\n<p>2007    60to64      45.1</p>\\n\\n<p>2007    65ANDOVER   10.9\\n2008    16to21      9.2</p>\\n\\n<p>2008    22to29      34.8</p>\\n\\n<p>2008    30to39      53.6</p>\\n\\n<p>2008    40to49      60</p>\\n\\n<p>2008    50to54      62.9</p>\\n\\n<p>2008    55to59      59</p>\\n\\n<p>2008    60to64      45.4</p>\\n\\n<p>2008    65ANDOVER   12.3</p>\\n\\n<p>2009    16to21      9.6</p>\\n\\n<p>2009    22to29      35.4</p>\\n\\n<p>2009    30to39      53.2</p>\\n\\n<p>2009    40to49      60.3</p>\\n\\n<p>2009    50to54      62.4</p>\\n\\n<p>2009    55to59      59.7</p>\\n\\n<p>2009    60to64      46.3</p>\\n\\n<p>2009    65ANDOVER   12.5</p>\\n\\n<p>2010    16to21      9.1</p>\\n\\n<p>2010    22to29      34.1</p>\\n\\n<p>2010    30to39      52.6</p>\\n\\n<p>2010    40to49      59.6</p>\\n\\n<p>2010    50to54      62</p>\\n\\n<p>2010    55to59      59.2</p>\\n\\n<p>2010    60to64      46.3</p>\\n\\n<p>2010    65ANDOVER   13.9</p>\\n\\n<p>2011    16to21      7.7</p>\\n\\n<p>2011    22to29      31.8</p>\\n\\n<p>2011    30to39      50.7</p>\\n\\n<p>2011    40to49      57.9</p>\\n\\n<p>2011    50to54      60.1</p>\\n\\n<p>2011    55to59      57.3</p>\\n\\n<p>2011    60to64      45</p>\\n\\n<p>2011    65ANDOVER   14.6</p>\\n\\n<p>2012    16to21      6.5</p>\\n\\n<p>2012    22to29      30.2</p>\\n\\n<p>2012    30to39      49.1</p>\\n\\n<p>2012    40to49      56.1</p>\\n\\n<p>2012    50to54      58.2</p>\\n\\n<p>2012    55to59      55.5</p>\\n\\n<p>2012    60to64      43.9</p>\\n\\n<p>2012    65ANDOVER   14.8</p>\\n\",\n          \"<p>I'm trying to make my results more intuitive, and so I want to compare the predicted values at the interquartile range. I'm trying to figure out how to get the predicted value for a given variable, keeping everything else at the median.</p>\\n\\n<p>I've tried something like this:</p>\\n\\n<pre><code>x_1 &lt;- rnorm(20)\\nx_2 &lt;- rnorm(20)\\ny &lt;- x_1 + x_2 + rnorm(20)\\nz &lt;- data.frame(y,x_1,x_2)\\nfit &lt;- lm(y~x_1 + x_2,data = z)\\npredict(fit,newdata = data.frame(x_1=c(quantile(x_1)[2],quantile(x_1)[4]), x_2=median(x_2)))\\n</code></pre>\\n\\n<p>which works, but my actual model has 10+ variables, and this starts to get ugly really quickly, so I figure there must be a better way?</p>\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"siBpKFe3IZNw"},"source":["# Text Cleaning"]},{"cell_type":"markdown","metadata":{"id":"hmeuzAF9Ic1d"},"source":["Let's define a function to clean the text data."]},{"cell_type":"code","metadata":{"id":"ADh9l-RWNSDU","executionInfo":{"status":"ok","timestamp":1713500253672,"user_tz":-330,"elapsed":376,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["def cleaner(text):\n","\n","  # take off html tags and links\n","  text = BeautifulSoup(text).get_text()\n","\n","  # fetch alphabetic characters\n","  text = re.sub(\"[^a-zA-Z]\", \" \", text)\n","\n","  # convert text to lower case\n","  text = text.lower()\n","\n","  # split text into tokens to remove whitespaces\n","  tokens = text.split()\n","\n","  return \" \".join(tokens)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"o98nUFycNSB-","executionInfo":{"status":"ok","timestamp":1713500303325,"user_tz":-330,"elapsed":46526,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# call preprocessing function\n","questions_df['cleaned_text'] = questions_df['Body'].apply(cleaner)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"umvS_4ZQNR6r","outputId":"48f53865-6ce7-4e93-f372-c7490088f5ac","colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"status":"ok","timestamp":1713500315858,"user_tz":-330,"elapsed":369,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["questions_df['Body'][1]"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"<p>What are some of the ways to forecast demographic census with some validation and calibration techniques?</p>\\n\\n<p>Some of the concerns:</p>\\n\\n<ul>\\n<li>Census blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?</li>\\n<li>if let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far can i forecast it into the\\nfuture?</li>\\n<li>if some of the census zone change\\nlightly in boundaries, how can i\\naccount for that change?</li>\\n<li>What are the methods to validate\\ncensus forecasts? for example, if i\\nhave data for existing 5 census\\nperiods, should I model the first 3\\nand test it on the latter two? or is\\nthere another way?</li>\\n<li>what's the state of practice in\\nforecasting census data, and what are\\nsome of the state of the art methods?</li>\\n</ul>\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"FoEZ0aQ7KvN2","outputId":"b7e6ea73-b6c8-4f30-f420-715b69fb92c4","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1713500320836,"user_tz":-330,"elapsed":350,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["questions_df['cleaned_text'][1]"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'what are some of the ways to forecast demographic census with some validation and calibration techniques some of the concerns census blocks vary in sizes as rural areas are a lot larger than condensed urban areas is there a need to account for the area size difference if let s say i have census data dating back to census periods how far can i forecast it into the future if some of the census zone change lightly in boundaries how can i account for that change what are the methods to validate census forecasts for example if i have data for existing census periods should i model the first and test it on the latter two or is there another way what s the state of practice in forecasting census data and what are some of the state of the art methods'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"J9b6nqIcZ0Gz"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uw5lSAb7Z0BV"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-zpMQEKhZz9T"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4UffwIVlZzv0"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dTPISO70LOM4"},"source":["# Merge Tags with Questions"]},{"cell_type":"markdown","metadata":{"id":"jTXwGw2xKhWk"},"source":["Let's now explore the tags data."]},{"cell_type":"code","metadata":{"id":"4p9JAFA9tTxO","outputId":"54319ffd-62fe-47d7-b836-b2601c50f854","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1713500338822,"user_tz":-330,"elapsed":361,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["tags_df.head()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Id            Tag\n","0   1       bayesian\n","1   1          prior\n","2   1    elicitation\n","3   2  distributions\n","4   2      normality"],"text/html":["\n","  <div id=\"df-c7aebe20-6b99-4eb5-98f0-26bd087cb2a3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>bayesian</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>prior</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>elicitation</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>distributions</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>normality</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7aebe20-6b99-4eb5-98f0-26bd087cb2a3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c7aebe20-6b99-4eb5-98f0-26bd087cb2a3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c7aebe20-6b99-4eb5-98f0-26bd087cb2a3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ccd0aed8-d5ba-4ed0-a39d-bcebee63c210\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ccd0aed8-d5ba-4ed0-a39d-bcebee63c210')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ccd0aed8-d5ba-4ed0-a39d-bcebee63c210 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"tags_df"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"rVGubRcWe01J","outputId":"27aeec86-179b-4177-f1db-0d9ae003eb30","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713500363420,"user_tz":-330,"elapsed":357,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# count of unique tags\n","len(tags_df['Tag'].unique())"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1315"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"ZqW5nBknesV-","outputId":"42c36457-3e27-4854-ab34-f6e2204bea76","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713500369405,"user_tz":-330,"elapsed":354,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["tags_df['Tag'].value_counts()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tag\n","r                       13236\n","regression              10959\n","machine-learning         6089\n","time-series              5559\n","probability              4217\n","                        ...  \n","fmincon                     1\n","doc2vec                     1\n","sympy                       1\n","adversarial-boosting        1\n","corpus-linguistics          1\n","Name: count, Length: 1315, dtype: int64"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"3SEjB4OwiJ0b","executionInfo":{"status":"ok","timestamp":1713500411333,"user_tz":-330,"elapsed":372,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# remove \"-\" from the tags\n","tags_df['Tag']= tags_df['Tag'].apply(lambda x:re.sub(\"-\",\" \",x))"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"MhPvTj6ytcW0","outputId":"50eec5e7-9653-4849-ebe9-32f2e0b3eac9","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1713500453483,"user_tz":-330,"elapsed":4792,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# group tags Id wise mix the tags\n","tags_df = tags_df.groupby('Id').apply(lambda x:x['Tag'].values).reset_index(name='tags')\n","tags_df.head()"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Id                                       tags\n","0   1             [bayesian, prior, elicitation]\n","1   2                 [distributions, normality]\n","2   3                    [software, open source]\n","3   4  [distributions, statistical significance]\n","4   6                         [machine learning]"],"text/html":["\n","  <div id=\"df-2b7f300b-19e4-475f-9140-bc1cb36b6342\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>[bayesian, prior, elicitation]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>[distributions, normality]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>[software, open source]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>[distributions, statistical significance]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6</td>\n","      <td>[machine learning]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b7f300b-19e4-475f-9140-bc1cb36b6342')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2b7f300b-19e4-475f-9140-bc1cb36b6342 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2b7f300b-19e4-475f-9140-bc1cb36b6342');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-21d202bd-7f7c-48d1-a3c8-c967cb726639\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-21d202bd-7f7c-48d1-a3c8-c967cb726639')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-21d202bd-7f7c-48d1-a3c8-c967cb726639 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"tags_df","summary":"{\n  \"name\": \"tags_df\",\n  \"rows\": 85085,\n  \"fields\": [\n    {\n      \"column\": \"Id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 70656,\n        \"min\": 1,\n        \"max\": 241481,\n        \"num_unique_values\": 85085,\n        \"samples\": [\n          113857,\n          89143,\n          105783\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"zCnEKm1ouTnm","executionInfo":{"status":"ok","timestamp":1713500488310,"user_tz":-330,"elapsed":611,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# merge tags and questions\n","df = pd.merge(questions_df,tags_df,how='inner',on='Id')"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"fn37BQ5TusSt","outputId":"d08f84e3-59b0-42f0-ea77-17a7e363d330","colab":{"base_uri":"https://localhost:8080/","height":449},"executionInfo":{"status":"ok","timestamp":1713500496212,"user_tz":-330,"elapsed":1895,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["df = df[['Id','Body','cleaned_text','tags']]\n","df.head()"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Id  \\\n","0   6   \n","1  21   \n","2  22   \n","3  31   \n","4  36   \n","\n","                                                                                                                                                                                                      Body  \\\n","0  <p>Last year, I read a blog post from <a href=\"http://anyall.org/\">Brendan O'Connor</a> entitled <a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\">\"Statistics vs. Mach...   \n","1  <p>What are some of the ways to forecast demographic census with some validation and calibration techniques?</p>\\n\\n<p>Some of the concerns:</p>\\n\\n<ul>\\n<li>Census blocks vary in sizes as rural\\n...   \n","2                                                                               <p>How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?</p>\\n   \n","3  <p>After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....   \n","4  <p>There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:</p>\\n\\n<ol>\\n<li>number of storks and birth ...   \n","\n","                                                                                                                                                                                              cleaned_text  \\\n","0  last year i read a blog post from brendan o connor entitled statistics vs machine learning fight that discussed some of the differences between the two fields andrew gelman responded favorably to ...   \n","1  what are some of the ways to forecast demographic census with some validation and calibration techniques some of the concerns census blocks vary in sizes as rural areas are a lot larger than conde...   \n","2                                                                                         how would you describe in plain english the characteristics that distinguish bayesian from frequentist reasoning   \n","3  after taking a statistics course and then trying to help fellow students i noticed one subject that inspires much head desk banging is interpreting the results of statistical hypothesis tests it s...   \n","4  there is an old saying correlation does not mean causation when i teach i tend to use the following standard examples to illustrate this point number of storks and birth rate in denmark number of ...   \n","\n","                                                               tags  \n","0                                                [machine learning]  \n","1                                 [forecasting, population, census]  \n","2                                           [bayesian, frequentist]  \n","3  [hypothesis testing, t test, p value, interpretation, intuition]  \n","4                                           [correlation, teaching]  "],"text/html":["\n","  <div id=\"df-6407685c-78a9-4713-807a-b82846e566e8\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Body</th>\n","      <th>cleaned_text</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=\"http://anyall.org/\"&gt;Brendan O'Connor&lt;/a&gt; entitled &lt;a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\"&gt;\"Statistics vs. Mach...</td>\n","      <td>last year i read a blog post from brendan o connor entitled statistics vs machine learning fight that discussed some of the differences between the two fields andrew gelman responded favorably to ...</td>\n","      <td>[machine learning]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>21</td>\n","      <td>&lt;p&gt;What are some of the ways to forecast demographic census with some validation and calibration techniques?&lt;/p&gt;\\n\\n&lt;p&gt;Some of the concerns:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Census blocks vary in sizes as rural\\n...</td>\n","      <td>what are some of the ways to forecast demographic census with some validation and calibration techniques some of the concerns census blocks vary in sizes as rural areas are a lot larger than conde...</td>\n","      <td>[forecasting, population, census]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>22</td>\n","      <td>&lt;p&gt;How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?&lt;/p&gt;\\n</td>\n","      <td>how would you describe in plain english the characteristics that distinguish bayesian from frequentist reasoning</td>\n","      <td>[bayesian, frequentist]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>31</td>\n","      <td>&lt;p&gt;After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....</td>\n","      <td>after taking a statistics course and then trying to help fellow students i noticed one subject that inspires much head desk banging is interpreting the results of statistical hypothesis tests it s...</td>\n","      <td>[hypothesis testing, t test, p value, interpretation, intuition]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>36</td>\n","      <td>&lt;p&gt;There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;number of storks and birth ...</td>\n","      <td>there is an old saying correlation does not mean causation when i teach i tend to use the following standard examples to illustrate this point number of storks and birth rate in denmark number of ...</td>\n","      <td>[correlation, teaching]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6407685c-78a9-4713-807a-b82846e566e8')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6407685c-78a9-4713-807a-b82846e566e8 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6407685c-78a9-4713-807a-b82846e566e8');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5fffa5f3-a1ac-409f-9611-5a55e7e2b5fe\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5fffa5f3-a1ac-409f-9611-5a55e7e2b5fe')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5fffa5f3-a1ac-409f-9611-5a55e7e2b5fe button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 85085,\n  \"fields\": [\n    {\n      \"column\": \"Id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 70656,\n        \"min\": 1,\n        \"max\": 241481,\n        \"num_unique_values\": 85085,\n        \"samples\": [\n          182860,\n          113691,\n          11232\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85076,\n        \"samples\": [\n          \"<p>I've read a paper where they compute an $F$-test for the hypothesis that the autocorrelations of two groups are equal. Specifically, they estimate the autocorrelations of two time series $x_t$ and $y_t$ via OLS:\\n$$y_t = a_1 + b_1y_{t-1} + e_t$$\\n$$x_t = a_2 + b_2x_{t-1} + e_t$$</p>\\n\\n<p>Now they test the null hypothesis that $b_1 = b_2$ with an $F$-test. My question is, how can I do that, and which particular test statistic do I have to use?</p>\\n\\n<p>Best regards,<br>\\nChristian</p>\\n\",\n          \"<p>I have been attempting to do an ARIMA modelling in SAS. The series is not stationary but when I estimate the ACF and PACF p-values I don't get appropriate answers to find out if my model is adequate or not.Can anyone help me as may be I have been choosing the wrong p and q values. year age-group members.For stationarity I have used Sas which shows me that series is stationary with constant mean and variance.<img src=\\\"http://i.stack.imgur.com/GwpIk.png\\\" alt=\\\" model showing Stationary series for members\\\"></p>\\n\\n<p>year    age-group   members</p>\\n\\n<p>1997    16to21      21.1</p>\\n\\n<p>1997    22to29      47.5</p>\\n\\n<p>1997    30to39      61.7</p>\\n\\n<p>1997    40to49      65.1</p>\\n\\n<p>1997    50to54      64.1</p>\\n\\n<p>1997    55to59      58.7</p>\\n\\n<p>1997    60to64      48.2</p>\\n\\n<p>1997    65ANDOVER   12.2</p>\\n\\n<p>1998    16to21      18.6</p>\\n\\n<p>1998    22to29      46.3</p>\\n\\n<p>1998    30to39      61.1</p>\\n\\n<p>1998    40to49      65.4</p>\\n\\n<p>1998    50to54      64</p>\\n\\n<p>1998    55to59      59</p>\\n\\n<p>1998    60to64      45.4</p>\\n\\n<p>1998    65ANDOVER   12.5</p>\\n\\n<p>1999    16to21      19.6</p>\\n\\n<p>1999    22to29      47.3</p>\\n\\n<p>1999    30to39      61.6</p>\\n\\n<p>1999    40to49      65.8</p>\\n\\n<p>1999    50to54      64.8</p>\\n\\n<p>1999    55to59      58.5</p>\\n\\n<p>1999    60to64      45.2</p>\\n\\n<p>1999    65ANDOVER   10.1</p>\\n\\n<p>2000    16to21      20.9</p>\\n\\n<p>2000    22to29      47.6</p>\\n\\n<p>2000    30to39      61.5</p>\\n\\n<p>2000    40to49      65.8</p>\\n\\n<p>2000    50to54      64.6</p>\\n\\n<p>2000    55to59      58.8</p>\\n\\n<p>2000    60to64      44</p>\\n\\n<p>2000    65ANDOVER   10.7</p>\\n\\n<p>2001    16to21      20.7</p>\\n\\n<p>2001    22to29      47.1</p>\\n\\n<p>2001    30to39      61.7</p>\\n\\n<p>2001    40to49      65.7</p>\\n\\n<p>2001    50to54      64.5</p>\\n\\n<p>2001    55to59      59.2</p>\\n\\n<p>2001    60to64      42.6</p>\\n\\n<p>2001    65ANDOVER   11.7</p>\\n\\n<p>2002    16to21      19.4</p>\\n\\n<p>2002    22to29      49.2</p>\\n\\n<p>2002    30to39      62.8</p>\\n\\n<p>2002    40to49      67.1</p>\\n\\n<p>2002    50to54      65.8</p>\\n\\n<p>2002    55to59      61.2 </p>\\n\\n<p>2002    60to64      45.2</p>\\n\\n<p>2002    65ANDOVER   10.1</p>\\n\\n<p>2003    16to21      17.3</p>\\n\\n<p>2003    22to29      45.2</p>\\n\\n<p>2003    30to39      59.7</p>\\n\\n<p>2003    40to49      65.1</p>\\n\\n<p>2003    50to54      64.9</p>\\n\\n<p>2003    55to59      59.1</p>\\n\\n<p>2003    60to64      44.5</p>\\n\\n<p>2003    65ANDOVER   10.7</p>\\n\\n<p>2004    16to21      14.1</p>\\n\\n<p>2004    22to29      44</p>\\n\\n<p>2004    30to39      60.5</p>\\n\\n<p>2004    40to49      66.2</p>\\n\\n<p>2004    50to54      66.3</p>\\n\\n<p>2004    55to59      61.4</p>\\n\\n<p>2004    60to64      45.9</p>\\n\\n<p>2004    65ANDOVER   12.1</p>\\n\\n<p>2005    16to21      11.4</p>\\n\\n<p>2005    22to29      38.7</p>\\n\\n<p>2005    30to39      56.1</p>\\n\\n<p>2005    40to49      62.3</p>\\n\\n<p>2005    50to54      63.2</p>\\n\\n<p>2005    55to59      58</p>\\n\\n<p>2005    60to64      42.7</p>\\n\\n<p>2005    65ANDOVER   6.8</p>\\n\\n<p>2006    16to21      11.7</p>\\n\\n<p>2006    22to29      38.1</p>\\n\\n<p>2006    30to39      56</p>\\n\\n<p>2006    40to49      62.1</p>\\n\\n<p>2006    50to54      62.8</p>\\n\\n<p>2006    55to59      58.8</p>\\n\\n<p>2006    60to64      44.7</p>\\n\\n<p>2006    65ANDOVER   10</p>\\n\\n<p>2007    16to21      11.4</p>\\n\\n<p>2007    22to29      36.9</p>\\n\\n<p>2007    30to39      54.8</p>\\n\\n<p>2007    40to49      60.7</p>\\n\\n<p>2007    50to54      62.3</p>\\n\\n<p>2007    55to59      58.7</p>\\n\\n<p>2007    60to64      45.1</p>\\n\\n<p>2007    65ANDOVER   10.9\\n2008    16to21      9.2</p>\\n\\n<p>2008    22to29      34.8</p>\\n\\n<p>2008    30to39      53.6</p>\\n\\n<p>2008    40to49      60</p>\\n\\n<p>2008    50to54      62.9</p>\\n\\n<p>2008    55to59      59</p>\\n\\n<p>2008    60to64      45.4</p>\\n\\n<p>2008    65ANDOVER   12.3</p>\\n\\n<p>2009    16to21      9.6</p>\\n\\n<p>2009    22to29      35.4</p>\\n\\n<p>2009    30to39      53.2</p>\\n\\n<p>2009    40to49      60.3</p>\\n\\n<p>2009    50to54      62.4</p>\\n\\n<p>2009    55to59      59.7</p>\\n\\n<p>2009    60to64      46.3</p>\\n\\n<p>2009    65ANDOVER   12.5</p>\\n\\n<p>2010    16to21      9.1</p>\\n\\n<p>2010    22to29      34.1</p>\\n\\n<p>2010    30to39      52.6</p>\\n\\n<p>2010    40to49      59.6</p>\\n\\n<p>2010    50to54      62</p>\\n\\n<p>2010    55to59      59.2</p>\\n\\n<p>2010    60to64      46.3</p>\\n\\n<p>2010    65ANDOVER   13.9</p>\\n\\n<p>2011    16to21      7.7</p>\\n\\n<p>2011    22to29      31.8</p>\\n\\n<p>2011    30to39      50.7</p>\\n\\n<p>2011    40to49      57.9</p>\\n\\n<p>2011    50to54      60.1</p>\\n\\n<p>2011    55to59      57.3</p>\\n\\n<p>2011    60to64      45</p>\\n\\n<p>2011    65ANDOVER   14.6</p>\\n\\n<p>2012    16to21      6.5</p>\\n\\n<p>2012    22to29      30.2</p>\\n\\n<p>2012    30to39      49.1</p>\\n\\n<p>2012    40to49      56.1</p>\\n\\n<p>2012    50to54      58.2</p>\\n\\n<p>2012    55to59      55.5</p>\\n\\n<p>2012    60to64      43.9</p>\\n\\n<p>2012    65ANDOVER   14.8</p>\\n\",\n          \"<p>I'm trying to make my results more intuitive, and so I want to compare the predicted values at the interquartile range. I'm trying to figure out how to get the predicted value for a given variable, keeping everything else at the median.</p>\\n\\n<p>I've tried something like this:</p>\\n\\n<pre><code>x_1 &lt;- rnorm(20)\\nx_2 &lt;- rnorm(20)\\ny &lt;- x_1 + x_2 + rnorm(20)\\nz &lt;- data.frame(y,x_1,x_2)\\nfit &lt;- lm(y~x_1 + x_2,data = z)\\npredict(fit,newdata = data.frame(x_1=c(quantile(x_1)[2],quantile(x_1)[4]), x_2=median(x_2)))\\n</code></pre>\\n\\n<p>which works, but my actual model has 10+ variables, and this starts to get ugly really quickly, so I figure there must be a better way?</p>\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85062,\n        \"samples\": [\n          \"if i take some sequences of random numbers generated by a random number generator with uniform distribution will the resulting sequences be uniformly distributed as well by example if i have a generator that returns or what are the probabilities to get and\",\n          \"i have what is possible a naive question i am current comparing various models i e distributions and the comparisons do not involve different distributions but rather how the model is fed the data for example two models might be a mixture of a gamma exponential and a mixture of a gamma exponential wherein the minimum data point is subtracted with respect to model if i subtract the minimum data then i am left with a data point the model s fit fine and i get my mle values however if i am working with just a gamma and in one model i remove the minimum data point then that data point causes errors in the mle estimator to get past this issue i simply remove the data point and fit the distribution my question is is there a problem with simply removing the data point my worry is decreasing the size of my data set and should i do that for the gamma exponential as well thanks\",\n          \"i am doing a binary classification task and i am calculating the auc roc and the recall as follows recall metrics recall score y test y pred pos label none average macro auc roc auc score y test y pred and i always end up wit the exact same value for both recall auc i have no idea why this is happening any help\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"outputId":"5580f86c-25d0-4e8f-c366-411b9c0f62e0","id":"2cqkOjieMKBk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713500537572,"user_tz":-330,"elapsed":353,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["df.shape"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(85085, 4)"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"YV6KXBw1MRyY"},"source":["There are over 85,000 unique questions and over 1300 tags."]},{"cell_type":"code","metadata":{"id":"tqNmqGxtolzT"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xFgRNsPzolpH"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DIgC7iRUollQ"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i3kb1uk-olha"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PSHE0-PBolfN"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxGQGzA9olby"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c_22ook_MiRv"},"source":["# Dataset Preparation"]},{"cell_type":"code","metadata":{"id":"3uj_0l0jwL3f","executionInfo":{"status":"ok","timestamp":1713500566492,"user_tz":-330,"elapsed":389,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# check frequency of occurence of each tag\n","freq= {}\n","for i in df['tags']:\n","  for j in i:\n","    if j in freq.keys():\n","      freq[j] = freq[j] + 1\n","    else:\n","      freq[j] = 1"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CUDiameNNhPh"},"source":["Let's find out the most frequent tags."]},{"cell_type":"code","metadata":{"id":"WOzWyGfLzli9","executionInfo":{"status":"ok","timestamp":1713500571052,"user_tz":-330,"elapsed":353,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# sort the dictionary in descending order\n","freq = dict(sorted(freq.items(), key=lambda x:x[1],reverse=True))"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"vKcagvyi0Wfk","outputId":"997256f8-d1b2-43fc-976f-7cb893028b45","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713500576620,"user_tz":-330,"elapsed":434,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["freq.items()"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_items([('r', 13236), ('regression', 10959), ('machine learning', 6089), ('time series', 5559), ('probability', 4217), ('hypothesis testing', 3869), ('self study', 3732), ('distributions', 3501), ('logistic', 3316), ('classification', 2881), ('correlation', 2871), ('statistical significance', 2666), ('bayesian', 2656), ('anova', 2505), ('normal distribution', 2181), ('multiple regression', 2054), ('mixed model', 1998), ('clustering', 1952), ('neural networks', 1897), ('mathematical statistics', 1888), ('confidence interval', 1776), ('categorical data', 1703), ('generalized linear model', 1614), ('variance', 1576), ('data visualization', 1549), ('estimation', 1533), ('forecasting', 1422), ('t test', 1418), ('pca', 1395), ('sampling', 1363), ('cross validation', 1344), ('repeated measures', 1335), ('spss', 1296), ('svm', 1283), ('chi squared', 1261), ('maximum likelihood', 1209), ('predictive models', 1189), ('multivariate analysis', 1116), ('survival', 1081), ('references', 1076), ('data transformation', 1057), ('modeling', 1055), ('p value', 1040), ('feature selection', 997), ('econometrics', 989), ('panel data', 966), ('python', 955), ('data mining', 950), ('interaction', 946), ('matlab', 941), ('linear model', 937), ('binomial', 935), ('random forest', 935), ('nonparametric', 922), ('arima', 917), ('least squares', 898), ('optimization', 898), ('model selection', 876), ('standard deviation', 866), ('poisson', 865), ('interpretation', 860), ('sample size', 847), ('mean', 842), ('stata', 842), ('dataset', 840), ('conditional probability', 837), ('prediction', 832), ('multiple comparisons', 825), ('bootstrap', 814), ('experiment design', 780), ('random variable', 745), ('autocorrelation', 678), ('simulation', 676), ('covariance', 666), ('multilevel analysis', 663), ('pdf', 654), ('missing data', 652), ('expected value', 645), ('regression coefficients', 643), ('factor analysis', 642), ('mcmc', 635), ('outliers', 629), ('standard error', 629), ('inference', 625), ('ordinal', 624), ('survey', 617), ('deep learning', 600), ('cart', 593), ('residuals', 582), ('binary data', 570), ('random effects model', 569), ('goodness of fit', 567), ('model', 567), ('terminology', 551), ('stochastic processes', 530), ('nonlinear regression', 514), ('cox model', 510), ('monte carlo', 504), ('proportion', 503), ('algorithms', 500), ('sas', 496), ('lasso', 490), ('normalization', 484), ('heteroscedasticity', 483), ('error', 481), ('independence', 480), ('meta analysis', 480), ('multinomial', 480), ('k means', 465), ('lmer', 463), ('sample', 450), ('markov process', 445), ('scikit learn', 440), ('multicollinearity', 438), ('text mining', 432), ('aic', 431), ('descriptive statistics', 430), ('spatial', 429), ('assumptions', 418), ('matrix', 413), ('likelihood', 407), ('dimensionality reduction', 407), ('sem', 405), ('bias', 396), ('fixed effects model', 391), ('effect size', 375), ('logit', 374), ('r squared', 372), ('normality', 371), ('lme4', 371), ('convergence', 370), ('likert', 366), ('power analysis', 365), ('glmm', 359), ('negative binomial', 358), ('roc', 358), ('fitting', 357), ('computational statistics', 348), ('count data', 347), ('random generation', 345), ('prior', 340), ('summary statistics', 338), ('ranking', 338), ('stationarity', 337), ('natural language', 335), ('covariance matrix', 332), ('skewness', 325), ('kernel trick', 321), ('gamma distribution', 319), ('naive bayes', 318), ('continuous data', 317), ('regularization', 317), ('hidden markov model', 314), ('reliability', 314), ('power', 312), ('gaussian process', 310), ('group differences', 309), ('autoregressive', 307), ('biostatistics', 306), ('distance', 304), ('garch', 302), ('ancova', 300), ('causality', 300), ('standardization', 300), ('validation', 296), ('small sample', 295), ('exponential', 295), ('quantiles', 293), ('posterior', 291), ('var', 289), ('curve fitting', 288), ('post hoc', 284), ('kernel smoothing', 284), ('robust', 282), ('average', 277), ('gradient descent', 277), ('odds ratio', 275), ('lognormal', 275), ('median', 273), ('bayes', 273), ('seasonality', 270), ('expectation maximization', 270), ('uniform', 268), ('cointegration', 268), ('large data', 266), ('kolmogorov smirnov', 266), ('wilcoxon', 266), ('discrete data', 266), ('conv neural network', 264), ('gaussian mixture', 261), ('histogram', 260), ('non independent', 259), ('entropy', 259), ('pearson', 258), ('excel', 257), ('trend', 256), ('linear', 256), ('arma', 255), ('contingency tables', 253), ('joint distribution', 253), ('pattern recognition', 253), ('manova', 252), ('cdf', 250), ('scales', 248), ('unbalanced classes', 247), ('conditional expectation', 245), ('unbiased estimator', 245), ('mixture', 244), ('measurement error', 243), ('mann whitney u test', 242), ('boosting', 240), ('likelihood ratio', 238), ('data imputation', 238), ('hierarchical bayesian', 237), ('k nearest neighbour', 236), ('central limit theorem', 236), ('asymptotics', 236), ('discriminant analysis', 234), ('caret', 233), ('poisson regression', 233), ('unsupervised learning', 232), ('paired comparisons', 232), ('accuracy', 231), ('permutation', 231), ('graphical model', 231), ('psychometrics', 228), ('ridge regression', 228), ('instrumental variables', 227), ('image processing', 227), ('probit', 226), ('basic concepts', 226), ('similarities', 225), ('multiple imputation', 223), ('distance functions', 222), ('population', 219), ('overfitting', 217), ('predictor', 215), ('gibbs', 215), ('information theory', 212), ('recommender system', 206), ('feature construction', 206), ('estimators', 205), ('degrees of freedom', 205), ('glmnet', 202), ('jags', 201), ('finance', 200), ('gam', 199), ('epidemiology', 198), ('beta distribution', 198), ('proof', 198), ('moments', 198), ('notation', 196), ('linear algebra', 193), ('model comparison', 193), ('bayesian network', 192), ('nonlinear', 191), ('smoothing', 191), ('supervised learning', 191), ('approximation', 187), ('prediction interval', 185), ('cross correlation', 185), ('lme', 183), ('nested', 183), ('svd', 182), ('kalman filter', 180), ('fishers exact', 180), ('bernoulli distribution', 179), ('precision recall', 178), ('libsvm', 177), ('gee', 177), ('measurement', 177), ('latent variable', 177), ('loss functions', 176), ('contrasts', 176), ('zero inflation', 174), ('frequency', 174), ('splines', 173), ('logarithm', 172), ('t distribution', 172), ('auc', 172), ('censoring', 172), ('unit root', 172), ('resampling', 171), ('kruskal wallis', 170), ('intuition', 168), ('uncertainty', 165), ('order statistics', 165), ('hazard', 162), ('regression strategies', 162), ('mediation', 162), ('f test', 162), ('weka', 162), ('graph theory', 160), ('ensemble', 159), ('confirmatory factor', 157), ('definition', 156), ('glmer', 156), ('parametric', 155), ('copula', 155), ('combinatorics', 155), ('polynomial', 154), ('lm', 153), ('performance', 153), ('marginal', 153), ('software', 151), ('signal processing', 151), ('mutual information', 150), ('weighted regression', 150), ('propensity scores', 148), ('bonferroni', 148), ('multi class', 148), ('matching', 147), ('reinforcement learning', 145), ('diagnostic', 145), ('frequentist', 144), ('non stationary', 144), ('methodology', 142), ('genetics', 141), ('pymc', 141), ('dirichlet distribution', 140), ('bic', 139), ('stepwise regression', 139), ('metropolis hastings', 138), ('gbm', 138), ('analysis', 138), ('theory', 137), ('kullback leibler', 137), ('eigenvalues', 136), ('intraclass correlation', 135), ('inter rater', 134), ('paired data', 134), ('difference in difference', 133), ('metric', 132), ('hierarchical', 132), ('error propagation', 131), ('scatterplot', 131), ('multivariate regression', 131), ('interpolation', 130), ('quantile regression', 130), ('multidimensional scaling', 130), ('aggregation', 128), ('mse', 128), ('reporting', 128), ('hierarchical clustering', 128), ('weibull', 128), ('qq plot', 127), ('multivariate normal', 127), ('parameterization', 126), ('train', 126), ('change point', 125), ('irt', 124), ('matrix decomposition', 123), ('sparse', 123), ('topic models', 123), ('bioinformatics', 123), ('bivariate', 122), ('decision theory', 121), ('exponential smoothing', 121), ('lags', 120), ('backpropagation', 120), ('kurtosis', 120), ('poisson process', 119), ('state space models', 119), ('percentage', 119), ('randomization', 119), ('endogeneity', 118), ('ratio', 117), ('weighted mean', 116), ('z test', 116), ('eda', 116), ('spearman', 116), ('exponential family', 115), ('confidence', 115), ('nlme', 114), ('statistical learning', 114), ('probability inequalities', 114), ('false discovery rate', 113), ('networks', 112), ('convolution', 112), ('markov chain', 111), ('extreme value', 111), ('clinical trials', 110), ('autoencoders', 110), ('generalized least squares', 110), ('pls', 109), ('ecology', 109), ('boxplot', 109), ('hyperparameter', 109), ('sums of squares', 109), ('stratification', 109), ('learning', 108), ('teaching', 107), ('ab test', 107), ('conjugate prior', 106), ('sufficient statistics', 106), ('confounding', 106), ('consistency', 106), ('treatment effect', 105), ('ggplot2', 105), ('covariate', 104), ('bugs', 102), ('computer vision', 102), ('online', 100), ('coefficient', 99), ('randomness', 99), ('games', 98), ('granger causality', 98), ('weighted sampling', 98), ('kaplan meier', 97), ('high dimensional', 97), ('elastic net', 97), ('threshold', 96), ('sample mean', 94), ('lstm', 94), ('augmented dickey fuller', 94), ('fisher information', 94), ('rms', 93), ('pooling', 92), ('time varying covariate', 92), ('rpart', 92), ('spearman rho', 92), ('vecm', 92), ('hypergeometric', 92), ('moving average', 92), ('bounds', 92), ('maximum', 91), ('scores', 91), ('fourier transform', 90), ('integral', 90), ('overdispersion', 90), ('scipy', 90), ('type i errors', 90), ('power law', 89), ('residual analysis', 89), ('mathematics', 88), ('deviance', 88), ('binning', 88), ('interval', 87), ('psychology', 87), ('tukey hsd', 87), ('calibration', 87), ('rank correlation', 87), ('nominal', 86), ('intercept', 86), ('model evaluation', 86), ('information retrieval', 85), ('cross section', 85), ('partial correlation', 84), ('dice', 84), ('lme4 nlme', 84), ('z score', 84), ('genetic algorithms', 82), ('truncation', 81), ('partitioning', 81), ('weighted data', 81), ('quality control', 81), ('kappa', 81), ('importance', 80), ('log linear', 79), ('empirical', 79), ('function', 79), ('parameter optimization', 78), ('data preprocessing', 78), ('generalized moments', 77), ('association rules', 77), ('rnn', 77), ('social network', 77), ('sensitivity', 76), ('point estimation', 76), ('bagging', 76), ('matrix inverse', 76), ('java', 75), ('cohens d', 75), ('spectral analysis', 75), ('risk', 75), ('odds', 75), ('out of sample', 74), ('history', 74), ('association measure', 74), ('quadratic form', 74), ('random walk', 74), ('sequence analysis', 74), ('rbm', 74), ('filter', 74), ('centering', 73), ('control', 73), ('clustered standard errors', 73), ('link function', 73), ('maximum entropy', 73), ('deep belief networks', 72), ('artificial intelligence', 72), ('dirichlet process', 72), ('rare events', 72), ('validity', 71), ('mode', 71), ('confusion matrix', 71), ('meta regression', 71), ('pareto distribution', 70), ('winbugs', 70), ('observational study', 70), ('point process', 70), ('method comparison', 69), ('cluster sample', 68), ('circular statistics', 68), ('case control study', 68), ('segmentation', 68), ('shrinkage', 68), ('sequential analysis', 67), ('mcnemar test', 67), ('scoring', 67), ('kendall tau', 67), ('intervention analysis', 67), ('2sls', 66), ('fisher', 65), ('tobit regression', 65), ('loess', 65), ('volatility forecasting', 64), ('mgcv', 64), ('ranks', 64), ('beta binomial', 63), ('dynamic regression', 63), ('inferential statistics', 63), ('stan', 63), ('mice', 62), ('delta method', 62), ('rating', 62), ('iid', 61), ('moderation', 61), ('correspondence analysis', 61), ('anomaly detection', 61), ('method of moments', 61), ('equivalence', 61), ('relative risk', 61), ('hausman', 60), ('euclidean', 60), ('marketing', 60), ('noise', 60), ('minimum', 60), ('efficiency', 60), ('ordered logit', 60), ('numerical integration', 60), ('beta regression', 59), ('identifiability', 59), ('structural change', 59), ('geostatistics', 58), ('vif', 58), ('signal detection', 58), ('derivative', 58), ('traminer', 57), ('variational bayes', 57), ('tensorflow', 57), ('growth model', 57), ('coefficient of variation', 57), ('subset', 56), ('canonical correlation', 56), ('offset', 56), ('latent class', 56), ('spatio temporal', 55), ('multilabel', 55), ('adjustment', 55), ('cronbachs alpha', 55), ('white noise', 54), ('queueing', 54), ('credible interval', 54), ('composite', 53), ('philosophical', 53), ('statsmodels', 52), ('perceptron', 52), ('variogram', 52), ('statistical', 51), ('importance sampling', 51), ('variability', 51), ('mgf', 51), ('nls', 50), ('penalized', 50), ('numerics', 50), ('self organizing maps', 50), ('weights', 50), ('word2vec', 50), ('lsa', 49), ('finite population', 49), ('particle filter', 49), ('amos', 49), ('nonparametric bayes', 49), ('sensitivity analysis', 48), ('specificity', 48), ('education', 48), ('wishart', 48), ('levenes test', 48), ('gradient', 48), ('geometric distribution', 47), ('eviews', 47), ('lsmeans', 47), ('fuzzy', 47), ('density estimation', 46), ('minitab', 46), ('type ii errors', 46), ('robust standard error', 46), ('agreement statistics', 46), ('path model', 46), ('multivariable', 45), ('combining p values', 45), ('model based clustering', 45), ('programming', 45), ('arithmetic', 45), ('word embeddings', 44), ('geometry', 44), ('replication', 44), ('split plot', 44), ('gini', 44), ('microarray', 44), ('blocking', 44), ('rejection sampling', 43), ('macroeconomics', 43), ('constrained regression', 43), ('log likelihood', 43), ('multiarmed bandit', 42), ('code', 42), ('change scores', 42), ('imbalanced', 42), ('brownian', 42), ('clogit', 42), ('conjoint analysis', 42), ('univariate', 42), ('mixed design', 42), ('arch', 41), ('lavaan', 41), ('application', 41), ('jmp', 41), ('conditioning', 41), ('communication', 40), ('z statistic', 40), ('barplot', 40), ('semi supervised', 40), ('measure theory', 40), ('summations', 40), ('data cleaning', 40), ('tables', 39), ('impulse response', 39), ('demography', 39), ('generative models', 39), ('f distribution', 39), ('functional data analysis', 38), ('dlm', 38), ('sentiment analysis', 38), ('curves', 38), ('reproducible research', 38), ('c++', 38), ('back transformation', 38), ('logrank', 37), ('fat tails', 37), ('survey weights', 37), ('umvue', 37), ('mlogit', 37), ('package', 37), ('friedman test', 37), ('plm', 37), ('wavelet', 37), ('fractional factorial', 37), ('uninformative prior', 35), ('cauchy', 35), ('law of large numbers', 35), ('kriging', 35), ('marginal effect', 35), ('signed rank test', 34), ('lars', 34), ('bias correction', 34), ('mathematica', 34), ('formula', 34), ('ica', 34), ('valuation', 33), ('discontinuity', 33), ('projection', 33), ('multiple seasonalities', 33), ('hauck donner effect', 33), ('cosine similarity', 33), ('rotation', 33), ('census', 32), ('heterogeneity', 32), ('dendrogram', 32), ('biplot', 32), ('cholesky', 32), ('radial basis', 32), ('interval censoring', 32), ('error message', 31), ('careers', 31), ('crossover study', 31), ('numpy', 31), ('softmax', 31), ('rule of thumb', 31), ('real time', 31), ('f statistic', 31), ('mplus', 31), ('two way', 31), ('factor rotation', 31), ('anderson darling', 31), ('ecdf', 31), ('web', 31), ('parallel computing', 30), ('piecewise linear', 30), ('igraph', 30), ('oversampling', 30), ('range', 30), ('adaboost', 30), ('dataframe', 30), ('test for trend', 30), ('random matrix', 30), ('dispersion', 30), ('inverse gamma', 29), ('laplace distribution', 29), ('jaccard similarity', 29), ('e1071', 29), ('effects', 29), ('computing', 29), ('business intelligence', 29), ('incidence rate ratio', 29), ('bayes factors', 29), ('heavy tailed', 29), ('errors in variables', 29), ('heckman', 28), ('neyman pearson lemma', 28), ('transition matrix', 28), ('quasi likelihood', 28), ('discriminant', 28), ('model averaging', 28), ('frailty', 28), ('sphericity', 28), ('chemometrics', 28), ('statistical control', 28), ('constraint', 28), ('scale invariance', 28), ('stacking', 27), ('optimal scaling', 27), ('vc dimension', 27), ('social science', 27), ('k medoids', 27), ('moving window', 27), ('indicator variables', 27), ('tolerance interval', 26), ('poisson binomial', 26), ('conditional random field', 26), ('non response', 26), ('correlated predictors', 26), ('nnet', 26), ('apriori', 26), ('spark mllib', 26), ('tbats', 26), ('chow test', 26), ('segmented regression', 26), ('coding', 25), ('total least squares', 25), ('profile likelihood', 25), ('theano', 25), ('interaction variable', 25), ('control chart', 25), ('truncated normal', 25), ('mad', 25), ('cosine distance', 25), ('information', 24), ('big data', 24), ('partial', 24), ('concordance', 24), ('jackknife', 24), ('dropout', 24), ('rapidminer', 24), ('units', 24), ('churn', 24), ('qualitative', 24), ('survey sampling', 24), ('precision', 24), ('trimmed mean', 24), ('time complexity', 23), ('correlation matrix', 23), ('probabilistic programming', 23), ('ecm', 23), ('repeatability', 23), ('leverage', 23), ('subsampling', 23), ('funnel plot', 23), ('convex', 23), ('dunn test', 23), ('jeffreys prior', 23), ('kde', 23), ('sql', 23), ('gumbel', 23), ('characteristic function', 23), ('age', 23), ('representative', 23), ('bimodal', 22), ('skew normal', 22), ('compositional data', 22), ('presentation', 22), ('neuroscience', 22), ('pandas', 22), ('interactive visualization', 22), ('neweywest', 22), ('integration', 22), ('causalimpact', 21), ('finite mixture model', 21), ('non central', 21), ('synthetic data', 21), ('paradox', 21), ('ergodic', 21), ('zero inflated', 21), ('capture mark recapture', 21), ('events', 21), ('sequential pattern mining', 21), ('two step estimation', 21), ('choice', 21), ('geometric mean', 21), ('neuroimaging', 21), ('martingale', 20), ('symmetry', 20), ('c#', 20), ('deming regression', 20), ('optimal stopping', 20), ('publication bias', 20), ('familywise error', 20), ('simpsons paradox', 20), ('interarrival time', 20), ('multivariate distribution', 20), ('taylor series', 20), ('hotelling', 20), ('failure', 20), ('average precision', 20), ('cost maximization', 20), ('determinant', 20), ('project management', 20), ('mancova', 20), ('polling', 19), ('nonparametric regression', 19), ('language models', 19), ('matplotlib', 19), ('compression', 19), ('coverage probability', 19), ('abc', 19), ('competing risks', 19), ('singular', 19), ('bernoulli process', 19), ('fraud', 19), ('box jenkins', 19), ('nnmf', 19), ('decomposition', 19), ('xgboost', 19), ('standard', 19), ('cross entropy', 19), ('elasticity', 19), ('database', 18), ('operations research', 18), ('variance decomposition', 18), ('phylogeny', 18), ('scoring rules', 18), ('hessian', 18), ('differences', 18), ('tsne', 18), ('zipf', 18), ('pivot', 17), ('non nested', 17), ('data association', 17), ('cfa', 17), ('directional statistics', 17), ('overlapping data', 17), ('steins phenomenon', 17), ('recurrent events', 17), ('sign test', 17), ('heatmap', 17), ('planned comparisons test', 17), ('fisher transform', 17), ('academia', 17), ('dbscan', 17), ('tost', 17), ('proportional hazards', 16), ('underdispersion', 16), ('open bugs', 16), ('manifold learning', 16), ('fuzzy set', 16), ('one class', 16), ('linearity', 16), ('coupon collector problem', 16), ('sandwich', 16), ('mape', 16), ('cramers v', 16), ('reml', 16), ('index decomposition', 15), ('gis', 15), ('inequality', 15), ('rbf network', 15), ('heuristic', 15), ('gamm4', 15), ('lrt', 15), ('matrix calculus', 15), ('dependence', 15), ('climate', 15), ('extrapolation', 15), ('rasch', 15), ('dag', 15), ('fractal', 15), ('exact test', 15), ('mortality', 15), ('differential equations', 15), ('transform', 14), ('data generating process', 14), ('bland altman plot', 14), ('stochastic approximation', 14), ('elections', 14), ('collaborative', 14), ('homogeneity', 14), ('suppressor', 14), ('sgd', 14), ('recursive model', 14), ('interquartile', 14), ('geography', 14), ('gwas', 14), ('rayleigh', 14), ('relative distribution', 14), ('viterbi algorithm', 14), ('pie chart', 14), ('birthday paradox', 13), ('semiparametric', 13), ('nonlinearity', 13), ('breusch pagan', 13), ('discussion', 13), ('jacobian', 13), ('benchmark', 13), ('latent semantic indexing', 13), ('underdetermined', 13), ('explanatory', 13), ('skellam', 13), ('pcoa', 13), ('game theory', 13), ('quasi binomial', 13), ('distance covariance', 13), ('cochran mantel haenszel', 13), ('open source', 12), ('q learning', 12), ('nonparametric density', 12), ('statistical bias', 12), ('markov random field', 12), ('library', 12), ('invariance', 12), ('journals', 12), ('gamlss', 12), ('order', 12), ('inverse gaussian distrib', 12), ('cochran q', 12), ('two sample', 12), ('case cohort', 12), ('error in variables', 12), ('novelty detection', 12), ('mean shift', 12), ('growth mixture model', 12), ('checking', 12), ('quasi monte carlo', 11), ('search theory', 11), ('information geometry', 11), ('latex', 11), ('partial plot', 11), ('regression to the mean', 11), ('mars', 11), ('automatic algorithms', 11), ('l moments', 11), ('nltk', 11), ('vector fields', 11), ('labeling', 11), ('linear dynamical system', 11), ('dependent', 11), ('systematic', 11), ('mase', 11), ('spurious correlation', 11), ('network meta analysis', 11), ('environmental data', 11), ('latin hypercube', 11), ('point mass at zero', 11), ('medicine', 11), ('mae', 10), ('disease', 10), ('optimal', 10), ('discrete time', 10), ('twin', 10), ('politics', 10), ('blue', 10), ('yates correction', 10), ('bradley terry model', 10), ('contrast', 10), ('baum welch', 10), ('expectation', 10), ('condition number', 10), ('modularity', 10), ('irls', 10), ('minimax', 10), ('counterbalancing', 10), ('dyadic data', 10), ('topologies', 10), ('javascript', 10), ('armax', 10), ('local statistics', 10), ('tweedie distribution', 10), ('bayesian optimization', 10), ('sur', 10), ('pre training', 10), ('gambling', 10), ('minimum variance', 10), ('torch', 10), ('gretl', 10), ('rao blackwell', 10), ('science', 9), ('life expectancy', 9), ('csv file', 9), ('vowpal wabbit', 9), ('belief propagation', 9), ('puzzle', 9), ('rocr', 9), ('scale construction', 9), ('approximate inference', 9), ('car', 9), ('poker', 9), ('sweave', 9), ('ordered probit', 9), ('starting values', 9), ('variance stabilizing', 9), ('scale estimator', 9), ('scalability', 9), ('glmmlasso', 9), ('party', 9), ('elo', 9), ('down sample', 9), ('active learning', 9), ('ward', 9), ('multitask learning', 9), ('population average', 9), ('linear programming', 9), ('schoenfeld residuals', 9), ('products', 9), ('crostons method', 9), ('separability', 9), ('pareto', 9), ('permutation test', 8), ('elicitation', 8), ('randomized', 8), ('moment', 8), ('julia', 8), ('absolute risk', 8), ('item analysis', 8), ('score function', 8), ('tf idf', 8), ('parallel analysis', 8), ('knowledge discovery', 8), ('spatial interaction model', 8), ('shape', 8), ('ruby', 8), ('explanatory models', 8), ('multinomial logit', 8), ('fallacy', 8), ('partykit', 8), ('probability calculus', 8), ('sigma algebra', 8), ('in sample', 8), ('marginal model', 8), ('statistics in media', 8), ('nlmer', 8), ('latin square', 8), ('internet', 8), ('logic', 8), ('mfcc', 8), ('prediction limit', 8), ('numerical models', 8), ('diffusion', 8), ('inverse cdf', 8), ('pmml', 8), ('pivot table', 7), ('treatment', 7), ('enrichment', 7), ('batch normalization', 7), ('saddlepoint approximation', 7), ('non inferiority', 7), ('probability generating fn', 7), ('contextual bandit', 7), ('max margin', 7), ('hac', 7), ('visual summary', 7), ('reduced rank regression', 7), ('lifetable', 7), ('chemistry', 7), ('runs', 7), ('identification', 7), ('lilliefors', 7), ('polr', 7), ('replicate', 7), ('courses', 7), ('gllamm', 7), ('combinatorial', 7), ('etymology', 7), ('hosmer lemeshow test', 7), ('musical data analysis', 6), ('mixed distribution', 6), ('lorenz curve', 6), ('likelihood ratio test', 6), ('astronomy', 6), ('isotonic', 6), ('phd', 6), ('ellipse', 6), ('restrictions', 6), ('missing value', 6), ('untagged', 6), ('stochastic ordering', 6), ('simultaneous equation', 6), ('fiducial', 6), ('population ecology', 6), ('blup', 6), ('gpower', 6), ('bayes optimal classifier', 6), ('structured svm', 6), ('value of information', 6), ('community wiki', 6), ('adagrad', 6), ('php', 6), ('coda', 6), ('gnuplot', 6), ('admissibility', 6), ('pruning', 6), ('bayesian score', 5), ('derived distributions', 5), ('regression testing', 5), ('engineering statistics', 5), ('voting system', 5), ('hotelling t2', 5), ('normalizing constant', 5), ('exchangeability', 5), ('spss modeler', 5), ('domain adaptation', 5), ('rlm', 5), ('information extraction', 5), ('circular', 5), ('diagnosis', 5), ('deterministic', 5), ('gamboost', 5), ('normal approximation', 5), ('bessels correction', 5), ('reproducibility', 5), ('google spreadsheet', 5), ('extremal dependence', 5), ('m estimation', 5), ('casella berger', 5), ('absolute deviation', 5), ('cv.glm', 5), ('cumulants', 5), ('fisher scoring', 5), ('monitoring', 4), ('logarithmic series', 4), ('combining estimates', 4), ('transportation', 4), ('design based inference', 4), ('forecastability', 4), ('conferences', 4), ('polychoric', 4), ('smallareaestimation', 4), ('forward backward', 4), ('disaggregation', 4), ('d prime', 4), ('splus', 4), ('gui', 4), ('named entity recognition', 4), ('gru', 4), ('pybrain', 4), ('differential privacy', 4), ('double blind', 4), ('improper prior', 4), ('structured prediction', 4), ('abbreviation', 4), ('calc', 4), ('combining predictions', 4), ('orthogonal', 4), ('anosim', 4), ('ronald fisher', 4), ('general additive model', 4), ('dropconnect', 4), ('multiple membership', 4), ('tensor', 4), ('hmc', 4), ('quotation', 4), ('bias node', 4), ('consulting', 4), ('compartmental models', 4), ('algebraic statistics', 3), ('auxiliary variable', 3), ('multicore', 3), ('unit information prior', 3), ('dplyr', 3), ('cooccurrence', 3), ('slutsky theorem', 3), ('infinite variance', 3), ('gpu', 3), ('frequency severity', 3), ('rademacher complexity', 3), ('perl', 3), ('clara', 3), ('subject specific', 3), ('sigmoid', 3), ('example', 3), ('multinomial probit', 3), ('nnt', 3), ('empirical likelihood', 3), ('log loss', 3), ('rounding', 3), ('collecting data', 3), ('chi distribution', 3), ('complete statistics', 3), ('dunnett', 3), ('kolmogorov axioms', 3), ('np', 3), ('generalized eta squared', 3), ('ancillary statistics', 3), ('intractable likelihood', 3), ('optunity', 3), ('fortran', 3), ('systematic review', 3), ('reversible jump', 3), ('timelines', 3), ('nadaraya watson', 3), ('crossover', 3), ('humor', 2), ('concavity', 2), ('geomarketing', 2), ('plyr', 2), ('regularity', 2), ('referee', 2), ('generator', 2), ('rough sets', 2), ('rhadoop', 2), ('add one smoothing', 2), ('theta method', 2), ('factorisation theorem', 2), ('xorshift', 2), ('legal', 2), ('risk difference', 2), ('oracle', 2), ('automatic differentiation', 2), ('ipf', 2), ('model checking', 2), ('lyapunov exponent', 2), ('tweedie', 2), ('wald estimator', 2), ('toeplitz', 2), ('qr', 2), ('cubic', 2), ('duan smearing', 2), ('dic', 2), ('pitch game', 2), ('shortest half', 2), ('transfer learning', 2), ('statistical theory', 2), ('volatility', 2), ('potts model', 2), ('calculus', 2), ('als', 2), ('bag of words', 2), ('approximate randomization', 2), ('drug', 2), ('therapy', 2), ('evolutionary algorithms', 2), ('rmr', 2), ('variance test', 2), ('test equating', 2), ('characterization', 2), ('2d', 1), ('protovis', 1), ('pspp', 1), ('qsar', 1), ('netflix prize', 1), ('bnlearn', 1), ('bayesian anova', 1), ('inliers', 1), ('auxiliary particle filter', 1), ('hierarchical softmax', 1), ('law of total expectation', 1), ('langevin diffusion', 1), ('quartile', 1), ('segmented', 1), ('svmlibsm', 1), ('fused lasso', 1), ('gmm', 1), ('american community survey', 1), ('mechanism design', 1), ('representation learning', 1), ('propensity', 1), ('mcar', 1), ('combining models', 1), ('leave one out', 1), ('gmmboost', 1), ('dimensions', 1), ('fda', 1), ('corpus linguistics', 1), ('pit', 1), ('mboost', 1), ('memm', 1), ('fmincon', 1), ('capability certification', 1), ('mean deviation', 1), ('mean absolute deviation', 1), ('doc2vec', 1), ('network layout', 1), ('shapley value', 1), ('adversarial boosting', 1), ('sympy', 1), ('matconvnet', 1), ('negative results', 1), ('hawkes', 1), ('retrospective', 1), ('ram', 1), ('replicability', 1), ('efficacy', 1), ('bands', 1), ('concept drift', 1), ('clumping', 1), ('markov logic network', 1)])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"1PQMi8WIv0_u","outputId":"9b3c5831-a849-4fd3-860e-94d26fde3165","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713500673129,"user_tz":-330,"elapsed":632,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# Top 10 most frequent tags\n","common_tags = list(freq.keys())[:10]\n","common_tags"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['r',\n"," 'regression',\n"," 'machine learning',\n"," 'time series',\n"," 'probability',\n"," 'hypothesis testing',\n"," 'self study',\n"," 'distributions',\n"," 'logistic',\n"," 'classification']"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"buPS2OrlN50F"},"source":["We will use only those questions/queries that have the above 10 tags associated with it."]},{"cell_type":"code","metadata":{"id":"CVB3DKppym51","executionInfo":{"status":"ok","timestamp":1713500686980,"user_tz":-330,"elapsed":1521,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["x=[]\n","y=[]\n","\n","for i in range(len(df['tags'])):\n","\n","  temp=[]\n","  for j in df['tags'][i]:\n","    if j in common_tags: # more than 10\n","      temp.append(j)\n","\n","  if(len(temp)>1):\n","    x.append(df['cleaned_text'][i])\n","    y.append(temp)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"fYMxubGzzN7Q","outputId":"0c370c9a-a8e1-44eb-bc1b-74cf4c89bcf9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713500694519,"user_tz":-330,"elapsed":351,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# number of questions left\n","len(x)"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11106"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"hFmgSxWp00Gu","outputId":"f140204c-904e-4481-9c6a-cc26c72ce3ff","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712913434746,"user_tz":-330,"elapsed":2,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["y[:10] # multilable targets"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['r', 'time series'],\n"," ['regression', 'distributions'],\n"," ['distributions', 'probability', 'hypothesis testing'],\n"," ['hypothesis testing', 'self study'],\n"," ['r', 'regression', 'time series'],\n"," ['r', 'time series', 'self study'],\n"," ['probability', 'hypothesis testing'],\n"," ['r', 'regression'],\n"," ['r', 'regression'],\n"," ['regression', 'logistic']]"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"pzCk5T-KR-W5","outputId":"2b5438dc-7030-42e7-f771-0076756929d2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713500782309,"user_tz":-330,"elapsed":904,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["from sklearn.preprocessing import MultiLabelBinarizer\n","mlb = MultiLabelBinarizer()\n","\n","y = mlb.fit_transform(y)\n","y.shape"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11106, 10)"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"eJxESqMJSEKZ","outputId":"c5f19a1b-e083-46c0-f9ed-baa3b89bb0c9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713500788965,"user_tz":-330,"elapsed":350,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["y[0,:] # Multihot encoded vector"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 1, 0, 0, 1])"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"YZHXV-GqSg3s","outputId":"e5cfe1b8-93a3-45a1-f30c-ffc42d64db8d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713500807155,"user_tz":-330,"elapsed":405,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["mlb.classes_"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['classification', 'distributions', 'hypothesis testing',\n","       'logistic', 'machine learning', 'probability', 'r', 'regression',\n","       'self study', 'time series'], dtype=object)"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"WkF4pDaJStjg"},"source":["We can now split the dataset into training set and validation set."]},{"cell_type":"code","metadata":{"id":"QPHeAiS9KvD9","executionInfo":{"status":"ok","timestamp":1713500840452,"user_tz":-330,"elapsed":473,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["from sklearn.model_selection import train_test_split\n","x_tr,x_val,y_tr,y_val=train_test_split(x, y, test_size=0.2, random_state=0,shuffle=True)"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H4GaDNwtTmPh"},"source":["# Text Representation"]},{"cell_type":"code","metadata":{"id":"TtrDalDiPXJM","executionInfo":{"status":"ok","timestamp":1713501576253,"user_tz":-330,"elapsed":4043,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","\n","#prepare a tokenizer\n","x_tokenizer = Tokenizer()\n","\n","x_tokenizer.fit_on_texts(x_tr)"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"zl1vZKpwU2P2","outputId":"ee0e6875-1378-41d4-a458-d423150e2bdf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713501576253,"user_tz":-330,"elapsed":4,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["x_tokenizer.word_index # Give each word an index in corpus"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'the': 1,\n"," 'i': 2,\n"," 'to': 3,\n"," 'a': 4,\n"," 'of': 5,\n"," 'is': 6,\n"," 'and': 7,\n"," 'in': 8,\n"," 'l': 9,\n"," 'x': 10,\n"," 'for': 11,\n"," 'that': 12,\n"," 'data': 13,\n"," 'this': 14,\n"," 't': 15,\n"," 'have': 16,\n"," 'y': 17,\n"," 'with': 18,\n"," 'model': 19,\n"," 'it': 20,\n"," 'are': 21,\n"," 'be': 22,\n"," 'my': 23,\n"," 'as': 24,\n"," 'on': 25,\n"," 'e': 26,\n"," 'p': 27,\n"," 'if': 28,\n"," 'can': 29,\n"," 'n': 30,\n"," 'but': 31,\n"," 'not': 32,\n"," 'm': 33,\n"," 'or': 34,\n"," 'r': 35,\n"," 'how': 36,\n"," 'regression': 37,\n"," 'c': 38,\n"," 'am': 39,\n"," 's': 40,\n"," 'from': 41,\n"," 'test': 42,\n"," 'what': 43,\n"," 'would': 44,\n"," 'b': 45,\n"," 'so': 46,\n"," 'time': 47,\n"," 'there': 48,\n"," 'using': 49,\n"," 'which': 50,\n"," 'an': 51,\n"," 'do': 52,\n"," 'one': 53,\n"," 'each': 54,\n"," 'value': 55,\n"," 'use': 56,\n"," 'by': 57,\n"," 'some': 58,\n"," 'variables': 59,\n"," 'like': 60,\n"," 'variable': 61,\n"," 'we': 62,\n"," 'at': 63,\n"," 'na': 64,\n"," 'any': 65,\n"," 'f': 66,\n"," 'distribution': 67,\n"," 'two': 68,\n"," 'values': 69,\n"," 'set': 70,\n"," 'you': 71,\n"," 'all': 72,\n"," 'function': 73,\n"," 'fit': 74,\n"," 'd': 75,\n"," 'beta': 76,\n"," 'question': 77,\n"," 'then': 78,\n"," 'mean': 79,\n"," 'me': 80,\n"," 'know': 81,\n"," 'where': 82,\n"," 'when': 83,\n"," 'should': 84,\n"," 'different': 85,\n"," 'want': 86,\n"," 'series': 87,\n"," 'probability': 88,\n"," 'error': 89,\n"," 'number': 90,\n"," 'logistic': 91,\n"," 'problem': 92,\n"," 'about': 93,\n"," 'z': 94,\n"," 'here': 95,\n"," 'k': 96,\n"," 'get': 97,\n"," 'was': 98,\n"," 'linear': 99,\n"," 'other': 100,\n"," 'more': 101,\n"," 'will': 102,\n"," 'sample': 103,\n"," 'between': 104,\n"," 'also': 105,\n"," 'these': 106,\n"," 'has': 107,\n"," 'example': 108,\n"," 'frac': 109,\n"," 'way': 110,\n"," 'same': 111,\n"," 'sum': 112,\n"," 'out': 113,\n"," 'right': 114,\n"," 'only': 115,\n"," 'h': 116,\n"," 'following': 117,\n"," 'could': 118,\n"," 'does': 119,\n"," 'random': 120,\n"," 'than': 121,\n"," 'log': 122,\n"," 'first': 123,\n"," 'given': 124,\n"," 'find': 125,\n"," 'used': 126,\n"," 'however': 127,\n"," 'models': 128,\n"," 'they': 129,\n"," 'no': 130,\n"," 'theta': 131,\n"," 'class': 132,\n"," 'just': 133,\n"," 'predict': 134,\n"," 'df': 135,\n"," 'results': 136,\n"," 'q': 137,\n"," 'w': 138,\n"," 'trying': 139,\n"," 'now': 140,\n"," 'training': 141,\n"," 'coefficients': 142,\n"," 'need': 143,\n"," 'plot': 144,\n"," 'v': 145,\n"," 'g': 146,\n"," 'method': 147,\n"," 'j': 148,\n"," 'case': 149,\n"," 'dataset': 150,\n"," 'very': 151,\n"," 'help': 152,\n"," 'true': 153,\n"," 'lm': 154,\n"," 'estimate': 155,\n"," 'sigma': 156,\n"," 'into': 157,\n"," 'see': 158,\n"," 'alpha': 159,\n"," 'don': 160,\n"," 've': 161,\n"," 'say': 162,\n"," 'matrix': 163,\n"," 'package': 164,\n"," 'such': 165,\n"," 'classification': 166,\n"," 'code': 167,\n"," 'factor': 168,\n"," 'analysis': 169,\n"," 'because': 170,\n"," 'understand': 171,\n"," 'left': 172,\n"," 'why': 173,\n"," 'hat': 174,\n"," 'thanks': 175,\n"," 'independent': 176,\n"," 'intercept': 177,\n"," 'new': 178,\n"," 'based': 179,\n"," 'type': 180,\n"," 'group': 181,\n"," 'glm': 182,\n"," 'correct': 183,\n"," 'best': 184,\n"," 'order': 185,\n"," 'make': 186,\n"," 'let': 187,\n"," 'standard': 188,\n"," 'u': 189,\n"," 'both': 190,\n"," 'output': 191,\n"," 'mu': 192,\n"," 'good': 193,\n"," 'possible': 194,\n"," 'over': 195,\n"," 'arima': 196,\n"," 'them': 197,\n"," 'text': 198,\n"," 'approach': 199,\n"," 'binomial': 200,\n"," 'age': 201,\n"," 'features': 202,\n"," 'response': 203,\n"," 'year': 204,\n"," 'point': 205,\n"," 'something': 206,\n"," 'significant': 207,\n"," 'whether': 208,\n"," 'better': 209,\n"," 'points': 210,\n"," 'up': 211,\n"," 'think': 212,\n"," 'been': 213,\n"," 'parameters': 214,\n"," 'residuals': 215,\n"," 'observations': 216,\n"," 'formula': 217,\n"," 'sure': 218,\n"," 'calculate': 219,\n"," 'train': 220,\n"," 'since': 221,\n"," 'binary': 222,\n"," 'run': 223,\n"," 'size': 224,\n"," 'summary': 225,\n"," 'variance': 226,\n"," 'non': 227,\n"," 'hypothesis': 228,\n"," 'var': 229,\n"," 'above': 230,\n"," 'below': 231,\n"," 'end': 232,\n"," 'after': 233,\n"," 'length': 234,\n"," 'learning': 235,\n"," 'normal': 236,\n"," 'lambda': 237,\n"," 'level': 238,\n"," 'result': 239,\n"," 'dependent': 240,\n"," 'difference': 241,\n"," 'family': 242,\n"," 'seems': 243,\n"," 'tried': 244,\n"," 'forecast': 245,\n"," 'null': 246,\n"," 'times': 247,\n"," 'many': 248,\n"," 'prediction': 249,\n"," 'doing': 250,\n"," 'questions': 251,\n"," 'much': 252,\n"," 'max': 253,\n"," 'effect': 254,\n"," 'answer': 255,\n"," 'looking': 256,\n"," 'well': 257,\n"," 'pr': 258,\n"," 'classifier': 259,\n"," 'parameter': 260,\n"," 'vector': 261,\n"," 'continuous': 262,\n"," 'multiple': 263,\n"," 'were': 264,\n"," 'found': 265,\n"," 'please': 266,\n"," 'may': 267,\n"," 'squared': 268,\n"," 'library': 269,\n"," 'their': 270,\n"," 'samples': 271,\n"," 'most': 272,\n"," 'simple': 273,\n"," 'predictor': 274,\n"," 'frame': 275,\n"," 'likelihood': 276,\n"," 'etc': 277,\n"," 'second': 278,\n"," 'correlation': 279,\n"," 'predictors': 280,\n"," 'being': 281,\n"," 'give': 282,\n"," 'change': 283,\n"," 'list': 284,\n"," 'score': 285,\n"," 'accuracy': 286,\n"," 'feature': 287,\n"," 'outcome': 288,\n"," 'might': 289,\n"," 'really': 290,\n"," 'its': 291,\n"," 'day': 292,\n"," 'information': 293,\n"," 'even': 294,\n"," 'similar': 295,\n"," 'means': 296,\n"," 'epsilon': 297,\n"," 'categorical': 298,\n"," 'equation': 299,\n"," 'take': 300,\n"," 'false': 301,\n"," 'min': 302,\n"," 'work': 303,\n"," 'those': 304,\n"," 'input': 305,\n"," 'anyone': 306,\n"," 'std': 307,\n"," 'look': 308,\n"," 'another': 309,\n"," 'exp': 310,\n"," 'suppose': 311,\n"," 'zero': 312,\n"," 'average': 313,\n"," 'read': 314,\n"," 'total': 315,\n"," 'mathbf': 316,\n"," 'before': 317,\n"," 'logit': 318,\n"," 'terms': 319,\n"," 'effects': 320,\n"," 'three': 321,\n"," 'algorithm': 322,\n"," 'compare': 323,\n"," 'ts': 324,\n"," 'interval': 325,\n"," 'gamma': 326,\n"," 'still': 327,\n"," 'show': 328,\n"," 'negative': 329,\n"," 'working': 330,\n"," 'probabilities': 331,\n"," 'high': 332,\n"," 'machine': 333,\n"," 'table': 334,\n"," 'having': 335,\n"," 'cross': 336,\n"," 'confidence': 337,\n"," 'start': 338,\n"," 'testing': 339,\n"," 'predicted': 340,\n"," 'statistical': 341,\n"," 'while': 342,\n"," 'did': 343,\n"," 'your': 344,\n"," 'rate': 345,\n"," 'levels': 346,\n"," 'wrong': 347,\n"," 'groups': 348,\n"," 'large': 349,\n"," 'assume': 350,\n"," 'scale': 351,\n"," 'coefficient': 352,\n"," 'bar': 353,\n"," 'line': 354,\n"," 'residual': 355,\n"," 'statistics': 356,\n"," 'days': 357,\n"," 'positive': 358,\n"," 'call': 359,\n"," 'methods': 360,\n"," 'distributions': 361,\n"," 'phi': 362,\n"," 'someone': 363,\n"," 'term': 364,\n"," 'edit': 365,\n"," 'cases': 366,\n"," 'every': 367,\n"," 'far': 368,\n"," 'able': 369,\n"," 'process': 370,\n"," 'statistic': 371,\n"," 'people': 372,\n"," 'determine': 373,\n"," 'fitted': 374,\n"," 'gives': 375,\n"," 'step': 376,\n"," 'validation': 377,\n"," 'lag': 378,\n"," 'deviance': 379,\n"," 'appreciated': 380,\n"," 'part': 381,\n"," 'sqrt': 382,\n"," 'ratio': 383,\n"," 'thank': 384,\n"," 'form': 385,\n"," 'tests': 386,\n"," 'classes': 387,\n"," 'without': 388,\n"," 'degrees': 389,\n"," 'freedom': 390,\n"," 'idea': 391,\n"," 'try': 392,\n"," 'rep': 393,\n"," 'aic': 394,\n"," 'within': 395,\n"," 'least': 396,\n"," 'measure': 397,\n"," 'around': 398,\n"," 'got': 399,\n"," 'perform': 400,\n"," 'sim': 401,\n"," 'done': 402,\n"," 'per': 403,\n"," 'doesn': 404,\n"," 'had': 405,\n"," 'create': 406,\n"," 'sense': 407,\n"," 'link': 408,\n"," 'real': 409,\n"," 'rnorm': 410,\n"," 'interaction': 411,\n"," 'price': 412,\n"," 'median': 413,\n"," 'explain': 414,\n"," 'trend': 415,\n"," 'month': 416,\n"," 'vs': 417,\n"," 'follows': 418,\n"," 'specific': 419,\n"," 'chi': 420,\n"," 'years': 421,\n"," 'weight': 422,\n"," 'yes': 423,\n"," 'begin': 424,\n"," 'population': 425,\n"," 'looks': 426,\n"," 'particular': 427,\n"," 'id': 428,\n"," 'kind': 429,\n"," 'state': 430,\n"," 'missing': 431,\n"," 'event': 432,\n"," 'control': 433,\n"," 'less': 434,\n"," 'go': 435,\n"," 'expected': 436,\n"," 'equal': 437,\n"," 'small': 438,\n"," 'sd': 439,\n"," 'wondering': 440,\n"," 'compute': 441,\n"," 'performance': 442,\n"," 'errors': 443,\n"," 'too': 444,\n"," 'actually': 445,\n"," 'single': 446,\n"," 'distributed': 447,\n"," 'several': 448,\n"," 'apply': 449,\n"," 'svm': 450,\n"," 'seem': 451,\n"," 'treatment': 452,\n"," 'observation': 453,\n"," 'estimates': 454,\n"," 'weights': 455,\n"," 'either': 456,\n"," 'consider': 457,\n"," 'frequency': 458,\n"," 'density': 459,\n"," 'instead': 460,\n"," 'cannot': 461,\n"," 'thought': 462,\n"," 'check': 463,\n"," 'int': 464,\n"," 'sets': 465,\n"," 'estimated': 466,\n"," 'solution': 467,\n"," 'interested': 468,\n"," 'certain': 469,\n"," 'range': 470,\n"," 'general': 471,\n"," 'power': 472,\n"," 'date': 473,\n"," 'sales': 474,\n"," 'low': 475,\n"," 'quite': 476,\n"," 'appropriate': 477,\n"," 'choose': 478,\n"," 'solve': 479,\n"," 'poisson': 480,\n"," 'our': 481,\n"," 'through': 482,\n"," 'col': 483,\n"," 'few': 484,\n"," 'odds': 485,\n"," 'anova': 486,\n"," 'pi': 487,\n"," 'next': 488,\n"," 'dummy': 489,\n"," 'numeric': 490,\n"," 'period': 491,\n"," 'http': 492,\n"," 'individual': 493,\n"," 'fixed': 494,\n"," 'last': 495,\n"," 'figure': 496,\n"," 'factors': 497,\n"," 'add': 498,\n"," 'original': 499,\n"," 'build': 500,\n"," 'subject': 501,\n"," 'pred': 502,\n"," 'significance': 503,\n"," 'mod': 504,\n"," 'getting': 505,\n"," 'higher': 506,\n"," 'fitting': 507,\n"," 'include': 508,\n"," 'note': 509,\n"," 'across': 510,\n"," 'delta': 511,\n"," 'running': 512,\n"," 'calculated': 513,\n"," 'examples': 514,\n"," 'predictions': 515,\n"," 'ar': 516,\n"," 'paper': 517,\n"," 'lower': 518,\n"," 'advance': 519,\n"," 'actual': 520,\n"," 'relationship': 521,\n"," 'return': 522,\n"," 'count': 523,\n"," 'structure': 524,\n"," 'lot': 525,\n"," 'who': 526,\n"," 'infty': 527,\n"," 'functions': 528,\n"," 'red': 529,\n"," 'related': 530,\n"," 'product': 531,\n"," 'observed': 532,\n"," 'selection': 533,\n"," 'interpret': 534,\n"," 'codes': 535,\n"," 'dat': 536,\n"," 'generate': 537,\n"," 'under': 538,\n"," 'though': 539,\n"," 'currently': 540,\n"," 'category': 541,\n"," 'square': 542,\n"," 'label': 543,\n"," 'rather': 544,\n"," 'understanding': 545,\n"," 'numbers': 546,\n"," 'cost': 547,\n"," 'course': 548,\n"," 'target': 549,\n"," 'made': 550,\n"," 'distance': 551,\n"," 'exactly': 552,\n"," 'space': 553,\n"," 'previous': 554,\n"," 'coef': 555,\n"," 'constant': 556,\n"," 'main': 557,\n"," 'thinking': 558,\n"," 'curve': 559,\n"," 'problems': 560,\n"," 'scores': 561,\n"," 'bit': 562,\n"," 'gaussian': 563,\n"," 'thus': 564,\n"," 'mathbb': 565,\n"," 'simply': 566,\n"," 'prior': 567,\n"," 'always': 568,\n"," 'therefore': 569,\n"," 'final': 570,\n"," 'alternative': 571,\n"," 'going': 572,\n"," 'likely': 573,\n"," 'network': 574,\n"," 'maybe': 575,\n"," 'tree': 576,\n"," 'book': 577,\n"," 'lines': 578,\n"," 'sex': 579,\n"," 'leq': 580,\n"," 'object': 581,\n"," 'seasonal': 582,\n"," 'study': 583,\n"," 'row': 584,\n"," 'long': 585,\n"," 'big': 586,\n"," 'auto': 587,\n"," 'known': 588,\n"," 'fact': 589,\n"," 'slope': 590,\n"," 'column': 591,\n"," 'account': 592,\n"," 'come': 593,\n"," 'user': 594,\n"," 'signif': 595,\n"," 'important': 596,\n"," 'differences': 597,\n"," 'rows': 598,\n"," 'events': 599,\n"," 'due': 600,\n"," 'words': 601,\n"," 'neural': 602,\n"," 'daily': 603,\n"," 'se': 604,\n"," 'names': 605,\n"," 'post': 606,\n"," 'full': 607,\n"," 'procedure': 608,\n"," 'tell': 609,\n"," 'already': 610,\n"," 'mydata': 611,\n"," 'adjusted': 612,\n"," 'gender': 613,\n"," 'forest': 614,\n"," 'makes': 615,\n"," 're': 616,\n"," 'seed': 617,\n"," 'decision': 618,\n"," 'appreciate': 619,\n"," 'he': 620,\n"," 'pdf': 621,\n"," 'maximum': 622,\n"," 'index': 623,\n"," 'print': 624,\n"," 'current': 625,\n"," 'algorithms': 626,\n"," 'deviation': 627,\n"," 'shape': 628,\n"," 'reading': 629,\n"," 'issue': 630,\n"," 'system': 631,\n"," 'seasonality': 632,\n"," 'provide': 633,\n"," 'reason': 634,\n"," 'increase': 635,\n"," 'enough': 636,\n"," 'ols': 637,\n"," 'again': 638,\n"," 'intervals': 639,\n"," 'shows': 640,\n"," 'confused': 641,\n"," 'amount': 642,\n"," 'csv': 643,\n"," 'conditional': 644,\n"," 'cdot': 645,\n"," 'proportion': 646,\n"," 'com': 647,\n"," 'labels': 648,\n"," 'guess': 649,\n"," 'taken': 650,\n"," 'significantly': 651,\n"," 'graph': 652,\n"," 'taking': 653,\n"," 'diff': 654,\n"," 'rank': 655,\n"," 'learn': 656,\n"," 'according': 657,\n"," 'stationary': 658,\n"," 'acf': 659,\n"," 'page': 660,\n"," 'noise': 661,\n"," 'categories': 662,\n"," 'obtain': 663,\n"," 'update': 664,\n"," 'datasets': 665,\n"," 'success': 666,\n"," 'correctly': 667,\n"," 'person': 668,\n"," 'down': 669,\n"," 'against': 670,\n"," 'bad': 671,\n"," 'classify': 672,\n"," 'must': 673,\n"," 'threshold': 674,\n"," 'sampling': 675,\n"," 'instance': 676,\n"," 'assumption': 677,\n"," 'close': 678,\n"," 'suggestions': 679,\n"," 'columns': 680,\n"," 'student': 681,\n"," 'defined': 682,\n"," 'cbind': 683,\n"," 'partial': 684,\n"," 'condition': 685,\n"," 'name': 686,\n"," 'temperature': 687,\n"," 'greater': 688,\n"," 'else': 689,\n"," 'things': 690,\n"," 'anything': 691,\n"," 'loss': 692,\n"," 'seen': 693,\n"," 'believe': 694,\n"," 'little': 695,\n"," 'blue': 696,\n"," 'assuming': 697,\n"," 'male': 698,\n"," 'correlated': 699,\n"," 'statistically': 700,\n"," 'suggest': 701,\n"," 'direction': 702,\n"," 'support': 703,\n"," 'experiment': 704,\n"," 'goal': 705,\n"," 'area': 706,\n"," 'predictive': 707,\n"," 'week': 708,\n"," 'vectors': 709,\n"," 'basic': 710,\n"," 'cv': 711,\n"," 'classifiers': 712,\n"," 'available': 713,\n"," 'iv': 714,\n"," 'region': 715,\n"," 'subset': 716,\n"," 'ldots': 717,\n"," 'explanatory': 718,\n"," 'discrete': 719,\n"," 'off': 720,\n"," 'chance': 721,\n"," 'select': 722,\n"," 'reference': 723,\n"," 'split': 724,\n"," 'works': 725,\n"," 'us': 726,\n"," 'ones': 727,\n"," 'ways': 728,\n"," 'shown': 729,\n"," 'task': 730,\n"," 'transformation': 731,\n"," 'clear': 732,\n"," 'seq': 733,\n"," 'multivariate': 734,\n"," 'obtained': 735,\n"," 'trees': 736,\n"," 'rm': 737,\n"," 'unit': 738,\n"," 'thing': 739,\n"," 'during': 740,\n"," 'estimation': 741,\n"," 'ab': 742,\n"," 'contains': 743,\n"," 'basically': 744,\n"," 'st': 745,\n"," 'align': 746,\n"," 'months': 747,\n"," 'normally': 748,\n"," 'follow': 749,\n"," 'future': 750,\n"," 'array': 751,\n"," 'female': 752,\n"," 'advice': 753,\n"," 'mathcal': 754,\n"," 'measures': 755,\n"," 'roc': 756,\n"," 'vec': 757,\n"," 'income': 758,\n"," 'others': 759,\n"," 'isn': 760,\n"," 'forecasting': 761,\n"," 'default': 762,\n"," 'packages': 763,\n"," 'further': 764,\n"," 'pattern': 765,\n"," 'returns': 766,\n"," 'changes': 767,\n"," 'covariates': 768,\n"," 'write': 769,\n"," 'asked': 770,\n"," 'squares': 771,\n"," 'randomly': 772,\n"," 'bayes': 773,\n"," 'prob': 774,\n"," 'temp': 775,\n"," 'finding': 776,\n"," 'overall': 777,\n"," 'corresponding': 778,\n"," 'initial': 779,\n"," 'multinomial': 780,\n"," 'bayesian': 781,\n"," 'res': 782,\n"," 'exponential': 783,\n"," 'useful': 784,\n"," 'iterations': 785,\n"," 'ran': 786,\n"," 'measured': 787,\n"," 'four': 788,\n"," 'stats': 789,\n"," 'predicting': 790,\n"," 'exact': 791,\n"," 'generated': 792,\n"," 'situation': 793,\n"," 'sort': 794,\n"," 'monthly': 795,\n"," 'pretty': 796,\n"," 'probably': 797,\n"," 'll': 798,\n"," 'students': 799,\n"," 'research': 800,\n"," 'including': 801,\n"," 'naive': 802,\n"," 'rho': 803,\n"," 'represent': 804,\n"," 'glmnet': 805,\n"," 'plots': 806,\n"," 'sequence': 807,\n"," 'image': 808,\n"," 'measurements': 809,\n"," 'once': 810,\n"," 'put': 811,\n"," 'ln': 812,\n"," 'cluster': 813,\n"," 'uses': 814,\n"," 'ml': 815,\n"," 'th': 816,\n"," 'implement': 817,\n"," 'past': 818,\n"," 'mixed': 819,\n"," 'types': 820,\n"," 'ordinal': 821,\n"," 'compared': 822,\n"," 'hidden': 823,\n"," 'season': 824,\n"," 'combination': 825,\n"," 'covariance': 826,\n"," 'ask': 827,\n"," 'although': 828,\n"," 'uniform': 829,\n"," 'steps': 830,\n"," 'risk': 831,\n"," 'np': 832,\n"," 'answers': 833,\n"," 'cov': 834,\n"," 'says': 835,\n"," 'applied': 836,\n"," 'project': 837,\n"," 'created': 838,\n"," 'choice': 839,\n"," 'relative': 840,\n"," 'hand': 841,\n"," 'raw': 842,\n"," 'valid': 843,\n"," 'head': 844,\n"," 'species': 845,\n"," 'gradient': 846,\n"," 'called': 847,\n"," 'num': 848,\n"," 'whole': 849,\n"," 'easy': 850,\n"," 'associated': 851,\n"," 'selected': 852,\n"," 'larger': 853,\n"," 'perhaps': 854,\n"," 'match': 855,\n"," 'site': 856,\n"," 'dots': 857,\n"," 'tau': 858,\n"," 'o': 859,\n"," 'obs': 860,\n"," 'among': 861,\n"," 'techniques': 862,\n"," 'expect': 863,\n"," 'nrow': 864,\n"," 'back': 865,\n"," 'top': 866,\n"," 'transform': 867,\n"," 'common': 868,\n"," 'comes': 869,\n"," 'file': 870,\n"," 'omega': 871,\n"," 'dv': 872,\n"," 'adding': 873,\n"," 'regarding': 874,\n"," 'auc': 875,\n"," 'wanted': 876,\n"," 'optimal': 877,\n"," 'scaled': 878,\n"," 'survival': 879,\n"," 'comparing': 880,\n"," 'modeling': 881,\n"," 'regressions': 882,\n"," 'define': 883,\n"," 'quad': 884,\n"," 'knowledge': 885,\n"," 'building': 886,\n"," 'importance': 887,\n"," 'context': 888,\n"," 'fold': 889,\n"," 'approaches': 890,\n"," 'game': 891,\n"," 'weighted': 892,\n"," 'outliers': 893,\n"," 'reject': 894,\n"," 'obviously': 895,\n"," 'hope': 896,\n"," 'various': 897,\n"," 'status': 898,\n"," 'present': 899,\n"," 'additional': 900,\n"," 'customer': 901,\n"," 'estimator': 902,\n"," 'background': 903,\n"," 'takes': 904,\n"," 'added': 905,\n"," 'specifically': 906,\n"," 'www': 907,\n"," 'box': 908,\n"," 'own': 909,\n"," 'individuals': 910,\n"," 'otherwise': 911,\n"," 'component': 912,\n"," 'keep': 913,\n"," 'self': 914,\n"," 'assumptions': 915,\n"," 'interest': 916,\n"," 'ma': 917,\n"," 'components': 918,\n"," 'subjects': 919,\n"," 'require': 920,\n"," 'attributes': 921,\n"," 'highly': 922,\n"," 'suggested': 923,\n"," 'root': 924,\n"," 'greatly': 925,\n"," 'interpretation': 926,\n"," 'axis': 927,\n"," 'states': 928,\n"," 'included': 929,\n"," 'often': 930,\n"," 'implementation': 931,\n"," 'hence': 932,\n"," 'remove': 933,\n"," 'option': 934,\n"," 'patients': 935,\n"," 'separate': 936,\n"," 'fisher': 937,\n"," 'python': 938,\n"," 'theory': 939,\n"," 'considered': 940,\n"," 'explanation': 941,\n"," 'white': 942,\n"," 'identify': 943,\n"," 'trained': 944,\n"," 'window': 945,\n"," 'location': 946,\n"," 'almost': 947,\n"," 'kernel': 948,\n"," 'prices': 949,\n"," 'simulation': 950,\n"," 'unknown': 951,\n"," 'inputs': 952,\n"," 'great': 953,\n"," 'polynomial': 954,\n"," 'qu': 955,\n"," 'deal': 956,\n"," 'percentage': 957,\n"," 'autocorrelation': 958,\n"," 'balls': 959,\n"," 'overline': 960,\n"," 'outputs': 961,\n"," 'bootstrap': 962,\n"," 'improve': 963,\n"," 'wt': 964,\n"," 'none': 965,\n"," 'bias': 966,\n"," 'calculating': 967,\n"," 'reasonable': 968,\n"," 'limits': 969,\n"," 'evaluate': 970,\n"," 'usually': 971,\n"," 'posterior': 972,\n"," 'came': 973,\n"," 'upper': 974,\n"," 'pca': 975,\n"," 'relevant': 976,\n"," 'ideas': 977,\n"," 'fits': 978,\n"," 'users': 979,\n"," 'together': 980,\n"," 'items': 981,\n"," 'ci': 982,\n"," 'outcomes': 983,\n"," 'prove': 984,\n"," 'runif': 985,\n"," 'along': 986,\n"," 'unfortunately': 987,\n"," 'hour': 988,\n"," 'trials': 989,\n"," 'conditions': 990,\n"," 'randomforest': 991,\n"," 'message': 992,\n"," 'making': 993,\n"," 'lasso': 994,\n"," 'sub': 995,\n"," 'stat': 996,\n"," 'feel': 997,\n"," 'command': 998,\n"," 'le': 999,\n"," 'instances': 1000,\n"," ...}"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"Srz9RWKvVsm7","outputId":"21f03016-6943-433d-8117-75f0b189dba3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713501625135,"user_tz":-330,"elapsed":380,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["len(x_tokenizer.word_index)"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["25312"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"nQLwSve9VYqN"},"source":["There are around 25,000 tokens in the training dataset. Let's see how many tokens appear at least 5 times in the dataset."]},{"cell_type":"code","metadata":{"id":"H-d_UjVmPjgo","outputId":"abcaae03-7468-49d9-d5d5-e9a2e2854009","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713501650342,"user_tz":-330,"elapsed":371,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["thresh = 3\n","\n","cnt=0\n","for key,value in x_tokenizer.word_counts.items():\n","  if value>=thresh:\n","    cnt=cnt+1\n","\n","print(cnt)"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["12574\n"]}]},{"cell_type":"markdown","metadata":{"id":"3Eqly3dnVh-S"},"source":["Over 12,000 tokens have appeared three times or more in the training set.\n"]},{"cell_type":"markdown","source":["`num_words=cnt`: This specifies the maximum number of words to keep in the vocabulary, based on word frequency. Only the most common cnt words will be kept. If cnt is set, for instance, to 10000, then the tokenizer will only keep the top 10000 most frequent words in the corpus.\n","\n","`oov_token='unk'`: The oov_token parameter sets the token to represent all out-of-vocabulary words (OOV) during text-to-sequence conversion. When texts are converted to sequences, any word that is not found in the tokenizer's word index will be replaced with the oov_token. In this case, 'unk' will be used to represent all words that are not among the most frequent cnt words in the vocabulary (i.e., not in the top cnt words)."],"metadata":{"id":"v1gFwsh3Fy6m"}},{"cell_type":"markdown","source":["**Example**"],"metadata":{"id":"ppgslYuSGA-M"}},{"cell_type":"code","source":["# Assume the vocabulary only has the words 'hello' and 'world'\n","# with the indices 1 and 2, respectively. Let's also assume 'cnt' was set to 2.\n","\n","x_tokenizer = Tokenizer(num_words=2, oov_token='unk')\n","\n","# Fit the tokenizer on some text\n","x_tokenizer.fit_on_texts(['hello world', 'hello unknown world'])\n","\n","# Now convert text to sequences\n","sequences = x_tokenizer.texts_to_sequences(['hello unknown world'])\n","\n","print(sequences) # Output might look like: [[1, 'unk', 2]]\n"],"metadata":{"id":"6M7JiscFF8w9"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZrJnr-dItPn","executionInfo":{"status":"ok","timestamp":1713501733140,"user_tz":-330,"elapsed":1365,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# prepare the tokenizer again\n","#\n","\n","x_tokenizer = Tokenizer(num_words=cnt,oov_token='unk') #\n","\n","#prepare vocabulary\n","x_tokenizer.fit_on_texts(x_tr)"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MJFfvLDJWZbb"},"source":["Now that we have encoded every token to an integer, let's convert the text sequences to integer sequences. After that we will pad the integer sequences to the maximum sequence length, i.e., 100."]},{"cell_type":"code","metadata":{"id":"VpJvPYx5WR07","executionInfo":{"status":"ok","timestamp":1713501767528,"user_tz":-330,"elapsed":2141,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# maximum sequence length allowed\n","max_len = 100\n","\n","#convert text sequences into integer sequences\n","x_tr_seq = x_tokenizer.texts_to_sequences(x_tr)\n","x_val_seq = x_tokenizer.texts_to_sequences(x_val)\n","\n","#padding up with zero\n","x_tr_seq = pad_sequences(x_tr_seq,  padding='post', maxlen=max_len)\n","x_val_seq = pad_sequences(x_val_seq, padding='post', maxlen=max_len)"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6TkeQpLgXled"},"source":["Since we are padding the sequences with zeros, we must increment the vocabulary size by one."]},{"cell_type":"code","metadata":{"id":"Q4na29hBItes","outputId":"7b18628b-e905-4451-8b2a-ef3e5cac6fef","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713501773967,"user_tz":-330,"elapsed":341,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["#no. of unique words\n","x_voc_size = x_tokenizer.num_words + 1\n","x_voc_size"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12575"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"A9jdhRc_O12J","outputId":"ec8c3bf2-dfb9-4c1a-fdd3-c365e22d6da4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713501786011,"user_tz":-330,"elapsed":367,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["x_tr_seq[0]"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1953, 5711,  416, 2023,    1,  226, 1747, 3740,  609,   43,  181,\n","       1953,  372,   19,  100,  416,    9, 1747, 3839,  238,   27,   27,\n","         27,   27,   27,   70,    6, 6919,    8, 1163,   70,    6,   43,\n","         43, 1802, 1802, 1802,   36,   36,   36,   36, 4308, 5410,    4,\n","        124,  592,  107,   22,    2, 1747, 4065,   27,   10, 1309,   10,\n","       6414,   10,  190,   10,  416,   10,   27,   10, 1309,   10, 6414,\n","         10,  190,   10,  416,   10,  456,  139,   15,    7,    2, 4610,\n","        164,   27,   10, 1309,   10, 6414,   10,  190,   10,  416,   10,\n","         27,   76,   27, 1309,   76,   27, 6414,   76,   27,  190,   76,\n","         27], dtype=int32)"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"FOrVSzzmP3PX"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tkl63yImP3KQ"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R30CSTInP2KP"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lrd9DP-eP2Iu"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9tneme__P2EX"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ykBa719UP1_E"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BCtPnSrsscN1"},"source":["# Model Building"]},{"cell_type":"code","metadata":{"id":"RrRgqQ4M8OZu","executionInfo":{"status":"ok","timestamp":1713501869768,"user_tz":-330,"elapsed":368,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["from keras.models import *\n","from keras.layers import *\n","from keras.callbacks import *"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wxE6IK3Uic-d"},"source":["### Define Model Architecture"]},{"cell_type":"code","metadata":{"id":"vHtamwcMkVcr","executionInfo":{"status":"ok","timestamp":1713501996051,"user_tz":-330,"elapsed":1853,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["#sequential model\n","model = Sequential()\n","\n","#embedding layer\n","model.add(Embedding(x_voc_size, 50, input_shape=(max_len,), mask_zero=True))\n","\n","#rnn layer\n","model.add(SimpleRNN(128,activation='relu'))\n","\n","#dense layer\n","model.add(Dense(128,activation='relu'))\n","\n","#output layer\n","model.add(Dense(10,activation='sigmoid')) # Sigmoid for multilable"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2wd26r0y3n4c"},"source":["Understand the output shape and no. of parameters of each layer:"]},{"cell_type":"code","metadata":{"id":"6K14UgT--fCk","outputId":"3bab1b3e-5833-4fa1-95ec-6361e327c989","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713501999805,"user_tz":-330,"elapsed":369,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["model.summary()"],"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 100, 50)           628750    \n","                                                                 \n"," simple_rnn (SimpleRNN)      (None, 128)               22912     \n","                                                                 \n"," dense (Dense)               (None, 128)               16512     \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 669464 (2.55 MB)\n","Trainable params: 669464 (2.55 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZGk0ELGi3yjx"},"source":["Define the optimizer and loss:"]},{"cell_type":"code","metadata":{"id":"tzRoTFVIItjK","executionInfo":{"status":"ok","timestamp":1713502012869,"user_tz":-330,"elapsed":344,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["#define optimizer and loss\n","model.compile(optimizer='adam',loss='binary_crossentropy')"],"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N4w6YHUD4BC1"},"source":["Define a callback - Model Checkpoint. Model Checkpoint is a callback used to save the best model during training."]},{"cell_type":"code","metadata":{"id":"OpomosTF4AKW","executionInfo":{"status":"ok","timestamp":1713502041064,"user_tz":-330,"elapsed":368,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# checkpoint to save best model during training\n","mc = ModelCheckpoint(\"weights.best.hdf5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"80gtKbElii0e"},"source":["### Train the Model\n","\n","Lets train the model for 10 epochs with a batch size of 128:"]},{"cell_type":"code","metadata":{"id":"XH8ggzcdkzkL","outputId":"15059fc1-5287-4d0d-c8aa-5b3c749764a7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713502210967,"user_tz":-330,"elapsed":161640,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["#train the model\n","model.fit(x_tr_seq, y_tr, batch_size=128, epochs=10, verbose=1, validation_data=(x_val_seq, y_val), callbacks=[mc])"],"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","70/70 [==============================] - ETA: 0s - loss: 0.5237\n","Epoch 1: val_loss improved from inf to 0.47928, saving model to weights.best.hdf5\n","70/70 [==============================] - 26s 300ms/step - loss: 0.5237 - val_loss: 0.4793\n","Epoch 2/10\n"," 1/70 [..............................] - ETA: 8s - loss: 0.4626"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["70/70 [==============================] - ETA: 0s - loss: 0.4700\n","Epoch 2: val_loss did not improve from 0.47928\n","70/70 [==============================] - 17s 249ms/step - loss: 0.4700 - val_loss: 0.4887\n","Epoch 3/10\n","70/70 [==============================] - ETA: 0s - loss: 0.4501\n","Epoch 3: val_loss improved from 0.47928 to 0.44821, saving model to weights.best.hdf5\n","70/70 [==============================] - 16s 235ms/step - loss: 0.4501 - val_loss: 0.4482\n","Epoch 4/10\n","70/70 [==============================] - ETA: 0s - loss: 0.4000\n","Epoch 4: val_loss improved from 0.44821 to 0.41587, saving model to weights.best.hdf5\n","70/70 [==============================] - 15s 209ms/step - loss: 0.4000 - val_loss: 0.4159\n","Epoch 5/10\n","70/70 [==============================] - ETA: 0s - loss: 0.3723\n","Epoch 5: val_loss did not improve from 0.41587\n","70/70 [==============================] - 15s 211ms/step - loss: 0.3723 - val_loss: 0.4247\n","Epoch 6/10\n","70/70 [==============================] - ETA: 0s - loss: 0.3397\n","Epoch 6: val_loss did not improve from 0.41587\n","70/70 [==============================] - 14s 206ms/step - loss: 0.3397 - val_loss: 0.4176\n","Epoch 7/10\n","70/70 [==============================] - ETA: 0s - loss: 0.3188\n","Epoch 7: val_loss improved from 0.41587 to 0.39823, saving model to weights.best.hdf5\n","70/70 [==============================] - 16s 225ms/step - loss: 0.3188 - val_loss: 0.3982\n","Epoch 8/10\n","70/70 [==============================] - ETA: 0s - loss: 0.2852\n","Epoch 8: val_loss did not improve from 0.39823\n","70/70 [==============================] - 13s 187ms/step - loss: 0.2852 - val_loss: 0.4145\n","Epoch 9/10\n","70/70 [==============================] - ETA: 0s - loss: 0.3031\n","Epoch 9: val_loss did not improve from 0.39823\n","70/70 [==============================] - 16s 232ms/step - loss: 0.3031 - val_loss: 0.4215\n","Epoch 10/10\n","70/70 [==============================] - ETA: 0s - loss: 0.2516\n","Epoch 10: val_loss did not improve from 0.39823\n","70/70 [==============================] - 13s 188ms/step - loss: 0.2516 - val_loss: 0.4262\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x783429df88b0>"]},"metadata":{},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"JDzen8xvioUd"},"source":["# Model Predictions\n","\n","Load the best model weights and now, the model is ready for the predictions"]},{"cell_type":"code","metadata":{"id":"xL8qz8zvDvpH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713502237528,"user_tz":-330,"elapsed":1649,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}},"outputId":"f31a7fa8-d4fe-4cc5-ea5b-d0c942ebf816"},"source":["# load weights into new model\n","model.load_weights(\"weights.best.hdf5\")\n","\n","#predict probabilities\n","pred_prob = model.predict(x_val_seq)"],"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["70/70 [==============================] - 1s 13ms/step\n"]}]},{"cell_type":"code","metadata":{"id":"AUF5H7bIlRLr","outputId":"3377ed62-4af8-472a-e9f6-b9c44b17d956","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713502242772,"user_tz":-330,"elapsed":3,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["pred_prob[0]"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.05206481, 0.02697627, 0.05701637, 0.00923064, 0.1429621 ,\n","       0.00366715, 0.6580425 , 0.2327607 , 0.03503307, 0.714599  ],\n","      dtype=float32)"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"ph2xAWbFjLv5"},"source":["The predictions are in terms of probabilities for each of the 10 tags. Hence we need to have a threshold value to convert these probabilities to 0 or 1.\n","\n","Let's specify a set of candidate threshold values. We will select the threshold value that performs the best for the validation set."]},{"cell_type":"code","metadata":{"id":"5hYDCTKXguMF","outputId":"ac345155-6be0-499e-f95d-b8b068f31552","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713502308159,"user_tz":-330,"elapsed":384,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["#define candidate threshold values\n","threshold  = np.arange(0,0.5,0.01)\n","threshold"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n","       0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n","       0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n","       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n","       0.44, 0.45, 0.46, 0.47, 0.48, 0.49])"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","metadata":{"id":"NA6wMIewkICl"},"source":["Let's define a function that takes a threshold value and uses it to convert probabilities into 1 or 0."]},{"cell_type":"code","metadata":{"id":"aay56TvDGPoX","executionInfo":{"status":"ok","timestamp":1713502318420,"user_tz":-330,"elapsed":2,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# convert probabilities into classes or tags based on a threshold value\n","def classify(pred_prob,thresh):\n","  y_pred_seq = []\n","\n","  for i in pred_prob:\n","    temp=[]\n","    for j in i:\n","      if j>=thresh:\n","        temp.append(1)\n","      else:\n","        temp.append(0)\n","    y_pred_seq.append(temp)\n","\n","  return y_pred_seq"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"s0auJJmNDtv9","executionInfo":{"status":"ok","timestamp":1713502322671,"user_tz":-330,"elapsed":1346,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["from sklearn import metrics\n","score=[]\n","\n","#convert to 1 array\n","y_true = np.array(y_val).ravel()\n","\n","for thresh in threshold:\n","\n","    #classes for each threshold\n","    y_pred_seq = classify(pred_prob,thresh)\n","\n","    #convert to 1d array\n","    y_pred = np.array(y_pred_seq).ravel()\n","\n","    score.append(metrics.f1_score(y_true,y_pred))"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"id":"jrA8nJIGVBsl","outputId":"ed340280-82a1-4923-ba2a-a1ef7d79f09d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713502325198,"user_tz":-330,"elapsed":4,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["# find the optimal threshold\n","opt = threshold[score.index(max(score))]\n","opt"],"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.27"]},"metadata":{},"execution_count":50}]},{"cell_type":"markdown","metadata":{"id":"UF1mHdE3rjVu"},"source":["# Model Evaluation"]},{"cell_type":"code","metadata":{"id":"_74ujVjmVlcT","executionInfo":{"status":"ok","timestamp":1713502329930,"user_tz":-330,"elapsed":343,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["#predictions for optimal threshold\n","y_pred_seq = classify(pred_prob,opt)\n","y_pred = np.array(y_pred_seq).ravel()"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"9LKB6W7tItUm","outputId":"7b079373-6cf7-477f-b647-880b825e51ef","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713502332842,"user_tz":-330,"elapsed":356,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["print(metrics.classification_report(y_true,y_pred))"],"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.90      0.85      0.87     17520\n","           1       0.53      0.64      0.58      4700\n","\n","    accuracy                           0.80     22220\n","   macro avg       0.71      0.74      0.72     22220\n","weighted avg       0.82      0.80      0.81     22220\n","\n"]}]},{"cell_type":"code","metadata":{"id":"tzQsUoEV7ldm"},"source":["y_pred = mlb.inverse_transform(np.array(y_pred_seq))\n","y_true = mlb.inverse_transform(np.array(y_val))\n","\n","df = pd.DataFrame({'comment':x_val,'actual':y_true,'predictions':y_pred})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"plf_uclDlxwL","outputId":"4620ff00-cd29-4acc-a26b-1e053a2b2c53","colab":{"base_uri":"https://localhost:8080/","height":536},"executionInfo":{"status":"ok","timestamp":1712915259033,"user_tz":-330,"elapsed":4,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["df.sample(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                                                                                                                                                      comment  \\\n","899   could you help me i have been looking everywhere for an answer to this question it does not seem as straightfoward as running anovas in r i want to test for equality of variances between four grou...   \n","2200  i have binary count data as a response variable in my logistic regression the independent variables include among others two variables of inclination and orientation measurements annotated in degr...   \n","1649  one way to find accuracy of the logistic regression model using glm is to find auc plot how to check the same for regression model found with continuous response variable family gaussian what meth...   \n","1798  is the predictor function in logistic regression a function of the dot product of the parameter vector and the feature vector onto a real value between zero and one if i m getting dot products out...   \n","1108  as far as i know i have two options for tests in linear regression the f test for the model if it explains more variance than it has error variance and the t test to see if the slope is not zero w...   \n","1198  i would like to test if subjects are significantly more or less accurate under some experimental conditions at first i thought it s a job for anova for repeated measures but i am not sure anymore ...   \n","2073  let s say i m using the sonar data and i d like to make a hold out validation in r i partitioned the data using the createfolds from caret package as folds createfolds mydata class k i would like ...   \n","1902  for a project for which there are multiple bidders the following is known number of bidders mean bid highest bid lowest bid given the above is it possible however roughly to estimate i the number ...   \n","2198  i m currently working on a wildlife research problem where i evaluated animal habitat selection as a function of distance to landscape features types e g distance to shrub scrub i used a logistic ...   \n","2196  as you know one can use regression for inference to learn which variables correlate with a response variable if the input predictors and the response share the same time frame let s say a predicto...   \n","\n","                                     actual  \\\n","899                 (hypothesis testing, r)   \n","2200              (logistic, r, regression)   \n","1649                        (r, regression)   \n","1798                 (logistic, regression)   \n","1108       (hypothesis testing, regression)   \n","1198         (hypothesis testing, logistic)   \n","2073  (classification, machine learning, r)   \n","1902           (distributions, probability)   \n","2198                 (logistic, regression)   \n","2196                       (r, time series)   \n","\n","                                            predictions  \n","899                           (logistic, r, regression)  \n","2200                          (logistic, r, regression)  \n","1649                          (logistic, r, regression)  \n","1798     (classification, machine learning, regression)  \n","1108                                      (regression,)  \n","1198  (classification, machine learning, r, regression)  \n","2073                  (machine learning, r, regression)  \n","1902           (distributions, probability, self study)  \n","2198                 (machine learning, r, time series)  \n","2196                                    (r, regression)  "],"text/html":["\n","  <div id=\"df-9f1209af-6c8e-4199-8b9e-b39facc0bfda\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment</th>\n","      <th>actual</th>\n","      <th>predictions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>899</th>\n","      <td>could you help me i have been looking everywhere for an answer to this question it does not seem as straightfoward as running anovas in r i want to test for equality of variances between four grou...</td>\n","      <td>(hypothesis testing, r)</td>\n","      <td>(logistic, r, regression)</td>\n","    </tr>\n","    <tr>\n","      <th>2200</th>\n","      <td>i have binary count data as a response variable in my logistic regression the independent variables include among others two variables of inclination and orientation measurements annotated in degr...</td>\n","      <td>(logistic, r, regression)</td>\n","      <td>(logistic, r, regression)</td>\n","    </tr>\n","    <tr>\n","      <th>1649</th>\n","      <td>one way to find accuracy of the logistic regression model using glm is to find auc plot how to check the same for regression model found with continuous response variable family gaussian what meth...</td>\n","      <td>(r, regression)</td>\n","      <td>(logistic, r, regression)</td>\n","    </tr>\n","    <tr>\n","      <th>1798</th>\n","      <td>is the predictor function in logistic regression a function of the dot product of the parameter vector and the feature vector onto a real value between zero and one if i m getting dot products out...</td>\n","      <td>(logistic, regression)</td>\n","      <td>(classification, machine learning, regression)</td>\n","    </tr>\n","    <tr>\n","      <th>1108</th>\n","      <td>as far as i know i have two options for tests in linear regression the f test for the model if it explains more variance than it has error variance and the t test to see if the slope is not zero w...</td>\n","      <td>(hypothesis testing, regression)</td>\n","      <td>(regression,)</td>\n","    </tr>\n","    <tr>\n","      <th>1198</th>\n","      <td>i would like to test if subjects are significantly more or less accurate under some experimental conditions at first i thought it s a job for anova for repeated measures but i am not sure anymore ...</td>\n","      <td>(hypothesis testing, logistic)</td>\n","      <td>(classification, machine learning, r, regression)</td>\n","    </tr>\n","    <tr>\n","      <th>2073</th>\n","      <td>let s say i m using the sonar data and i d like to make a hold out validation in r i partitioned the data using the createfolds from caret package as folds createfolds mydata class k i would like ...</td>\n","      <td>(classification, machine learning, r)</td>\n","      <td>(machine learning, r, regression)</td>\n","    </tr>\n","    <tr>\n","      <th>1902</th>\n","      <td>for a project for which there are multiple bidders the following is known number of bidders mean bid highest bid lowest bid given the above is it possible however roughly to estimate i the number ...</td>\n","      <td>(distributions, probability)</td>\n","      <td>(distributions, probability, self study)</td>\n","    </tr>\n","    <tr>\n","      <th>2198</th>\n","      <td>i m currently working on a wildlife research problem where i evaluated animal habitat selection as a function of distance to landscape features types e g distance to shrub scrub i used a logistic ...</td>\n","      <td>(logistic, regression)</td>\n","      <td>(machine learning, r, time series)</td>\n","    </tr>\n","    <tr>\n","      <th>2196</th>\n","      <td>as you know one can use regression for inference to learn which variables correlate with a response variable if the input predictors and the response share the same time frame let s say a predicto...</td>\n","      <td>(r, time series)</td>\n","      <td>(r, regression)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f1209af-6c8e-4199-8b9e-b39facc0bfda')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9f1209af-6c8e-4199-8b9e-b39facc0bfda button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9f1209af-6c8e-4199-8b9e-b39facc0bfda');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-8668ece3-af73-4390-80b5-8936b0956a41\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8668ece3-af73-4390-80b5-8936b0956a41')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-8668ece3-af73-4390-80b5-8936b0956a41 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"comment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"i m currently working on a wildlife research problem where i evaluated animal habitat selection as a function of distance to landscape features types e g distance to shrub scrub i used a logistic regression framework where my response variable is random telemetry locations used or animal locations i m essentially modeling non random habitat selection as a function of used animal locations and their distance to habitat features relative to random locations and their distances generated on the landscape my mixed effects model is as follows results glmer r a season mp scaled season mphw scaled season hw scaled season yp scaled season ag scaled season ss scaled site id data turkey nd family binomial season is a categorical variable a fall winter b spring c summer and is interacting with each habitat type to assess differences in selection based on each season in other words does distance to mature pine change from fall winter spring and summer i also included a random effect for animal id to account for variation among individual animals as some animals have more or less used locations compared to others in the data set see also gillies et al after running the model i would now like to output predictive probability estimates for each habitat type and season in other words what is the predictive probability of use of shrub scrub stands during the spring season obviously all other variables must be held constant to achieve this goal but i m struggling to find a way to achieve my goal i tried the following code based on a series of internet searches prediction predict results type response however this provides predictions for all my observations in my data set rows or probability values i really need to fix all other variables constant and then predict across a range of distance values for each habitat type e g shrub scrub within a specific season e g spring additionally i would like to create predictive graphs to illustrate the probability of selection based on a specified set of distances is there an easy way to do this i wasn t sure if the random effect would influence the probability estimates in anyway either i would greatly appreciate any insight on this problem\",\n          \"i have binary count data as a response variable in my logistic regression the independent variables include among others two variables of inclination and orientation measurements annotated in degrees of arc for orientation or aspect it ranges from to and for inclination from to in cases where inclination is the orientation is annotated as because horizontal surfaces do not face any direction for a logistic regression my workflow would include to use r s scale function to standardize all continuous variables among them inclination and orientation and that is what i did but does that make sense here keep in mind that an orientation of north is the same as also north and that and are only two degrees apart how can i standardize those measurements how would you recode an orientation of which isn t either north nor east south or west at this point both variables appear to be highly influential on my model fit but can i trust that conclusion\",\n          \"i would like to test if subjects are significantly more or less accurate under some experimental conditions at first i thought it s a job for anova for repeated measures but i am not sure anymore experiment goes like this there are experimental conditions every subject perform multiple trials of the task under each condition for each trial he can be either correct or not i would like to see if some conditions make the task harder so there is a different proportion of correct c vs noncorrect n trials subject condition condition condition condition cccnnncccnc cncnnncccnn ccccnnncncn cccccnnnccc cccnncncncn cncncnncnnn cnnncnccnnn cccncncncnc ccncncncncn cnncncncnnc cncnnnccnnc cnncncncnnc i don t think that anova is a valid test because the the mean accuracy per subject per condition comes from binomial count data i read about chi squared and cochran s q test for binomial data but i don t have only binary true false for each subject and condition but accuracy rate i also read suggestion for a logistic regression but i don t know if that would be appropriate either and how to use it with repeated measures can i use anova for repeated measures if not why not and what would happen if i do and what test is more appropriate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actual\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          [\n            \"distributions\",\n            \"probability\"\n          ],\n          [\n            \"logistic\",\n            \"r\",\n            \"regression\"\n          ],\n          [\n            \"hypothesis testing\",\n            \"logistic\"\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predictions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          [\n            \"classification\",\n            \"machine learning\",\n            \"regression\"\n          ],\n          [\n            \"distributions\",\n            \"probability\",\n            \"self study\"\n          ],\n          [\n            \"logistic\",\n            \"r\",\n            \"regression\"\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":72}]},{"cell_type":"markdown","metadata":{"id":"K868o9U3H5u0"},"source":["### Inference"]},{"cell_type":"code","metadata":{"id":"xG_KIc1xhl2V"},"source":["def predict_tag(comment):\n","  text=[]\n","\n","  #preprocess\n","  text = [cleaner(comment)]\n","\n","  #convert to integer sequences\n","  seq = x_tokenizer.texts_to_sequences(text)\n","\n","  #pad the sequence\n","  pad_seq = pad_sequences(seq,  padding='post', maxlen=max_len)\n","\n","  #make predictions\n","  pred_prob = model.predict(pad_seq)\n","  classes = classify(pred_prob,opt)[0]\n","\n","  classes = np.array([classes])\n","  classes = mlb.inverse_transform(classes)\n","  return classes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Al3kfEgEYhU","outputId":"b816cfdb-dc21-4ce3-c555-537a642e4942","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712915266693,"user_tz":-330,"elapsed":580,"user":{"displayName":"Milan Joshi","userId":"13016873222319412216"}}},"source":["comment = \"For example, in the case of logistic regression, the learning function is a Sigmoid function that tries to separate the 2 classes\"\n","\n","print(\"Comment:\",comment)\n","print(\"Predicted Tags:\",predict_tag(comment))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Comment: For example, in the case of logistic regression, the learning function is a Sigmoid function that tries to separate the 2 classes\n","1/1 [==============================] - 0s 68ms/step\n","Predicted Tags: [('classification', 'logistic', 'machine learning', 'regression')]\n"]}]},{"cell_type":"code","metadata":{"id":"kUSrb3nE-r6S"},"source":[],"execution_count":null,"outputs":[]}]}