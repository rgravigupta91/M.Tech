{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71dfee7b",
   "metadata": {},
   "source": [
    "# Step-by-Step Guide to Building a Neural Network Model in Keras\n",
    "\n",
    "In this guide, we will build a simple neural network model using Keras. Each step will be explained in detail.\n",
    "\n",
    "### Step 1: Import Necessary Libraries\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "```\n",
    "### Or\n",
    "```python\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631ed9d3",
   "metadata": {},
   "source": [
    "```python\n",
    "# Set the random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "```\n",
    "\n",
    "- `np.random.seed(42)`: Controls the random number generation in NumPy. This affects operations like generating random arrays with `np.random.rand()`, shuffling, etc.\n",
    "\n",
    "<br>\n",
    "\n",
    "- `tf.random.set_seed(42)`: Controls the random number generation in TensorFlow/Keras. This affects operations like **initializing weights** in neural networks, applying random **dropout**, and other random operations within TensorFlow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f062a",
   "metadata": {},
   "source": [
    "# Step 2: Generate or Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d668b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the csv file\n",
    "data = pd.read_csv('Dataset/emergency_classification.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9677da",
   "metadata": {},
   "source": [
    "# Step 2 a Create train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c999f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a training and validation set\n",
    "X_train, X_valid, y_train, y_valid=train_test_split(X,y,test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cca580",
   "metadata": {},
   "source": [
    "### Building a Model instance with sequential class in keras and accessing methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7299be09",
   "metadata": {},
   "source": [
    "``` python\n",
    "model = Sequential()  # Initializes a Sequential model, which is a linear stack of layers\n",
    "\n",
    "model.add(Dense())  # Adds a dense (fully connected) layer to the model; requires parameters such as units, activation function, input shape, etc.\n",
    "\n",
    "model.compile()  # Configures the model for training by specifying the optimizer, loss function, and evaluation metrics\n",
    "\n",
    "model.fit()  # Trains the model on the training data for a fixed number of epochs, adjusting weights to minimize the loss function\n",
    "\n",
    "model.evaluate()  # Evaluates the trained model on a test dataset, returning the loss and metrics specified during compile\n",
    "\n",
    "model.predict()  # Generates output predictions from the model based on input data; used for inference after the model is trained\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f33e05d",
   "metadata": {},
   "source": [
    "# Step 3: Define the Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367c3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Input Layer with 3 neurons (R^3)\n",
    "model.add(Input(shape=(32,)))  \n",
    "\n",
    "# First hidden layer with 5 neurons (R^5)\n",
    "model.add(Dense(16, activation='relu'))  # First hidden layer with 5 neurons\n",
    "\n",
    "# Output layer with 1 neuron (R^1)\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer with 1 neuron\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a0a70",
   "metadata": {},
   "source": [
    "### Shape\n",
    "``` python\n",
    "shape = () # tuple\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825d10b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input(shape=(64, 64, 3))   # 64x64 image with 3 color channels (RGB)\n",
    "Input(shape=(60, 128, 128, 3))  # 60 frames, each 128x128 pixels, 3 channels (RGB)\n",
    "Input(shape=(10, 3))  # 10 timesteps, 3 features per timestep\n",
    "# In MLP we faltten images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985911bf",
   "metadata": {},
   "source": [
    "### Can directly start with `dense()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58cefb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Adding layers to the model\n",
    "model.add(Dense(32, input_dim=20, activation='relu'))  # Input layer and first hidden layer\n",
    "model.add(Dense(16, activation='relu'))  # Second hidden layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca9c90",
   "metadata": {},
   "source": [
    "# Step 4: Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9389227",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a10e2ed",
   "metadata": {},
   "source": [
    "# Step5: Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f46166",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train,epoch = 32,batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebbdfb9",
   "metadata": {},
   "source": [
    "# Step 6: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9952f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973cbb11",
   "metadata": {},
   "source": [
    "# Step 7: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239d89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(predictions[:5])  # Print the first 5 predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b5481a",
   "metadata": {},
   "source": [
    "# Explanation of Parameters in `Dense()` Layer\n",
    "\n",
    "The `Dense` layer in Keras is a fully connected layer, where every neuron in the layer is connected to every neuron in the previous layer. Here's a detailed explanation of the parameters used in the `Dense()` layer:\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80fd312",
   "metadata": {},
   "source": [
    "### `kernel_regularizer` (optional):\n",
    "\n",
    "**Description**: Regularizer function applied to the kernel weights matrix. Regularization helps prevent overfitting by penalizing large weights.\n",
    "\n",
    "**Common Regularizers**:\n",
    "- **`l1`**: L1 regularization adds a penalty equal to the absolute value of the weights.\n",
    "- **`l2`**: L2 regularization (also known as weight decay) adds a penalty equal to the square of the weights.\n",
    "- **`l1_l2`**: Combines both L1 and L2 regularization.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras import regularizers\n",
    "Dense(64, kernel_regularizer=regularizers.l2(0.01))\n",
    "```\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "Dense(64, kernel_constraint=max_norm(2.0))\n",
    "```\n",
    "\n",
    "```python\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "model.add(Dense(64, \n",
    "                activation='relu', \n",
    "                use_bias=True, \n",
    "                kernel_initializer='he_normal', \n",
    "                bias_initializer='ones', \n",
    "                kernel_regularizer=regularizers.l2(0.01), \n",
    "                bias_regularizer=regularizers.l2(0.01), \n",
    "                activity_regularizer=regularizers.l2(0.01), \n",
    "                kernel_constraint=max_norm(2.0)))\n",
    "```\n",
    "```pyton \n",
    "model.add(Dense(64, activation='relu',\n",
    "                kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a447531",
   "metadata": {},
   "source": [
    "# Understanding the `history` Object in Keras\n",
    "\n",
    "After training a model in Keras using the `model.fit()` function, a `history` object is returned. This object contains information about the training process, such as the values of the loss function and any metrics at each epoch. The `history` object can be used to analyze and visualize how the model performed over time.\n",
    "\n",
    "### Example\n",
    "\n",
    "```python\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    epochs=10, \n",
    "                    batch_size=32)\n",
    "```\n",
    "```history.history``` is a dictonary\n",
    "```\n",
    "{\n",
    "    'loss': [0.6932, 0.6874, 0.6819, ...],          # Training loss at each epoch\n",
    "    'accuracy': [0.50, 0.55, 0.60, ...],            # Training accuracy at each epoch (if specified in compile)\n",
    "    'val_loss': [0.6928, 0.6860, 0.6805, ...],      # Validation loss at each epoch (if validation data is provided)\n",
    "    'val_accuracy': [0.52, 0.57, 0.62, ...]         # Validation accuracy at each epoch (if validation data is provided)\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ca13c",
   "metadata": {},
   "source": [
    "``` python\n",
    "\n",
    "# Accessing the history attribute\n",
    "print(history.history.keys())\n",
    "\n",
    "# Access training loss\n",
    "print(history.history['loss'])\n",
    "\n",
    "# Access validation loss\n",
    "print(history.history['val_loss'])\n",
    "\n",
    "# Access training accuracy\n",
    "print(history.history['accuracy'])\n",
    "\n",
    "# Access validation accuracy\n",
    "print(history.history['val_accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edca2d94",
   "metadata": {},
   "source": [
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    epochs=10, \n",
    "                    batch_size=32)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedbee72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
