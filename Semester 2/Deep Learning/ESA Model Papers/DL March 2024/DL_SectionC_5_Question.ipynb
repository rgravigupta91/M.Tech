{"cells":[{"cell_type":"markdown","id":"41317547","metadata":{"id":"41317547"},"source":["###  END SEMESTER ASSESSMENT (ESA)\n","## M. TECH DATA SCIENCE AND MACHINE LEARNING_ SEMESTER II\n","\n","### UE20CS935 : Introduction to Deep Learning and Applications\n","\n","### Section C Q5"]},{"cell_type":"markdown","id":"58d5aa9b","metadata":{"id":"58d5aa9b"},"source":["#### Section C: Question 5:    (15 Marks)\n","\n","Develop a Semantic segmentation model using Unet architecture on the given dataset.\n","\n","Dataset contains the images and the corresponding masks. Find the dataset under the folder “Unet_Dataset”. Dataset contains the Chest X-ray images of Pneumothorax diseases and the corresponding masks.\n","\n","Students can make use of pre-trained Unet segmentation model using the library\n","\n","import segmentation_models as sm\n","\n","Hints :\n","    1. Load all the images in one array of size 96x128x128x1 Where 96 is total number of trained images 128x128x3 is each image size\n","    2. Load all the masks in one array of size 96x128x128x1\n","    3. Scale both the above two arrays\n","    4. Split the data into train and test\n","    5. Define the pre-trained segmentation model. Use encoder_weight=None, If internet access is not available.\n","    6. Compile with appropriate loss and metric and fit the data into it.\n","    7. Reduce the batch_size to 1 or 2, if you get any memory related error\n","    \n","Run the model for minimum 2 epochs and present your result. The solution will be evaluated based on approach only as it take lot of epochs to produce good result.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"cbef0860","metadata":{"id":"cbef0860","outputId":"9515e408-4147-4ea2-e2ed-362f374da53a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Segmentation Models: using `tf.keras` framework.\n"]}],"source":["import os\n","import cv2\n","from PIL import Image\n","import tensorflow as tf\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import segmentation_models as sm\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","from tensorflow.keras.utils import normalize"]},{"cell_type":"code","execution_count":null,"id":"466581f4","metadata":{"id":"466581f4"},"outputs":[],"source":["# hint : uncomment  below to fetch path\n","# image_dir='Unet_Dataset/CXR_png/'\n","# mask_dir='Unet_Dataset/masks/'"]},{"cell_type":"code","execution_count":null,"id":"e08ac511","metadata":{"id":"e08ac511"},"outputs":[],"source":["#Read all the data from both the folders X-ray images and mask images.\n","\n","# store the data in the following folders\n","# img_dataset=[]\n","# mask_dataset=[]\n","\n","\n","#Read the X-ray images and masks from the directories; hint: images=os.listdir(image_dir) and masks=os.listdir(mask_dir)\n","\n","#for i,image_name in enumerate(images):\n","#    if (image_name.split('.')[1]=='png'):\n","#       image=cv2.imread(image_dir+image_name,0)\n","#       image=Image.fromarray(image)\n","#       image=image.resize((SIZE,SIZE))\n","#       img_dataset.append(np.array(image))\n","\n","# Do the similar steps for masks, make sure your mask images are binary images."]},{"cell_type":"code","execution_count":null,"id":"2162f4ce","metadata":{"id":"2162f4ce"},"outputs":[],"source":["# convert the image data to array format and normalize/scale using (tensorflow.keras.utils.normalize()) function or (image data/255.)"]},{"cell_type":"code","execution_count":null,"id":"f52fa3ec","metadata":{"id":"f52fa3ec"},"outputs":[],"source":["# split the data into train test with following specifications\n","#Hint: train_test_split(img_dataset,mask_dataset,test_size=0.20,random_state=0)\n"]},{"cell_type":"code","execution_count":null,"id":"dc7ae027","metadata":{"id":"dc7ae027"},"outputs":[],"source":["#take the pre-trained model as resnet34 and do pre-processing\n","BACKBONE = 'resnet34'\n","preprocess_input = sm.get_preprocessing(BACKBONE)"]},{"cell_type":"code","execution_count":null,"id":"7a49ab6d","metadata":{"id":"7a49ab6d"},"outputs":[],"source":["# use the preprocessed train input for model fitting\n","X_train_prepr = preprocess_input(x_train)\n","X_test_prepr = preprocess_input(x_test)"]},{"cell_type":"code","execution_count":null,"id":"c71b9031","metadata":{"id":"c71b9031"},"outputs":[],"source":["#load the Unet model using the below syntax\n","model= sm.Unet(BACKBONE, input_shape=(128,128,1),\n","                                encoder_weights=None, classes=1, activation='sigmoid')\n","# Model compilation with the following specifications\n","#Hint: optimizer='Adam'\n","#    loss=sm.losses.bce_jaccard_loss\n","#    metrics=[sm.metrics.iou_score])"]},{"cell_type":"code","execution_count":null,"id":"f87ae0a7","metadata":{"id":"f87ae0a7"},"outputs":[],"source":["# fit the model for X_train_prepr and y_train.\n","# use batch_size=2 and epochs=5 (maximum)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":5}