{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9rBkyxGvUwL"
   },
   "source": [
    "#### Section B: Question No:2   (10 marks)\n",
    "Build a Convolution Neural Network to classify 6 classes of chess game images.\n",
    "\n",
    "Conditions to consider:\n",
    "\n",
    "- Parameters should not cross 300000\n",
    "\n",
    "- Should not use more than 4 layers (except input and output, including convolution and dense layers)\n",
    "\n",
    "- Use Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2i1JVl8FvUwP"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SjGYHYQ6vUwQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "867-iFpmsb-o"
   },
   "outputs": [],
   "source": [
    "train_dir=\"chess/Train\"\n",
    "test_dir=\"Chess/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pAbR53o6xY9Y",
    "outputId": "66a6fea4-aaeb-44b2-91ae-2ed6c13dab38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 469 images belonging to 6 classes.\n",
      "Found 82 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1/255.)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "\n",
    "train_data=train_datagen.flow_from_directory(train_dir,\n",
    "                                             target_size=(128,128),\n",
    "                                             batch_size=32,\n",
    "                                             class_mode='categorical')\n",
    "\n",
    "test_data=test_datagen.flow_from_directory(test_dir,\n",
    "                                           target_size=(128,128),\n",
    "                                           batch_size=32,\n",
    "                                           class_mode='categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UdWXaAb2vUwR",
    "outputId": "a96b5e07-c542-45f5-c47f-7b5750161037"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LTwpaBQixc6i",
    "outputId": "4579245d-ad23-4f88-9e18-849cd3aab8fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 63, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14400)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 86406     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,174\n",
      "Trainable params: 89,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "base_model=Sequential([\n",
    "                    Conv2D(16, 3, activation='relu', input_shape=(128,128,3)),\n",
    "                    MaxPool2D(),\n",
    "                    Conv2D(16,3,activation='relu'),\n",
    "                    MaxPool2D(),\n",
    "                    Flatten(),\n",
    "                    Dense(6, activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "base_model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIKasHVmxgl6",
    "outputId": "d070b92b-e697-40b2-898a-78f4c2428d7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 9s 581ms/step - loss: 2.0199 - accuracy: 0.1876 - val_loss: 1.8052 - val_accuracy: 0.2073\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 8s 509ms/step - loss: 1.7651 - accuracy: 0.2964 - val_loss: 1.7566 - val_accuracy: 0.2317\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 8s 513ms/step - loss: 1.6597 - accuracy: 0.4435 - val_loss: 1.7117 - val_accuracy: 0.3049\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 8s 513ms/step - loss: 1.5090 - accuracy: 0.4520 - val_loss: 1.7146 - val_accuracy: 0.3659\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 8s 526ms/step - loss: 1.2676 - accuracy: 0.5437 - val_loss: 1.7919 - val_accuracy: 0.3415\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 8s 531ms/step - loss: 1.0652 - accuracy: 0.6162 - val_loss: 1.8421 - val_accuracy: 0.3780\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 8s 534ms/step - loss: 0.9056 - accuracy: 0.6930 - val_loss: 1.9520 - val_accuracy: 0.4024\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 8s 525ms/step - loss: 0.7460 - accuracy: 0.7463 - val_loss: 2.0278 - val_accuracy: 0.3659\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 8s 558ms/step - loss: 0.6786 - accuracy: 0.7974 - val_loss: 2.0948 - val_accuracy: 0.4390\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 8s 523ms/step - loss: 0.5630 - accuracy: 0.8124 - val_loss: 2.2102 - val_accuracy: 0.4024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x285fa8cce20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.fit(train_data, epochs=10,\n",
    "            steps_per_epoch=len(train_data),\n",
    "            validation_data=test_data,\n",
    "            validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w-QSrbJjxjLa",
    "outputId": "d00aa515-e4dc-44f7-9a90-fd0ffa889753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 175ms/step - loss: 2.2102 - accuracy: 0.4024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.210216522216797, 0.40243902802467346]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cADAc8YyvUwT"
   },
   "outputs": [],
   "source": [
    "# With respect to the above architecture, the model is overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZuIoo2L0uXM"
   },
   "source": [
    "#### Section B: Question No:3   (20 marks)\n",
    "Improve the baseline model performance and save the weights of improved model\n",
    "\n",
    "Conditions to consider:\n",
    "\n",
    "- Apply Data Augmentation if required\n",
    "\n",
    "- No parameter limit\n",
    "\n",
    "- Can use any number of layers\n",
    "\n",
    "- Use any optimizers of your choice\n",
    "\n",
    "- Use early stopping and save best model callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5T4nAll2vUwT",
    "outputId": "950536a7-e9ff-4eda-f869-95239f267e99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 469 images belonging to 6 classes.\n",
      "Found 82 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen=ImageDataGenerator(rescale=1/255.,\n",
    "                                rotation_range=45,\n",
    "                                width_shift_range=0.2,\n",
    "                                height_shift_range=0.2,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                fill_mode='reflect')\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1/255.,zoom_range=0.2)\n",
    "\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "\n",
    "train_data=train_datagen.flow_from_directory(train_dir,\n",
    "                                             target_size=(128,128),\n",
    "                                             batch_size=64,\n",
    "                                             class_mode='categorical')\n",
    "\n",
    "test_data=test_datagen.flow_from_directory(test_dir,\n",
    "                                           target_size=(128,128),\n",
    "                                           batch_size=64,\n",
    "                                           class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDRTZ-t201ov"
   },
   "outputs": [],
   "source": [
    "model1=Sequential([\n",
    "                    Conv2D(16, 3, activation='relu', input_shape=(128,128,3)),\n",
    "                    Conv2D(32,3,activation='relu'),\n",
    "                    MaxPool2D(),\n",
    "                    Conv2D(64,3,activation='relu'),\n",
    "                    MaxPool2D(),\n",
    "                    Flatten(),\n",
    "                    Dropout(0.2),\n",
    "                    Dense(64,activation='relu'),\n",
    "                    Dropout(0.2),\n",
    "                    Dense(32,activation='relu'),\n",
    "                    Dense(6, activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "keras_callback=[EarlyStopping(monitor='val_loss',mode='min',patience=5,min_delta=0.01),\n",
    "                ModelCheckpoint('flower_best_transfer_model',monitor='val_loss',save_best_only=True)]\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "                optimizer=Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "#model1.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MSB_aBNVvUwT",
    "outputId": "5091a57b-f281-421e-9470-0612cebcfdba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.5262 - accuracy: 0.1471INFO:tensorflow:Assets written to: flower_best_transfer_model\\assets\n",
      "8/8 [==============================] - 15s 2s/step - loss: 2.5262 - accuracy: 0.1471 - val_loss: 1.7966 - val_accuracy: 0.1829\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.7887 - accuracy: 0.1748INFO:tensorflow:Assets written to: flower_best_transfer_model\\assets\n",
      "8/8 [==============================] - 15s 2s/step - loss: 1.7887 - accuracy: 0.1748 - val_loss: 1.7752 - val_accuracy: 0.2439\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.7801 - accuracy: 0.2196INFO:tensorflow:Assets written to: flower_best_transfer_model\\assets\n",
      "8/8 [==============================] - 15s 2s/step - loss: 1.7801 - accuracy: 0.2196 - val_loss: 1.7704 - val_accuracy: 0.1829\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.7567 - accuracy: 0.2559INFO:tensorflow:Assets written to: flower_best_transfer_model\\assets\n",
      "8/8 [==============================] - 15s 2s/step - loss: 1.7567 - accuracy: 0.2559 - val_loss: 1.7662 - val_accuracy: 0.2073\n",
      "Epoch 5/10\n",
      "2/8 [======>.......................] - ETA: 11s - loss: 1.8578 - accuracy: 0.1647"
     ]
    }
   ],
   "source": [
    "model1.fit(train_data, epochs=10,\n",
    "            steps_per_epoch=len(train_data),\n",
    "            validation_data=test_data,\n",
    "            validation_steps=len(test_data),callbacks=keras_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSDJCXcMvUwU"
   },
   "outputs": [],
   "source": [
    "# The overfitting is reduced, but model performance is not improved , it is undesrfitting ,\n",
    "  # but it is for only 10 epoch, changing the architecture may help,\n",
    "  # So running this for more epoch may imprrove performance.\n",
    "# Dataset size is very less, so transfer learning may help\n",
    "\n",
    "# Students can use differnt combinations of layers to improve the model performance.\n",
    "# Also more epochs will improve the model, but students dont have time for it in exam\n",
    "# Need to award mark for an approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lb_YHFYvvUwU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
