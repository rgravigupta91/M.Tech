{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41317547",
   "metadata": {},
   "source": [
    "### Oct 2024: END SEMESTER ASSESSMENT (ESA) \n",
    "## M. TECH DATA SCIENCE AND MACHINE LEARNING_ SEMESTER II\n",
    "\n",
    "### UE20CS935 : Introduction to Deep Learning and Applications\n",
    "\n",
    "### Section C Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d5aa9b",
   "metadata": {
    "id": "c629d9f1"
   },
   "source": [
    "#### Section C: Question 5:    (15 Marks)\n",
    "\n",
    "Develop a Semantic segmentation model using Unet architecture on the given dataset.\n",
    "\n",
    "Dataset contains the images and the corresponding masks. Find the dataset under the folder “Unet_Dataset”. 1141 Glioma tumor images and its corresponding masks are provided.\n",
    "\n",
    "Students can make use of pre-trained Unet segmentation model using the library\n",
    "\n",
    "import segmentation_models as sm\n",
    "\n",
    "Hints\n",
    "1. Load all the images in one array of size 1141x128x128x1\n",
    "    Where 1141 is total number of trained images\n",
    "    128x128x3 is each image size (You can resize to any size of your choice, but bigger images takes time)\n",
    "2. Load all the masks in one array of size 1141x128x128x1\n",
    "3. Scale both the above two arrays\n",
    "4. Split the data into train and test\n",
    "5. Define the pre-trained segmentation model. Use encoder_weight=None, If internet access is not available.\n",
    "6. Properly define the classes and activation of the model.\n",
    "6. Compile with appropriate loss and metric and fit the data into it.\n",
    "7. Reduce the batch_size to 1 or 2, if you get any memory related error \n",
    "\n",
    "Run the model for minimum 2 epochs and present your result. The solution will be evaluated based on approach only as it take lot of epochs to produce good result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbef0860",
   "metadata": {
    "id": "717bda92"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import segmentation_models as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f925cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint : uncomment  below to fetch path\n",
    "# image_dir='Unet_Dataset/glioma_img/'\n",
    "# mask_dir='Unet_Dataset/glioma_mask/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08ac511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all the data from both the folders X-ray images and mask images.\n",
    "\n",
    "# store the data in the following folders\n",
    "# img_dataset=[]\n",
    "# mask_dataset=[]\n",
    "\n",
    "\n",
    "#Read the X-ray images and masks from the directories; hint: images=os.listdir(image_dir) and masks=os.listdir(mask_dir)\n",
    "\n",
    "#for i,image_name in enumerate(images):\n",
    "#    if (image_name.split('.')[1]=='png'):\n",
    "#       image=cv2.imread(image_dir+image_name,0)\n",
    "#       image=Image.fromarray(image)\n",
    "#       image=image.resize((SIZE,SIZE))\n",
    "#       img_dataset.append(np.array(image))\n",
    "\n",
    "# Do the similar steps for masks, make sure your mask images are binary images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2162f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52fa3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f70adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b9031",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFZCUDKAmi6A",
    "outputId": "afbc2e5e-d723-4880-f54b-d9f6fe401388"
   },
   "outputs": [],
   "source": [
    "#take the pre-trained model as resnet34 and do pre-processing\n",
    "BACKBONE = 'resnet34'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4754ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the preprocessed train input for model fitting\n",
    "X_train_prepr = preprocess_input(x_train)\n",
    "X_test_prepr = preprocess_input(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d74baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the Unet model using the below syntax\n",
    "model= sm.Unet(BACKBONE, input_shape=(128,128,1), \n",
    "                                encoder_weights=None, classes=1, activation='sigmoid')\n",
    "# Model compilation with the following specifications\n",
    "#Hint: optimizer='Adam'\n",
    "#    loss=sm.losses.bce_jaccard_loss\n",
    "#    metrics=[sm.metrics.iou_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9778d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model for X_train_prepr and y_train.\n",
    "# use batch_size=2 and epochs=5 (maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463d6162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DL_ESA_SectionC_5-Solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
