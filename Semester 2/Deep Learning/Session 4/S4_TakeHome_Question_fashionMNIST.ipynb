{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"S4_TakeHome_Question_fashionMNIST.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOCaWhGophUkOq2OxzHTmkd"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"AP7y53DtxnSy"},"source":["<table align=\"center\" width=100%>\r\n","    <tr>\r\n","        <td width=\"15%\">\r\n","            <img src=\"in_class.png\">\r\n","        </td>\r\n","        <td>\r\n","            <div align=\"center\">\r\n","                <font color=\"#21618C\" size=8px>\r\n","                    <b> TakeHome - Lab <br>(Session 4)\r\n","                    </b>\r\n","                </font>\r\n","            </div>\r\n","        </td>\r\n","    </tr>\r\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"gqj9X_tjSyXy"},"source":["## Fashion MNIST Dataset\n"," \n","\n","Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. \n","\n","The classes are 'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n","\n","\n","Each example is a 28x28 grayscale image, associated with a label from 10 classes.The Fashion-MNIST dataset is one of the most common datasets used for image classification and accessible from many different sources. In fact, even Tensorflow and Keras allow us to import and download the Fashion-MNIST dataset directly from their API.\n"]},{"cell_type":"markdown","metadata":{"id":"ZOk8Eu4_t70R"},"source":["Firstly, let's select TensorFlow version 2.x in colab"]},{"cell_type":"markdown","metadata":{"id":"I3au4pXbx2J6"},"source":["## 1 . Install & Import the required packages"]},{"cell_type":"code","metadata":{"id":"WL70hz6r1Kgg"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a484Vz82x9hB"},"source":["# 2 . Load the dataset & perform exploratory analysis on the dataset"]},{"cell_type":"markdown","metadata":{"id":"YSkpB9TyyB2E"},"source":["### 2 .a. Import the Fashion MNIST dataset"]},{"cell_type":"markdown","metadata":{"id":"roDpNYcESyXz"},"source":["Let's load MNIST dataset"]},{"cell_type":"code","metadata":{"id":"4kQf1NjrSyX5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612003330884,"user_tz":-330,"elapsed":2085,"user":{"displayName":"Sutithi Chakraborty","photoUrl":"","userId":"12749148906436566424"}},"outputId":"52ce1c59-e47b-4ad5-a449-1f84dc8d64f5"},"source":["fashion_mnist = keras.datasets.fashion_mnist\n","\n","# the data, shuffled and split between train and test sets\n","(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RwhGrZ5SyUUe"},"source":["### 2 .b. Print out the datashape of train & test "]},{"cell_type":"code","metadata":{"id":"o7VC9enB1M__"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mVVInu-RSyYJ"},"source":["### Print shape of the data"]},{"cell_type":"code","metadata":{"id":"RqIphilw14x2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kg5Xiig4y0my"},"source":["### 2 .c.  Visualize a particular image"]},{"cell_type":"code","metadata":{"id":"MijoKIPk13SX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h9mReoQby30s"},"source":["### 2 .d.  Visualize a portion of the dataset"]},{"cell_type":"code","metadata":{"id":"PGunLkk21P0V"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hbg2KXZsy959"},"source":["### 2 .e.  Process the train & test data"]},{"cell_type":"markdown","metadata":{"id":"NvfxTB1CSyYO"},"source":["### Reshape train and test sets into compatible shapes\n","- Sequential model in tensorflow.keras expects data to be in the format (n_e, n_h, n_w, n_c)\n","- n_e= number of examples, n_h = height, n_w = width, n_c = number of channels\n","- do not reshape labels"]},{"cell_type":"code","metadata":{"id":"5_T9yn_M1VVK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GHok6WPuSyYU"},"source":["### Normalize data\n","- we must normalize our data as it is always required in neural network models\n","- we can achieve this by dividing the RGB codes with 255 (which is the maximum RGB code minus the minimum RGB code)\n","- normalize X_train and X_test\n","- make sure that the values are float so that we can get decimal points after division"]},{"cell_type":"code","metadata":{"id":"01GBEEcG1WEn"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Io8RGv39SyYZ"},"source":["### Print shape of data and number of images\n","- print shape of X_train\n","- print number of images in X_train\n","- print number of images in X_test"]},{"cell_type":"code","metadata":{"id":"ITFOV4my1ZYl"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kbCeNC9PSyYi"},"source":["### One-hot encode the class vector\n","- convert class vectors (integers) to binary class matrix\n","- convert y_train and y_test\n","- number of classes: 10\n","- we are doing this to use categorical_crossentropy as loss"]},{"cell_type":"code","metadata":{"id":"YMbmUVGW1a2D"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jv6JfiBozC3x"},"source":["# 3 .  Build a classification model for the dataset"]},{"cell_type":"markdown","metadata":{"id":"WwJ-UE70zFU_"},"source":["### 3 .a.Prepare a basic CNN (4 Layer) model"]},{"cell_type":"markdown","metadata":{"id":"5jQGzVrX19zt"},"source":["### Initialize a sequential model again\n","- define a sequential model\n","- add 2 convolutional layers\n","    - no of filters: 32\n","    - kernel size: 3x3\n","    - activation: \"relu\"\n","    - input shape: (28, 28, 1) for first layer\n","- flatten the data\n","    - add Flatten later\n","    - flatten layers flatten 2D arrays to 1D array before building the fully connected layers\n","- add 2 dense layers\n","    - number of neurons in first layer: 128\n","    - number of neurons in last layer: number of classes\n","    - activation function in first layer: relu\n","    - activation function in last layer: softmax\n","    - we may experiment with any number of neurons for the first Dense layer; however, the final Dense layer must have neurons equal to the number of output classes"]},{"cell_type":"code","metadata":{"id":"hYeIaeMX1dOM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZPib9wSnzQ0H"},"source":["### 3 .b.  Fit the model in the data"]},{"cell_type":"markdown","metadata":{"id":"c74LMVBg3AXb"},"source":["### Compile and fit the model\n","- let's compile our model\n","    - loss: \"categorical_crossentropy\"\n","    - metrics: \"accuracy\"\n","    - optimizer: \"adam\"\n","- then next step will be to fit model\n","    - give train data - training features and labels\n","    - batch size: 32\n","    - epochs: 10\n","    - give validation data - testing features and labels"]},{"cell_type":"code","metadata":{"id":"Akcoo-5v1hJQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ABVwhkpRzX3u"},"source":["# 4 . Evaluate the model"]},{"cell_type":"markdown","metadata":{"id":"seA-mJDuzbwu"},"source":["### 4 .a. Visualize the performance  (Accuracy & Loss for both training & validation datda) of the model"]},{"cell_type":"code","metadata":{"id":"ZI3pUuKm1i5D"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tQpAaQ_hBu1d"},"source":["# 5 .Prepare Model 2"]},{"cell_type":"markdown","metadata":{"id":"SYg_NKA2zmqr"},"source":["### 5 .a. Develope the base model"]},{"cell_type":"markdown","metadata":{"id":"-dqbAnSdvITA"},"source":["## Vanilla CNN + Pooling + Dropout"]},{"cell_type":"markdown","metadata":{"id":"SAA84Lfv4LVZ"},"source":["### Initialize a sequential model again\n","- define a sequential model\n","- add 2 convolutional layers\n","    - no of filters: 32\n","    - kernel size: 3x3\n","    - activation: \"relu\"\n","    - input shape: (28, 28, 1) for first layer\n","- add a max pooling layer of size 2x2\n","- add a dropout layer\n","    - dropout layers fight with the overfitting by disregarding some of the neurons while training\n","    - use dropout rate 0.2\n","- flatten the data\n","    - add Flatten later\n","    - flatten layers flatten 2D arrays to 1D array before building the fully connected layers\n","- add 2 dense layers\n","    - number of neurons in first layer: 128\n","    - number of neurons in last layer: number of classes\n","    - activation function in first layer: relu\n","    - activation function in last layer: softmax\n","    - we may experiment with any number of neurons for the first Dense layer; however, the final Dense layer must have neurons equal to the number of output classes"]},{"cell_type":"code","metadata":{"id":"ZQm5pb7y1mef"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Re9R7SUzvdG"},"source":["### 5 .b.  Fit the model in the data"]},{"cell_type":"markdown","metadata":{"id":"rTTqCN1g5KVf"},"source":["### Compile and fit the model\n","- let's compile our model\n","    - loss: \"categorical_crossentropy\"\n","    - metrics: \"accuracy\"\n","    - optimizer: \"adam\"\n","- Use EarlyStopping\n","- then next step will be to fit model\n","    - give train data - training features and labels\n","    - batch size: 32\n","    - epochs: 10\n","    - give validation data - testing features and labels"]},{"cell_type":"code","metadata":{"id":"luby6Krh1o8Y"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yiMroONbzy5b"},"source":["# 6 . Evaluate the modeluate the model 2"]},{"cell_type":"markdown","metadata":{"id":"J8YDOg9pz1HJ"},"source":["### 6 .a. Visualize the performance  (Accuracy & Loss for both training & validation datda) of the model"]},{"cell_type":"code","metadata":{"id":"WtPRnvhC1qrH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sXcamG07z-bl"},"source":["### 6 .b. Visualize the model prediction"]},{"cell_type":"code","metadata":{"id":"ekSTQpln1sXA"},"source":[""],"execution_count":null,"outputs":[]}]}