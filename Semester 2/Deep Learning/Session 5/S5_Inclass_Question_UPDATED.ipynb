{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"S5_Inclass_Question_UPDATED.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xEk9OlpXkY1j"},"source":["<table align=\"center\" width=100%>\n","    <tr>\n","        <td width=\"15%\">\n","            <img src=\"in_class.png\">\n","        </td>\n","        <td>\n","            <div align=\"center\">\n","                <font color=\"#21618C\" size=8px>\n","                    <b> Inclass - Lab <br>(Session 5)\n","                    </b>\n","                </font>\n","            </div>\n","        </td>\n","    </tr>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"vleqRwYPlGye"},"source":["## Cifar-10 Dataset\n","\n","The CIFAR-10 dataset contains  60,000 records 32x32 colour images in 10 classes, with 6000 images per class.\n","\n","The classes are 'airplane','automobile','bird','cat','deer', 'dog','frog','horse','ship','truck' . \n","\n","Again which is splitted into 50,000 train & 10,000 test images.The CIFAR-10 dataset is one of the most common datasets used for image classification and accessible from many different sources. In fact, even Tensorflow and Keras allow us to import and download the MNIST dataset directly from their API.\n","\n","The data could be directly dowloaded from https://www.cs.toronto.edu/~kriz/cifar.html. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.\n","\n","The folder version of this dataset is also available here\n","\n","https://www.kaggle.com/swaroopkml/cifar10-pngs-in-folders"]},{"cell_type":"markdown","metadata":{"id":"8DwZOezTptqt"},"source":["### 1. Visualize few images randomly from differnt classes."]},{"cell_type":"code","metadata":{"id":"JK7DzjpVo2PB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTAE8sp6pMdh"},"source":["### 2. Perform required data augumentation on the given train and test dataset."]},{"cell_type":"code","metadata":{"id":"CSOfruQ1u2jo"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kBB2_BLlpUUj"},"source":["### 3. Load the train and test data from the folders in to tensorflow objects"]},{"cell_type":"code","metadata":{"id":"KYfL2BNeu3yF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aNDRnLYsqZ0h"},"source":["### 4 .Contruct the CNN model with the following architecture:\n","\n","Covn -> Maxpool -> Conv -> Maxpool -> Flatten ->Hidden 1 ->Hidden 2-> Output\n","\n","-- The final convolution layer output must 64 feature maps\n","\n","-- The final Hidden layer must have 32 neurons\n","\n","--Choose other parameters wisely as your choice"]},{"cell_type":"code","metadata":{"id":"7H7y9zfdu4pw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3gSWV6feqjWU"},"source":["### 5. Print the size of each layer output, alongwith number of parameters"]},{"cell_type":"code","metadata":{"id":"U6QgNjSuu57T"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hthEgezjqpSP"},"source":["### 6 . Compile the model with 'adam' optimizer"]},{"cell_type":"code","metadata":{"id":"HwmdxWEju6rF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iDR00D7nrKAQ"},"source":["### 7. Fit the model and print the training and testing loss and accuracy for each iteration. Plot the loss and accuracy curves for both training and testing data"]},{"cell_type":"code","metadata":{"id":"bSEZzt5PP1Q4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OZe9CWCTP1Q4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X7QrEBnuq2SL"},"source":["### 8 . Visualize the output of the first convolution and Maxpool layer"]},{"cell_type":"code","metadata":{"id":"t1trAK6Cu7sl"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L5Fli4GyrR1i"},"source":["### 9. Explore/rebuild the model for diffent architecture size(vary the convolution and hidden layer sizes) and pick the final model"]},{"cell_type":"code","metadata":{"id":"tvd42kZyu88n"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xdQyb2b8rkbz"},"source":["### 10. Apply Dropout layer in the model and check its impact on reducing the overfitting of the model."]},{"cell_type":"code","metadata":{"id":"lypCX2BxP1Q5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KJk2-gf9ra80"},"source":["### 11. Apply BatchNormalization layer in the model and check its impact on the model."]},{"cell_type":"code","metadata":{"id":"f67ZRMmQu922"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jxikILU_rxCr"},"source":["### 12. Save the final model weights in.h5 format"]},{"cell_type":"code","metadata":{"id":"T6bUXewou-xj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hivj1Q-HvCox"},"source":[""],"execution_count":null,"outputs":[]}]}