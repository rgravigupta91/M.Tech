{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"S5_TakeHome_Question_Fashion.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMpJj4QHOIsCpWk2822dZVx"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WNM0jqBSBVD1"},"source":["# Classification of a subset Image net data Transfer Learning from pre-trained Fashion MNIST CNN\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tdwFJ7kd5-po"},"source":["ImageNet is an image database organized according to the WordNet hierarchy (currently only the nouns), in which each node of the hierarchy is depicted by hundreds and thousands of images. Currently we have an average of over five hundred images per node. We hope ImageNet will become a useful resource for researchers, educators, students and all of you who share our passion for pictures.\r\n","\r\n","A subset of data on 'airplane','automobile','bird','cat','deer', 'dog','frog' , 'horse','ship','truck' have been collected from Imagenet.\r\n","\r\n","The train and validation subsets can be combined to make a larger training set.\r\n"]},{"cell_type":"markdown","metadata":{"id":"pRZ663a06nWC"},"source":["Note : -\r\n","\r\n","For the sake of simplcity we have changed the format of the data and stored the data in a .npy format file.Which has the X_train , y_train ,X_test & y_test in a dictionary format."]},{"cell_type":"code","metadata":{"id":"fa67q08j5awy"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KlI004QPBVD_"},"source":["# 1 .Load the dataset and Import the packages"]},{"cell_type":"markdown","metadata":{"id":"yIlO_joVBVD5"},"source":["Firstly, let's select TensorFlow version 2.x in colab"]},{"cell_type":"code","metadata":{"id":"lhh9LI_qAZ_o"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8uK5Oq7GBVD_"},"source":["As we are using google colab, we need to mount the google drive to load the data file"]},{"cell_type":"code","metadata":{"id":"qTE4lGnZAYJe"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UCfIZgJBBVEB"},"source":["Add path to the folder where your dataset is present"]},{"cell_type":"code","metadata":{"id":"HvsUP2MbAW0F"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-1F6FsRGBVED"},"source":["Let's load the dataset now"]},{"cell_type":"code","metadata":{"id":"c9r_cYHBAeFH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0F-rPUYf-tAD"},"source":["# 2 . Perform exploratory analysis on the dataset"]},{"cell_type":"markdown","metadata":{"id":"98DT_vCk-76j"},"source":["### 2 .a. Print out the datashape of train & test "]},{"cell_type":"code","metadata":{"id":"k_T6iv2BAfb8"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VcVG5M4n_DvS"},"source":["### 2 .b.  Visualize a particular image"]},{"cell_type":"code","metadata":{"id":"ObayoRnhAhNW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"94GGwCwK_J9q"},"source":["### 2 .c.  Visualize a portion of the dataset"]},{"cell_type":"code","metadata":{"id":"qWBUhG7hApPa"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uDXjqacV9kUm"},"source":["# 3 . Process the dataset"]},{"cell_type":"markdown","metadata":{"id":"uk-KNptBAEs0"},"source":["### 3 .a. Print the shape of training and testing data"]},{"cell_type":"code","metadata":{"id":"z-UH39JJAqXR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PEcVz-OotHWM"},"source":["### 3 .b. Let's check out the dataset"]},{"cell_type":"code","metadata":{"id":"t3tUk9X_Aupi"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0D29eowNhmU8"},"source":["### 3 .c. Resize all the train and test inputs to 28X28, to match with MNIST CNN model's input size\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VvB48apD7t6Q"},"source":["### 3 .c.i. Preproccess the data"]},{"cell_type":"code","metadata":{"id":"dG-l_ISVAv9-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vHjUmD84t4ZB"},"source":["### 3 .c.ii. Reshape train and test sets into compatible shapes\n","- Sequential model in tensorflow.keras expects data to be in the format (n_e, n_h, n_w, n_c)\n","- n_e= number of examples, n_h = height, n_w = width, n_c = number of channels\n","- do not reshape labels"]},{"cell_type":"code","metadata":{"id":"tBdj_yLvAxMZ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lHZVZBOuF6cV"},"source":["We can delete X_train_resized and X_test_resized variables as we are going to use X_train and X_test variables going further"]},{"cell_type":"code","metadata":{"id":"b9AOK6sIAyxY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GHok6WPuSyYU"},"source":["### 3 .c.iii. Normalize data\n","- we must normalize our data as it is always required in neural network models\n","- we can achieve this by dividing the RGB codes with 255 (which is the maximum RGB code minus the minimum RGB code)\n","- normalize X_train and X_test\n","- make sure that the values are float so that we can get decimal points after division"]},{"cell_type":"code","metadata":{"id":"4-HA1uYnA0Kh"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Io8RGv39SyYZ"},"source":["### 2 .c.iv.  Print shape of data and number of images\n","- print shape of X_train\n","- print number of images in X_train\n","- print number of images in X_test"]},{"cell_type":"code","metadata":{"id":"E_GcbUYrA1QN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kbCeNC9PSyYi"},"source":["### 3 .c.vi.  One-hot encode the class vector\n","- convert class vectors (integers) to binary class matrix\n","- convert y_train and y_test\n","- number of classes: 10\n","- we are doing this to use categorical_crossentropy as loss"]},{"cell_type":"code","metadata":{"id":"L1maF3VMA3hv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jmWQ5aIIIMcK"},"source":["Let's see one example after one-hot encoding"]},{"cell_type":"markdown","metadata":{"id":"o0BmXR_y8ZG4"},"source":["### 3 .d. Visualize an iage from the data"]},{"cell_type":"code","metadata":{"id":"cYD-G6nIA40l"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TKDpHB3N8UEW"},"source":["# 4 .  Build a classification model for the dataset"]},{"cell_type":"markdown","metadata":{"id":"QV4R9IbjjOVT"},"source":["### 4 .a. Building the CNN \n","- Define the layers of model with same size as the CNN used for MNIST Classification"]},{"cell_type":"markdown","metadata":{"id":"SAA84Lfv4LVZ"},"source":["### Initialize a sequential model\n","- define a sequential model\n","- add 2 convolutional layers\n","    - no of filters in first layer: 32\n","    - no of filters in second layer: 64\n","    - kernel size: 3x3\n","    - activation: \"relu\"\n","    - input shape: (28, 28, 1) for first layer\n","- add a max pooling layer of size 2x2\n","- add a dropout layer\n","    - dropout layers fight with the overfitting by disregarding some of the neurons while training\n","    - use dropout rate 0.2\n","- flatten the data\n","    - add Flatten later\n","    - flatten layers flatten 2D arrays to 1D array before building the fully connected layers\n","- add 2 dense layers\n","    - number of neurons in first layer: 128\n","    - number of neurons in last layer: number of classes\n","    - activation function in first layer: relu\n","    - activation function in last layer: softmax\n","    - we may experiment with any number of neurons for the first Dense layer; however, the final Dense layer must have neurons equal to the number of output classes"]},{"cell_type":"code","metadata":{"id":"TQ5vZXx2A6NG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a3lRhbHKSyZD"},"source":["### 4 .b. Make only dense layers trainable\n","- freeze the initial convolutional layer weights and train only the dense (FC) layers\n","- set trainalble = False for all layers other than Dense layers"]},{"cell_type":"code","metadata":{"id":"1xxX9q8rA7Le"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JMT0L1Wmv7HZ"},"source":["### 4 .c.  Load pre-trained weights from MNIST CNN model\n","- load the file named `Cifar_weights.h5`"]},{"cell_type":"code","metadata":{"id":"e2LKK4woA8H-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iDYmge-AlJTX"},"source":["### 4 .d.  Compile the model\n","- loss: \"categorical_crossentropy\"\n","- metrics: \"accuracy\"\n","- optimizer: \"adam\""]},{"cell_type":"code","metadata":{"id":"-DuP9Ht6A8s2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y7UZIqp3fpE9"},"source":["# 5 . Evaluate this model"]},{"cell_type":"code","metadata":{"id":"yIGXeEnRBDgR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wVHOojpJlvVa"},"source":["# 6 . Training the CNN "]},{"cell_type":"markdown","metadata":{"id":"wJIhBhbDmZ8U"},"source":["### 6 .a. Fit the model to the CINIC-10 dataset\n","- Use early stopping\n","- fit the model\n","    - give train data - training features and labels\n","    - batch size: 32\n","    - epochs: 10\n","    - give validation data - testing features and labels"]},{"cell_type":"code","metadata":{"id":"Mx3rgwUsBFF3"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o_n2Q4ag5KVw"},"source":["# 7 . Evaluate this model "]},{"cell_type":"markdown","metadata":{"id":"rs9w-G8t9UfO"},"source":["### 7 .a. Final loss and accuracy"]},{"cell_type":"code","metadata":{"id":"PJ-4LkE-BGge"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tWuDdzf0rgf-"},"source":["### 7 .b. Visualizing some predictions"]},{"cell_type":"code","metadata":{"id":"vyBwgrHABG_T"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fvl0nK6pmsmt"},"source":["# 8 . Saving the CNN\n","- Save the trained weights and model in h5 files"]},{"cell_type":"code","metadata":{"id":"jegE0ohlBJED"},"source":[""],"execution_count":null,"outputs":[]}]}