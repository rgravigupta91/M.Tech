{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"center\" width=100%>\n",
    "    <tr>\n",
    "        <td width=\"15%\">\n",
    "            <img src=\"in_class.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"center\">\n",
    "                <font color=\"#21618C\" size=8px>\n",
    "                    <b> Inclass - Lab <br>(Session 6)\n",
    "                    </b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNM0jqBSBVD1"
   },
   "source": [
    "### Classification of CINIC-10 using Transfer Learning from pre-trained CIFAR-10 CNN\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdwFJ7kd5-po"
   },
   "source": [
    "To combat the shortcomings of existing benchmarking datasets, we present CINIC-10: CINIC-10 Is Not ImageNet or CIFAR-10. It is an extension of CIFAR-10 via the addition of downsampled ImageNet images. CINIC-10 has the following desirable properties:It has 270,000 images, 4.5 times that of CIFAR.\n",
    "The images are the same size as in CIFAR, meaning that CINIC-10 can be used as a drop-in alternative to CIFAR-10.\n",
    "It has equally sized train, validation, and test splits. In some experimental setups it may be that more than one training dataset is required. Nonetheless, a fair assessment of generalisation performance is enabled through equal dataset split sizes.\n",
    "The train and validation subsets can be combined to make a larger training set.\n",
    "\n",
    "CINIC-10 consists of images from both CIFAR and ImageNet. The images from these are not necessarily identically distributed, presenting a new challenge: distribution shift. In other words, we can find out how well models trained on CIFAR images perform on ImageNet images for the same classes.\n",
    "\n",
    "Detail :\n",
    "\n",
    "1. CINIC-10 has a total of 270,000 images equally split amonst three subsets: train, validate, and test.\n",
    "\n",
    "2. In each subset (90,000 images) there are ten classes (identical to CIFAR-10 classes). \n",
    "\n",
    "3. There are 9,000 images per class per subset. Using the suggested data split (an equal three-way split), CINIC-10 has 1.8 times as many training samples than CIFAR-10. CINIC-10 is designed to be directly swappable with CIFAR-10.\n",
    "\n",
    "4. The train and validation classes can be combined to form a larger train set. In this case, CINIC-10 would have 3.6 times as many training samples than CIFAR-10. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRZ663a06nWC"
   },
   "source": [
    "Note : -\n",
    "\n",
    "For the sake of simplcity we have changed the format of the data and stored the data in a .npy format file.Which has the X_train , y_train ,X_test & y_test in a dictionary format.\n",
    "\n",
    "Data Link:\n",
    "\n",
    "https://drive.google.com/file/d/1soWI-A5gDbAIwCXs-YS_vB0dgeEeDi_2/view?usp=sharing\n",
    "\n",
    "Use the following syntax to load it:\n",
    "\n",
    "data = np.load('cinic_10.npy',allow_pickle='TRUE').item()\n",
    "\n",
    "X_train = data['X_train']\n",
    "\n",
    "y_train = data['y_train']\n",
    "\n",
    "X_test = data['X_test']\n",
    "\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98DT_vCk-76j"
   },
   "source": [
    "### 1. Understand the dataset by printing its size and visualize some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_T6iv2BAfb8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcVG5M4n_DvS"
   },
   "source": [
    "### 2.  Makesure that you are assigning the same class indices of CIFAR dataset to CINIC class labels. Do required preprocssing to make the CINIC data to have same image size and scale of CIFAR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ObayoRnhAhNW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94GGwCwK_J9q"
   },
   "source": [
    "### 3 Recreate the same final architecture that you have developed for last inclass experiment (for CIFAR dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWBUhG7hApPa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uk-KNptBAEs0"
   },
   "source": [
    "### 4. Apply the weights of CIFAR dataset model now on this model to predcit the CINIC image classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-UH39JJAqXR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEcVz-OotHWM"
   },
   "source": [
    "### 5. Apply the test data and evaluate the model performace (without doing any training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t3tUk9X_Aupi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHok6WPuSyYU"
   },
   "source": [
    "### 6. Freeze the convolution layer weights and tune the weigths of dense layers with CINIC train dataset and print the model performace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-HA1uYnA0Kh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rs9w-G8t9UfO"
   },
   "source": [
    "### 7. Apply ResNet50 pre-trained model to predict the the class of some random image picked from CINIC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJ-4LkE-BGge"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWuDdzf0rgf-"
   },
   "source": [
    "### 8. Load only the convolution layers of ResNet model and freeze its weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyBwgrHABG_T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fvl0nK6pmsmt"
   },
   "source": [
    "### 9. Use the freezed convoltion layers of Resnet as a base model and include a hidden and output layer with it. Train the wieghts of dense layers for CINIC dataset classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jegE0ohlBJED"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Unfreeze few of the last convolution layers and tune those kernal weights also along with dense layer weights. Make sure you are using small learning rate during this process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPIuh6HARNzo5kbuG0dlMYq",
   "collapsed_sections": [],
   "name": "S5_Inclass_Question_cinic10.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
