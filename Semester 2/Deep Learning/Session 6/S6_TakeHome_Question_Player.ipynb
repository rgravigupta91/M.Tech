{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"S6_TakeHome_Question_Player.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"TaiagDblXjtG"},"source":["# Object localization - Bounding Box\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ht0YkpgnXu_5"},"source":["# 1 . 700 annotations of Kumar Sangakkara's face dataset"]},{"cell_type":"markdown","metadata":{"id":"CIEDfts0cAbk"},"source":["### 1 .a. Context\r\n","\r\n","Recently I have been working on some object localization problems using Convolutional Nets and I wanted to try train the model on a new dataset other than the very common COCO or PASCAL VOC datasets. While pondering on what object to compile a small dataset around, I thought of pushing the challenge a bit more to see if the same model can be trained to localize faces. Having this in mind I wanted a dataset of a person's face annotations.\r\n","\r\n","As you may know with Deep Learning models, the more data you have the more accuracy you reach. So considering the challenge to detect a face I wanted a considerable number of images of the same face that the model should be trained on.\r\n","\r\n","Hence, I needed many pictures of the same person. So the person had to be famous so I could easily find many pictures.\r\n","So being in Sri Lanka where else to look other than our Cricket stars. So I chose the living legend in Sri Lankan Cricket, Kumar Sangakkara."]},{"cell_type":"markdown","metadata":{"id":"CHDqpajycExd"},"source":["### 1 .b. Content\r\n","\r\n","I downloaded around 1000 images from google images and after manual cleaning ended up with 704, which are contained here. I manually annotated all the pictures using a python script to generate the xml files. (Yeah, I couldn't find a better thing to do in that 2 hours.) Now here is the dataset for anyone to make use of."]},{"cell_type":"markdown","metadata":{"id":"LQmnIpLocH-4"},"source":["### 1 .c. Inspiration\r\n","\r\n","So as I mentioned in the above description, my goal with this dataset was to see if an object localization model can be used to detect a face of a person. Even though I have the pipeline, I couldn't still thoroughly test its performance using a GPU. So anyone whose interested can use this dataset to test those results.\r\n","Also if these annotations can be useful for any other application, feel free to use it and share it.\r\n","Have fun!"]},{"cell_type":"markdown","metadata":{"id":"_GW0dto7cJ5A"},"source":["### 1 .d.  Link to dataset: \r\n","\r\n","https://www.kaggle.com/mirantha/sangaface/"]},{"cell_type":"markdown","metadata":{"id":"kkeHoOTucMHU"},"source":["### 1 .e.  Note: \r\n","\r\n","For the simplicity of the data, we have convered the .xml format to .csv fomat.\r\n","\r\n","The content has a images.zip , train.csv and validation.csv files.\r\n","\r\n","In the data set we have images.zip (where we have images as .png files) , train.csv (where we have path, image_height, image_width, x_min, y_min, x_max, y_max ) and validation.csv (where we have path, image_height, image_width, x_min, y_min, x_max, y_max )"]},{"cell_type":"markdown","metadata":{"id":"dWbZxv7MdHxN"},"source":["# 2 .Load the dataset and Import the packages"]},{"cell_type":"markdown","metadata":{"id":"F673vwjOdQy3"},"source":["### 2 .a. Import the packages"]},{"cell_type":"code","metadata":{"id":"AgrhW5PaiMOY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OKVkkLaLdPGU"},"source":["### 2 .b. Load the dataset"]},{"cell_type":"markdown","metadata":{"id":"JK0ZRJoxhrFe"},"source":["As we are using google colab, we need to mount the google drive to load the data file"]},{"cell_type":"code","metadata":{"id":"Xl8LXssPiQVG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3gqIEcuK-gqQ"},"source":["Add path to the folder where your dataset files are"]},{"cell_type":"code","metadata":{"id":"PFIHr7BQiRdA"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1FOfBTnoBjYi"},"source":["Let's load the dataset now"]},{"cell_type":"code","metadata":{"id":"tgHD9-rriSkZ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NkCdfYxOabAV"},"source":["### 2 .c. Get training data"]},{"cell_type":"code","metadata":{"id":"N9mqDlWCiT3q"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gs5SOHItl4E-"},"source":["### 2 .d. Let's check how does the data look like"]},{"cell_type":"markdown","metadata":{"id":"u0wRl0PxmhqS"},"source":["Fetching coordinates details"]},{"cell_type":"code","metadata":{"id":"6G8krmyKiVqh"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ySVX5jNFdjOZ"},"source":["### 2 .e. Visualize a particular image"]},{"cell_type":"markdown","metadata":{"id":"l7cnLFA1mrSc"},"source":["Now, let's plot the image and the bounding box on top of it"]},{"cell_type":"code","metadata":{"id":"UXdY-vVpiXPS"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8adsqHoTdoCD"},"source":["# 3 . Process the dataset"]},{"cell_type":"markdown","metadata":{"id":"0V-g99d6m878"},"source":["### 3 .a. Back to data preparation"]},{"cell_type":"code","metadata":{"id":"U63xWRgIiYoX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VS7R4Bt4dv-n"},"source":["### 3 .b. Data preperation for validation data"]},{"cell_type":"code","metadata":{"id":"0MEbk-Oriaf_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ohb4LBnVd0qg"},"source":["# 4 .  Build an Object Localizing model for the dataset"]},{"cell_type":"markdown","metadata":{"id":"1w4PEmcdnzGK"},"source":["### 4 .a. Create the model"]},{"cell_type":"code","metadata":{"id":"7cG_4rnrid68"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DE_fSPKAd8Kj"},"source":["# 5 . Evaluate this model"]},{"cell_type":"markdown","metadata":{"id":"9Zrf0DXVn5Ov"},"source":["### 5 .a. Define evaluation metric"]},{"cell_type":"code","metadata":{"id":"GikO_EudifK4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PzmiW1Ayoitu"},"source":["### 5 .b. Initialize the model and print summary"]},{"cell_type":"code","metadata":{"id":"8rB7bGrZig2n"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iDYmge-AlJTX"},"source":["### 5 .c. Compile the model\n","- loss: \"mean_squared_error\"\n","- metrics: IoU\n","- optimizer: \"adam\""]},{"cell_type":"code","metadata":{"id":"ALrnjYbiiiIy"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GQcJ00NheLJj"},"source":["# 6 . Train model 2 "]},{"cell_type":"markdown","metadata":{"id":"wVHOojpJlvVa"},"source":["### 6 .a. Training the model"]},{"cell_type":"markdown","metadata":{"id":"wJIhBhbDmZ8U"},"source":["Fit the model to the dataset\n","- Use early stopping\n","- fit the model\n","    - give train data - training features and labels\n","    - batch size: 32\n","    - epochs: 10\n","    - give validation data - testing features and labels"]},{"cell_type":"code","metadata":{"id":"_i68rB5Mijb8"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qDRKiebgeULh"},"source":["# 7 . Evaluate this model"]},{"cell_type":"markdown","metadata":{"id":"MO_MWVlssv9j"},"source":["### 7 .a. Final loss and accuracy"]},{"cell_type":"code","metadata":{"id":"x_BchAwVikx2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"588o7uyTekLu"},"source":["### 7 .b. Model evaluation on Validation data"]},{"cell_type":"markdown","metadata":{"id":"7Dc7u4iDp19z"},"source":["#### 7 .b.i. Test the model on an image from validation data"]},{"cell_type":"code","metadata":{"id":"iuaLjI3filvb"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RxpkZnujfea4"},"source":["#### 7 .b.ii. Fetching coordinates details from predicted result"]},{"cell_type":"code","metadata":{"id":"GpAQQNRfioSq"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jiT0-20Rfkl-"},"source":["#### 7 .b.iii. Now, let's plot the image and the bounding box on top of it"]},{"cell_type":"code","metadata":{"id":"u9ay2P38ipN6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R8-_IbLgfqjw"},"source":["### 7 .c. Model evaluation on 2nd Validation data"]},{"cell_type":"markdown","metadata":{"id":"xWnDIvIrfsob"},"source":["#### 7 .c.i. Test the model on second image from validation data"]},{"cell_type":"code","metadata":{"id":"BVTxJy9JirDr"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LG2IGjtTfwLQ"},"source":["#### 7 .c.ii. Fetching coordinates details"]},{"cell_type":"code","metadata":{"id":"YwJXMmf8isVe"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0RS8BDvYf6J7"},"source":["#### 7 .c.iii. Now, let's plot the second image and the bounding box on top of it"]},{"cell_type":"code","metadata":{"id":"FbBGmB-9itxs"},"source":[""],"execution_count":null,"outputs":[]}]}