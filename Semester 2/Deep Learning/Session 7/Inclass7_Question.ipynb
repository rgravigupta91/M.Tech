{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaiagDblXjtG"
   },
   "source": [
    "# Object localization - Bounding Box\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkyTjbwtQ7nc"
   },
   "source": [
    "### The Caltech-10 Dataset\n",
    "\n",
    "Caltech-101 consists of pictures of objects belonging to 101 classes, plus one background clutter class. Each image is labelled with a single object.Collected in September 2003 by Fei-Fei Li, Marco Andreetto, and Marc 'Aurelio Ranzato. Each class contains roughly 40 to 800 images, totalling around 9k images. Images are of variable sizes, with typical edge lengths of 200-300 pixels. This version contains image-level labels only. The original dataset also contains bounding boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vW4jY7QQ9W7"
   },
   "source": [
    "Home Page for the datset:\n",
    "\n",
    "http://www.vision.caltech.edu/Image_Datasets/Caltech101/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2RFu0H0PZFe"
   },
   "source": [
    "For the sake of simplcity we have changed the format of the data and stored the data in a .csv format files.Which are stored in train.csv and validation.csv files. We have  strored images in the 101_ObjectCategories.zip folder.         \n",
    "\n",
    "The data has been splitted into train and validation csv.\n",
    "The data about path, image_width, image_height, x-min, x-max, y-min,  y-max is stored in the csv files.\n",
    "\n",
    "Download the files and images from the below link:\n",
    "https://drive.google.com/drive/folders/1kuuEOBq-tFsC8n8SDCuM_-Q4BSlEYVSy?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dD55F0QaRhrm"
   },
   "source": [
    "#### 1. Extract only the required image path with name from the train and validation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xll3_2IkQeUF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-YPMYlhWb_7"
   },
   "source": [
    "#### 2. Scale the Bounding Box information of tran and validation with respect to the the constant image size (say 128x128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ijWljnmWgmh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gqIEcuK-gqQ"
   },
   "source": [
    "#### 3. Read all the train images using the path extracted in question 1 and resize it to a shape of 128x128 and perform required preprocessing with respect to the choice of your pre-trained model (Preferably Mobilenet). Keep all the train images in one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Guq9I9nWiYF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FOfBTnoBjYi"
   },
   "source": [
    "#### 4. Perform the same for the validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdvTZP62WjmD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkCdfYxOabAV"
   },
   "source": [
    "#### 5. Visulaize some sample image along with its Bounding Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNEfg9MzWlMa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gs5SOHItl4E-"
   },
   "source": [
    "#### 6. Define the function for IoU metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scszwFbmWnGx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GS42bk8SBru"
   },
   "source": [
    "#### 7. Load only the Mobilenet pretrained model's convolution layers and freeze its weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ut5T_GN9Wocj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Add the convolution layer with appropriate kernal size and count to produce 1x4 output and properly rehape that as one column vector.\n",
    "\n",
    "Note: Object localization problem is nothing but predicting 4 bounding box points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjJ0o0YNSJv-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0V-g99d6m878"
   },
   "source": [
    "#### 9. Compile the model with appropriate loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXLUvn4fWp_b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqYSuL89Sfdf"
   },
   "source": [
    "#### 10. Train and evaluate the model for better performance. Predict the bounding box for sample image and plot it on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TuLXdAjeWuhK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "S6_Inclass_CalTech101_Question.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
