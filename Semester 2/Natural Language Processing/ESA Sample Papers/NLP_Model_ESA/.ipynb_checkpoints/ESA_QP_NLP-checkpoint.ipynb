{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f87f2f",
   "metadata": {},
   "source": [
    "### XXXX-2022: END SEMESTER ASSESSMENT (ESA) \n",
    "## M TECH DATA SCIENCE AND MACHINE LEARNING_ SEMESTER II\n",
    "\n",
    "#### UE20CS933 - NATURAL LANGUAGE PROCESSING "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d2e19",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "869655aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from gensim.parsing.preprocessing import PorterStemmer, remove_stopwords\n",
    "import string \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eea2c4",
   "metadata": {},
   "source": [
    "## Section B\n",
    "### 2. Use the data.csv dataset as provided in the notebook as Pandas DataFrame and   process it as questioned below.\n",
    "\n",
    "#### Dataset \n",
    "Airline Sentiment dataset is provide as pandas dataframe. Using python NLP libraires process the dataset as questioned below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9890979d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
       "       'negativereason', 'negativereason_confidence', 'airline',\n",
       "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
       "       'retweet_count', 'text', 'tweet_coord', 'tweet_created',\n",
       "       'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9be4a4",
   "metadata": {},
   "source": [
    "### 2.a. Create a new Pandas DataFrame by fetching two columns 'textâ€™ and 'airline_sentiment' from data.csv.  (Marks-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfc5b39",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe69ab2",
   "metadata": {},
   "source": [
    "### 2.b. Clean the 'text' columns as questioned below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643cef6",
   "metadata": {},
   "source": [
    "#### 2.b.(i) Convert all text to lower case ( Marks- 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ad07b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ca8b166",
   "metadata": {},
   "source": [
    "#### 2.b.(ii)  Remove the URLs (http & www) from text ( Marks-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b4b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint: regular expression for URLs  matching is 'https?://\\S+|www\\.\\S+' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1623fe",
   "metadata": {},
   "source": [
    "#### 2.b.(iii).  Remove stopwords from text.  ( Marks-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e08e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any of nltk or gensim can be used\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884da79",
   "metadata": {},
   "source": [
    "#### 2.b.(iv) Remove punctuations from text. (Marks-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc60d427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint: refer string.punctuation to fetch all punctuations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac2208",
   "metadata": {},
   "source": [
    "### 2.c. Fetch the top six most frequently used words from the text corpus (Marks-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eccd212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0b35187",
   "metadata": {},
   "source": [
    "### 3. Use the cleaned dataframe from previous section inorder to build ML model as questioned below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e771db55",
   "metadata": {},
   "source": [
    "### 3.a. Convert the text feature/column into numerical using Count-vectorization  (Marks-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f17a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint: use below count_vectorize  method definition\n",
    "count_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afbf8dc",
   "metadata": {},
   "source": [
    "### 3.b. Convert the text  feature/column into numerical using TF-IDF (Marks-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b04f8c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint: use below TfidfVectorizer method definition\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word',stop_words='english', ngram_range=(1, 1))\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5d1fd5",
   "metadata": {},
   "source": [
    "### 3.c Split both Count-vectorirsed  & TF-IDF dataset into train & test set  with one fourth records being held for testing also ensure stratified sampling of traget i.e. airline_sentiment on both split ( Marks-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8ff379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint  use the split method : train_test_split(vectorise_dataframe,Y,stratify=Y,test_size= )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149f550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split count-vectorised dataset\n",
    "# 2 marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split tf-idf dataset\n",
    "#2 marks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7cea9",
   "metadata": {},
   "source": [
    "### 3.d Build a basic logistic regression model ( LogisticRegression(solver='liblinear')) on Count-vectorize train set and find out its accuracy on Count-vectorize test set.  ( Marks-10 = 5 -training + 5-finding accuracy )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6719994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint:  use below LogisticRegression method\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# train lr on Count-vectorize trainset\n",
    "\n",
    "# find accuracy on Count-vectorize test set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288099d2",
   "metadata": {},
   "source": [
    "### 3.e Build a basic logistic regression model ( LogisticRegression(solver='liblinear')) on TF-IDF train set and find out its accuracy on TF-IDF test set.  Which model has better accuracy ?(  Marks-10 = 5(training) + 5 (finding accuracy) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21351b51",
   "metadata": {},
   "outputs": [],
   "source": [
    " # train lr on TF-IDF train set\n",
    "\n",
    "# find accuracy on TF-IDF  test set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e913bc5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
