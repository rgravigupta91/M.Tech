{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2ab108c-c0ce-4207-aabf-45d8aa948acf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # create spark context \n",
    "# ## Spark Tutorial  (PySpark)\n",
    "# ### Initialize spark context \n",
    "\n",
    "# from pyspark import SparkConf\n",
    "# from pyspark.context import SparkContext\n",
    "# # appName parameter is a name for your application to show on the cluster UI. \n",
    "# #master is a Spark, Mesos or YARN cluster URL\n",
    "# conf = SparkConf().setAppName('appName').setMaster('local[*]')\n",
    "\n",
    "# #first thing a Spark program must do is to create a SparkContext object, which tells Spark how to access a cluster\n",
    "# sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc457855-75c2-4b7e-a137-ff8fc1379f1a",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # command to create spark context \n",
    "# from pyspark import  SparkContext\n",
    "# sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c121733d-60c6-45d5-8e4c-1123b21ebd03",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/databricks-datasets/COVID/</td><td>COVID/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/README.md</td><td>README.md</td><td>976</td><td>1532468253000</td></tr><tr><td>dbfs:/databricks-datasets/Rdatasets/</td><td>Rdatasets/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/SPARK_README.md</td><td>SPARK_README.md</td><td>3359</td><td>1455043490000</td></tr><tr><td>dbfs:/databricks-datasets/adult/</td><td>adult/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/airlines/</td><td>airlines/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/amazon/</td><td>amazon/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/asa/</td><td>asa/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/atlas_higgs/</td><td>atlas_higgs/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/bikeSharing/</td><td>bikeSharing/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/cctvVideos/</td><td>cctvVideos/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/credit-card-fraud/</td><td>credit-card-fraud/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/cs100/</td><td>cs100/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/cs110x/</td><td>cs110x/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/cs190/</td><td>cs190/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/data.gov/</td><td>data.gov/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/definitive-guide/</td><td>definitive-guide/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/delta-sharing/</td><td>delta-sharing/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/flights/</td><td>flights/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/flower_photos/</td><td>flower_photos/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/flowers/</td><td>flowers/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/genomics/</td><td>genomics/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/hail/</td><td>hail/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/identifying-campaign-effectiveness/</td><td>identifying-campaign-effectiveness/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/iot/</td><td>iot/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/iot-stream/</td><td>iot-stream/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/learning-spark/</td><td>learning-spark/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/learning-spark-v2/</td><td>learning-spark-v2/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/lending-club-loan-stats/</td><td>lending-club-loan-stats/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/med-images/</td><td>med-images/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/media/</td><td>media/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/mnist-digits/</td><td>mnist-digits/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/news20.binary/</td><td>news20.binary/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/nyctaxi/</td><td>nyctaxi/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/nyctaxi-with-zipcodes/</td><td>nyctaxi-with-zipcodes/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/online_retail/</td><td>online_retail/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/overlap-join/</td><td>overlap-join/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/power-plant/</td><td>power-plant/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/retail-org/</td><td>retail-org/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/rwe/</td><td>rwe/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/sai-summit-2019-sf/</td><td>sai-summit-2019-sf/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/sample_logs/</td><td>sample_logs/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/samples/</td><td>samples/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/sfo_customer_survey/</td><td>sfo_customer_survey/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/sms_spam_collection/</td><td>sms_spam_collection/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/songs/</td><td>songs/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/structured-streaming/</td><td>structured-streaming/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/timeseries/</td><td>timeseries/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/tpch/</td><td>tpch/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/travel_recommendations_realtime/</td><td>travel_recommendations_realtime/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/warmup/</td><td>warmup/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/weather/</td><td>weather/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/wiki/</td><td>wiki/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/wikipedia-datasets/</td><td>wikipedia-datasets/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/databricks-datasets/wine-quality/</td><td>wine-quality/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/databricks-datasets/COVID/",
         "COVID/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/README.md",
         "README.md",
         976,
         1532468253000
        ],
        [
         "dbfs:/databricks-datasets/Rdatasets/",
         "Rdatasets/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/SPARK_README.md",
         "SPARK_README.md",
         3359,
         1455043490000
        ],
        [
         "dbfs:/databricks-datasets/adult/",
         "adult/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/airlines/",
         "airlines/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/amazon/",
         "amazon/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/asa/",
         "asa/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/atlas_higgs/",
         "atlas_higgs/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/bikeSharing/",
         "bikeSharing/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/cctvVideos/",
         "cctvVideos/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/credit-card-fraud/",
         "credit-card-fraud/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/cs100/",
         "cs100/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/cs110x/",
         "cs110x/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/cs190/",
         "cs190/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/data.gov/",
         "data.gov/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/definitive-guide/",
         "definitive-guide/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/delta-sharing/",
         "delta-sharing/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/flights/",
         "flights/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/flower_photos/",
         "flower_photos/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/flowers/",
         "flowers/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/genomics/",
         "genomics/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/hail/",
         "hail/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/identifying-campaign-effectiveness/",
         "identifying-campaign-effectiveness/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/iot/",
         "iot/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/iot-stream/",
         "iot-stream/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/learning-spark/",
         "learning-spark/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/learning-spark-v2/",
         "learning-spark-v2/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/lending-club-loan-stats/",
         "lending-club-loan-stats/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/med-images/",
         "med-images/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/media/",
         "media/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/mnist-digits/",
         "mnist-digits/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/news20.binary/",
         "news20.binary/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/nyctaxi/",
         "nyctaxi/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/nyctaxi-with-zipcodes/",
         "nyctaxi-with-zipcodes/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/online_retail/",
         "online_retail/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/overlap-join/",
         "overlap-join/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/power-plant/",
         "power-plant/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/retail-org/",
         "retail-org/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/rwe/",
         "rwe/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/sai-summit-2019-sf/",
         "sai-summit-2019-sf/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/sample_logs/",
         "sample_logs/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/samples/",
         "samples/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/sfo_customer_survey/",
         "sfo_customer_survey/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/sms_spam_collection/",
         "sms_spam_collection/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/songs/",
         "songs/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/structured-streaming/",
         "structured-streaming/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/timeseries/",
         "timeseries/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/tpch/",
         "tpch/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/travel_recommendations_realtime/",
         "travel_recommendations_realtime/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/warmup/",
         "warmup/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/weather/",
         "weather/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/wiki/",
         "wiki/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/wikipedia-datasets/",
         "wikipedia-datasets/",
         0,
         0
        ],
        [
         "dbfs:/databricks-datasets/wine-quality/",
         "wine-quality/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " %fs ls /databricks-datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ca0d70d-c986-4fcb-a8cc-1349252722a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Spark Context is by default created \n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1331c63b-eb75-49e3-968a-096449433ee2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##  RDD \n",
    "### Ways to create RDD\n",
    "     1. Parallelizing an existing collection in your driver program\n",
    "     2. Referencing a dataset in an external storage system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6aa27cb-c95a-46a3-a7d3-9024e22362cd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Parallelizing an existing collection in your driver program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "902db197-468e-4400-868b-62b72238fb43",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# any collection  not only list \n",
    "\n",
    "data_list = [1,2,3,4,5,6,7,8,9,10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ae60032-92b4-4791-9518-e63729522c5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "type(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19d05a4b-6e72-47af-8eae-8f42f230dd75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# parallelize -- will take any python collection and convert into RDD \n",
    "\n",
    "rdd_list = sc.parallelize(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dadd389d-14d1-450e-9e7c-33080f1e618b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Type of RDD list\n",
    "type(rdd_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d8b376c-f1c4-4e81-8c70-c30f5175c6df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Return a list that contains all the elements in this RDD.\n",
    "rdd_list.collect()\n",
    "# no one does this actually i.e. prints all the RDD content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "677a3331-6db0-4c6e-b7bc-2d2fe1c2378d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#rdd_list.count()\n",
    "#rdd_list.first()\n",
    "#rdd_list.take(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3037f09-027d-4325-9320-4e17b776ce18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# check no of( partitons )\n",
    "rdd_list.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f20580c5-993a-4688-a6a9-b597dff9e2ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Refere transformation and Action in dcoumentation and try them\n",
    "# 20 tranformation \n",
    "# 12 Action "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a47f2b2-087f-47d6-a16e-b48d9e6b610a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rdd_list2 = sc.parallelize([10, 11,12,13,14,15, 16])\n",
    "\n",
    "# union will  just append \n",
    "\n",
    "# not going to remove any duplicates \n",
    "unioun_list = rdd_list.union(rdd_list2)\n",
    "\n",
    "\n",
    "unioun_list.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39c9b336-2dea-4f46-b07e-eede70244f06",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# intersection is like join only common elements will be there \n",
    "\n",
    "intersection_list = rdd_list.intersection(rdd_list2)\n",
    "intersection_list.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e263ebf1-b923-4317-8dd1-4a4d277006d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# check data inside each partition\n",
    "rdd_list.glom().collect()\n",
    "# how the data is distributed inside partion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea88527f-0342-4b11-b31f-faa9a1316c77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# define own partition \n",
    "rdd_list_selfPartiton = sc.parallelize(data_list, numSlices=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da9f8b6d-c399-4e22-a9ba-db61638dbc70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rdd_list_selfPartiton.glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4436499-7f6a-4d55-b075-3d8d79b0e9b9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Creating RDD From  External dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3138ab80-bd36-43fd-b45b-80e0922b7592",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rdd_ODI_data = sc.textFile('/FileStore/tables/ODIData.csv',minPartitions = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "608413fb-2fbd-4672-9e26-4d3014f37bf5",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check num of partion \n",
    "rdd_ODI_data.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c6856fa-7a5e-4a74-b8af-4df0738bb345",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "type(rdd_ODI_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "772b49f9-3a8e-4553-9be6-60b07fd22921",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Action "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12f5fbea-2024-42fc-8e12-114c55479e54",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rdd_ODI_data.collect()\n",
    "#\n",
    "# fields = (\"name\", \"country\", \"career\", \"matches\", \"won\", \"lost\", \"ties\", \"toss\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "340bd658-3470-4ed3-9e9c-ab574ed7162c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# similar to head function \n",
    "rdd_ODI_data.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8eeab2fd-9457-41b7-9414-874bca7d0812",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# map\n",
    "# tokenize \n",
    "rdd_ODI_data_map = rdd_ODI_data.map(lambda x : x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ce5d32a-2c15-4be9-aef4-8d6546e039ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "type(rdd_ODI_data_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1d63f48-210f-4fb6-9f9a-e727897e6b29",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# take\n",
    "rdd_ODI_data_map.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e53d5df-55ca-4c99-bfdd-b75890e2d6ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# list of list \n",
    "#or list of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7747b9f4-640b-45e1-a0a1-cd69a08e0db6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# distinct demo : Fetch names of the mentioned countries \n",
    "# transformation distinct \n",
    "rdd_ODI_data_country = rdd_ODI_data_map.map(lambda X : X[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96886fb4-e4c6-46cd-8f81-c9a426312ce9",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdd_ODI_data_country.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75b615fe-58c8-43ca-9804-e8c8a882c13b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rdd_ODI_data_country_unique = rdd_ODI_data_country.distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cbe8f55-1513-42ec-983b-9f6ac931deb7",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " rdd_ODI_data_country_unique.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff2f7be7-b439-4f8e-8b07-eb43ee4415b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Transformation Filter\n",
    "\n",
    "- 1. Map\n",
    "- 2. FlatMap\n",
    "  3. Filter\n",
    "  4. Distinct\n",
    "  5. Union\n",
    "  6. Intersection\n",
    "\n",
    "# original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6fcd6aa-67e6-4021-b91a-8b02b009a323",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# filter the crickter who belong to india \n",
    "rdd_ODI_data_india = rdd_ODI_data_map.filter(lambda x : x[1]=='India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ea1bc3c-71d2-465a-817d-4c7af9896448",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdd_ODI_data_india.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69d98270-48b9-4e71-ad88-9d2ddaa6becf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# use count to find out the total no players from India\n",
    "rdd_ODI_data_india.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0ed4e24-9028-4652-8818-f0bce7704c88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lets find out how many Aurtrailan cricketer  has plyed more than 99 ODI \n",
    "\n",
    "# Apply the filer transformation \n",
    "\n",
    "# demo of and and or  (|)\n",
    "\n",
    "rdd_ODI_data_filetered = rdd_ODI_data_map.filter(lambda x : ( x[1]=='Australia') &  (int(x[3])> 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bbff6ea-ca69-4148-a077-e64db2163517",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# collect the result \n",
    "\n",
    "rdd_ODI_data_filetered.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6900c37-ef9e-47b6-a5c9-390d8c81887c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## FlatMap\n",
    "## Flat map trnaformation - tokenize records \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "405caab0-147b-4743-903b-43fc735e9211",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdd_ODI_data_flatmap = rdd_ODI_data.flatMap(lambda x : x.split(','))\n",
    "#rdd_ODI_data_flatmap.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d30db02-b126-4d9d-adcb-7b0e9bd96130",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rdd_ODI_data_flatmap.take(10)\n",
    "# what is the data type of output -list  .. why ?\n",
    "# Why the output is not an RDD ?\n",
    "# output of action will be pushed to driver ..Dirver uses python datatypes only \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e823678-dd6c-4db6-8995-003015fc470a",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transformation union \n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d7adc97-352c-44b5-abc9-91c078dfb1a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "l = [(\"a\", 1), (\"b\", 1), (\"a\", 1)]\n",
    "type(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecdc8263-473d-44a1-91d8-3777aeb91d7e",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = (\"a\", 1)\n",
    "type(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2aba372f-fe05-4f66-871e-7054ad45ba78",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Reduce by key perfroms \n",
    "reduction operation on the values of each key. It's particularly useful for aggregating data based on keys in a distributed environment.\n",
    "useful for aggregating data based on keys in a distributed environment.\n",
    "How it works -- \n",
    "1. Grouping by Key\n",
    "2. Reduction: It applies a specified function to all the values associated with each key, reducing them to a single value\n",
    "3. Output: The result is a new RDD consisting of key-value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0ece408-e7c2-49df-bb7a-dd48365d55bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#  Reduce by key demo \n",
    "# list of tuple\n",
    "from operator import add\n",
    "rdd_list_of_tuple = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
    "rdd_reduce = rdd_list_of_tuple.reduceByKey(lambda p, n: p + n)\n",
    "rdd_reduce.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "706934a3-7bb4-4c4c-8e1f-cc288d050479",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfe76a9a-97c6-4aae-b461-0c11be2a695c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# without persist demo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39f52b98-deb2-4617-b384-2ab0c0f0d19e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark import  SparkContext\n",
    "\n",
    "# # command to create spark context \n",
    "# sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14ebc987-85d2-4621-8c48-4998e6e6da65",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"war_and_peace.txt\",2)\n",
    "type(lines)\n",
    "\n",
    "# we have to all an action to cach\n",
    "lines.count()\n",
    "\n",
    "# Now rename (using mv command) war_and_peace.txt file to some other name like wap.txt \n",
    "# In Databricks notebook, you can use the command:\n",
    "# %fs mv /FileStore/tables/war_and_peace.txt /FileStore/tables/wap.txt\n",
    "\n",
    "nonNullLines = lines.filter(lambda line: len(line)>0)\n",
    "words = nonNullLines.flatMap(lambda line: line.split())\n",
    "\n",
    "words.count()\n",
    "\n",
    "# You will see an error message that file war_and_peace.txt is missing.\n",
    "# Even though the application already read it and created lines RDD, for the secon action words.count(),\n",
    "# it tries to create the RDD from the beginning i.e. from the line sc.textfile onward.\n",
    "\n",
    "# Remeber to rename the wap.txt file back to war_and_peace.txt\n",
    "# %fs mv /FileStore/tables/wap.txt /FileStore/tables/war_and_peace.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fca98e13-99c0-41a5-b6c7-03278bccfe43",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52d07f31-8bb7-4c24-af2e-74516e975bee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## persist demo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e3cf8c6-3ef1-4776-8ff8-97c1851b6eb8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark import  SparkContext\n",
    "\n",
    "# # command to create spark context \n",
    "# sc = SparkContext()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43089a74-1dba-4aa3-bfc5-a97184115225",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"/FileStore/tables/war_and_peace.txt\",2)\n",
    "type(lines)\n",
    "\n",
    "lines.persist()\n",
    "\n",
    "lines.count()\n",
    "\n",
    "# Now rename (using mv command) war_and_peace.txt file to some other name like wap.txt \n",
    "# In Databricks notebook, you can use the command:\n",
    "# %fs mv /FileStore/tables/war_and_peace.txt /FileStore/tables/wap.txt\n",
    "\n",
    "nonNullLines = lines.filter(lambda line: len(line)>0)\n",
    "words = nonNullLines.flatMap(lambda line: line.split())\n",
    "\n",
    "words.count()\n",
    "\n",
    "# This time you will NOT get the error message that file war_and_peace.txt is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "262e3b2c-9650-43f3-ba1d-f7a56dfc67d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfde712b-7aa1-479e-8b50-dc4329f2ce3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dag demo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "770878c3-8457-4cb6-abc5-2590805d1205",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import  SparkContext\n",
    "\n",
    "# command to create spark context \n",
    "\n",
    "sc = SparkContext()\n",
    "\n",
    "# word count\n",
    "lines = sc.textFile(\"war_and_peace.txt\")\n",
    "nonNullLines = lines.filter(lambda line: len(line)>0) \n",
    "words = nonNullLines.flatMap(lambda line: line.split())\n",
    "upperWords = words.map(lambda word: word.upper())\n",
    "pairedOnes = upperWords.map(lambda uw: (uw, 1))\n",
    "wordCounts = pairedOnes.reduceByKey(lambda prev, next: prev + next)\n",
    "\n",
    "wordCounts.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1890d986-5bc3-45a5-adbd-128c6e8f88bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [
      {
       "dashboardResultIndex": 0,
       "elementNUID": "c121733d-60c6-45d5-8e4c-1123b21ebd03",
       "elementType": "command",
       "guid": "1e8af41e-6956-4494-98b2-25d361460b5a",
       "options": null,
       "position": null,
       "resultIndex": null
      }
     ],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "1edc8fd8-00e8-491d-a977-b36bf7372fbe",
     "origId": 1672846555808765,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1672846555808764,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "RDD_Demo_Databricks",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
