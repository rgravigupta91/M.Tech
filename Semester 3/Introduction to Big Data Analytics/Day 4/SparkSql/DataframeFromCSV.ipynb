{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/07 12:50:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/08/07 12:50:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext.getOrCreate()\n",
    "# initializing spark session\n",
    "spark = SparkSession(sc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6a27925c-0eca-4d2b-81a4-f448f4178bf2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Item Type: string (nullable = true)\n",
      " |-- Sales Channel: string (nullable = true)\n",
      " |-- Order Priority: string (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Order ID: integer (nullable = true)\n",
      " |-- Ship Date: string (nullable = true)\n",
      " |-- Units Sold: integer (nullable = true)\n",
      " |-- Unit Price: double (nullable = true)\n",
      " |-- Unit Cost: double (nullable = true)\n",
      " |-- Total Revenue: double (nullable = true)\n",
      " |-- Total Cost: double (nullable = true)\n",
      " |-- Total Profit: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a DF from a CSV file\n",
    "creditcardDF = spark.read.format(\"csv\") \\\n",
    "                         .option(\"header\", \"true\") \\\n",
    "                         .option(\"inferSchema\", \"true\") \\\n",
    "                         .load(\"SalesTraining.csv\")\n",
    "\n",
    "# display the schema\n",
    "creditcardDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "20e597d1-67f5-4e33-832e-0ea19dedfe21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[Region: string, Country: string, Item Type: string, Sales Channel: string, Order Priority: string, Order Date: string, Order ID: int, Ship Date: string, Units Sold: int, Unit Price: double, Unit Cost: double, Total Revenue: double, Total Cost: double, Total Profit: double]\n"
     ]
    }
   ],
   "source": [
    "print(creditcardDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "51a7d6b3-3ec4-4bb5-87bc-568ebbb4506b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "|Region            |Country   |Item Type |Sales Channel|Order Priority|Order Date|Order ID |Ship Date |Units Sold|Unit Price|Unit Cost|Total Revenue|Total Cost|Total Profit|\n",
      "+------------------+----------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "|Sub-Saharan Africa|Burundi   |Vegetables|Online       |M             |11/17/2010|951380240|12/20/2010|3410      |154.06    |90.93    |525344.6     |310071.3  |215273.3    |\n",
      "|Europe            |Ukraine   |Cosmetics |Online       |M             |11/13/2014|270001733|1/1/2015  |8368      |437.2     |263.33   |3658489.6    |2203545.44|1454944.16  |\n",
      "|Europe            |Croatia   |Beverages |Online       |C             |6/16/2016 |681941401|7/28/2016 |470       |47.45     |31.79    |22301.5      |14941.3   |7360.2      |\n",
      "|Sub-Saharan Africa|Madagascar|Fruits    |Online       |L             |5/31/2016 |566935575|6/7/2016  |7690      |9.33      |6.92     |71747.7      |53214.8   |18532.9     |\n",
      "|Asia              |Malaysia  |Snacks    |Offline      |M             |10/6/2012 |175033080|11/5/2012 |5033      |152.58    |97.44    |767935.14    |490415.52 |277519.62   |\n",
      "+------------------+----------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display first 5 records with no truncation\n",
    "creditcardDF.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6ac82407-52bc-429b-ad17-471efbb54989",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Item: string (nullable = true)\n",
      " |-- SalesChannel: string (nullable = true)\n",
      " |-- OrderPriority: string (nullable = true)\n",
      " |-- OrderDate: string (nullable = true)\n",
      " |-- OrderID: long (nullable = true)\n",
      " |-- ShipDate: string (nullable = true)\n",
      " |-- UnitsSold: integer (nullable = true)\n",
      " |-- UnitPrice: float (nullable = true)\n",
      " |-- UnitCost: float (nullable = true)\n",
      " |-- TotalRevenue: double (nullable = true)\n",
      " |-- TotalCost: double (nullable = true)\n",
      " |-- TotalProfit: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining your own schema\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, FloatType, LongType, IntegerType, DateType\n",
    "\n",
    "# define the structure\n",
    "schema = StructType([\n",
    "    StructField(\"Region\", StringType()),\n",
    "    StructField(\"Country\", StringType()),\n",
    "    StructField(\"Item\", StringType()),\n",
    "    StructField(\"SalesChannel\", StringType()),\n",
    "    StructField(\"OrderPriority\", StringType()),\n",
    "    StructField(\"OrderDate\", StringType()),\n",
    "    StructField(\"OrderID\", LongType()),\n",
    "    StructField(\"ShipDate\", StringType()),\n",
    "    StructField(\"UnitsSold\", IntegerType()),\n",
    "    StructField(\"UnitPrice\", FloatType()),\n",
    "    StructField(\"UnitCost\", FloatType()),\n",
    "    StructField(\"TotalRevenue\", DoubleType()),\n",
    "    StructField(\"TotalCost\", DoubleType()),\n",
    "    StructField(\"TotalProfit\", DoubleType())\n",
    "])\n",
    "\n",
    "# read the file by using the defined schema\n",
    "creditcardDF1 = spark.read.format(\"csv\").option(\"header\", \"true\").schema(schema).load(\"SalesTraining.csv\")\n",
    "\n",
    "# display the schema\n",
    "creditcardDF1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4f349aa9-4fe9-4240-9c20-37c36522a600",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/07 12:50:48 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Region, Country, Item Type, Sales Channel, Order Priority, Order Date, Order ID, Ship Date, Units Sold, Unit Price, Unit Cost, Total Revenue, Total Cost, Total Profit\n",
      " Schema: Region, Country, Item, SalesChannel, OrderPriority, OrderDate, OrderID, ShipDate, UnitsSold, UnitPrice, UnitCost, TotalRevenue, TotalCost, TotalProfit\n",
      "Expected: Item but found: Item Type\n",
      "CSV file: file:///Users/kaustuvkunal/learning/BDA/Big%20Data%20Final%20Content/Session%205_Spark%20_%20SparkSQL/Session%205_Spark%20_%20SparkSQL/Faculty%20Notebook/SalesTraining.csv\n",
      "+------------------+-------+----------+------------+-------------+----------+---------+----------+---------+---------+--------+------------+----------+-----------+\n",
      "|Region            |Country|Item      |SalesChannel|OrderPriority|OrderDate |OrderID  |ShipDate  |UnitsSold|UnitPrice|UnitCost|TotalRevenue|TotalCost |TotalProfit|\n",
      "+------------------+-------+----------+------------+-------------+----------+---------+----------+---------+---------+--------+------------+----------+-----------+\n",
      "|Sub-Saharan Africa|Burundi|Vegetables|Online      |M            |11/17/2010|951380240|12/20/2010|3410     |154.06   |90.93   |525344.6    |310071.3  |215273.3   |\n",
      "|Europe            |Ukraine|Cosmetics |Online      |M            |11/13/2014|270001733|1/1/2015  |8368     |437.2    |263.33  |3658489.6   |2203545.44|1454944.16 |\n",
      "|Europe            |Croatia|Beverages |Online      |C            |6/16/2016 |681941401|7/28/2016 |470      |47.45    |31.79   |22301.5     |14941.3   |7360.2     |\n",
      "+------------------+-------+----------+------------+-------------+----------+---------+----------+---------+---------+--------+------------+----------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the records\n",
    "creditcardDF1.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d7aa437e-8ac2-4852-b950-ed420ffb75a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+----------+----------+----------+-------------+------------+\n",
      "|Region            |Country   |Item Type |Order Date|Units Sold|Total Revenue|DefaultValue|\n",
      "+------------------+----------+----------+----------+----------+-------------+------------+\n",
      "|Sub-Saharan Africa|Burundi   |Vegetables|11/17/2010|3410      |525344.6     |DefaultValue|\n",
      "|Europe            |Ukraine   |Cosmetics |11/13/2014|8368      |3658489.6    |DefaultValue|\n",
      "|Europe            |Croatia   |Beverages |6/16/2016 |470       |22301.5      |DefaultValue|\n",
      "|Sub-Saharan Africa|Madagascar|Fruits    |5/31/2016 |7690      |71747.7      |DefaultValue|\n",
      "+------------------+----------+----------+----------+----------+-------------+------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting only a few columns\n",
    "from pyspark.sql.functions import col, column\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# select a few columns\n",
    "creditcardDF.select(\"Region\", \"Country\", F.col(\"Item Type\"), \"Order Date\", \"Units Sold\", \"Total Revenue\", F.lit('DefaultValue')).show(4, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "79eed820-be60-4f24-b653-938565bf4fa2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "|Region            |Country   |Item Type |Sales Channel|Order Priority|Order Date|Order ID |Ship Date |Units Sold|Unit Price|Unit Cost|Total Revenue|Total Cost|Total Profit|\n",
      "+------------------+----------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "|Sub-Saharan Africa|Burundi   |Vegetables|Online       |M             |11/17/2010|951380240|12/20/2010|3410      |154.06    |90.93    |525344.6     |310071.3  |215273.3    |\n",
      "|Europe            |Ukraine   |Cosmetics |Online       |M             |11/13/2014|270001733|1/1/2015  |8368      |437.2     |263.33   |3658489.6    |2203545.44|1454944.16  |\n",
      "|Europe            |Croatia   |Beverages |Online       |C             |6/16/2016 |681941401|7/28/2016 |470       |47.45     |31.79    |22301.5      |14941.3   |7360.2      |\n",
      "|Sub-Saharan Africa|Madagascar|Fruits    |Online       |L             |5/31/2016 |566935575|6/7/2016  |7690      |9.33      |6.92     |71747.7      |53214.8   |18532.9     |\n",
      "+------------------+----------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting all the columns\n",
    "creditcardDF.select(\"*\").show(4, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "be329984-be8e-4647-92c3-b1eb7354ed05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Region',\n",
       " 'Country',\n",
       " 'Item Type',\n",
       " 'Sales Channel',\n",
       " 'Order Priority',\n",
       " 'Order Date',\n",
       " 'Order ID',\n",
       " 'Ship Date',\n",
       " 'Units Sold',\n",
       " 'Unit Price',\n",
       " 'Unit Cost',\n",
       " 'Total Revenue',\n",
       " 'Total Cost',\n",
       " 'Total Profit']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# renaming a column\n",
    "creditcardDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d3aad838-fade-439c-9c2d-72084fc6056c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# renaming the columns - \"Sales Channel\" to \"SalesChannel\" and \"Item Type\" to \"Item\"\n",
    "creditcardDF2 = creditcardDF.withColumnRenamed(\"Sales Channel\", \"SalesChannel\").withColumnRenamed('Item Type','Item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b4310439-86dc-4a38-99be-189a3e485943",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+----------+------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "|Region            |Country|Item      |SalesChannel|Order Priority|Order Date|Order ID |Ship Date |Units Sold|Unit Price|Unit Cost|Total Revenue|Total Cost|Total Profit|\n",
      "+------------------+-------+----------+------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "|Sub-Saharan Africa|Burundi|Vegetables|Online      |M             |11/17/2010|951380240|12/20/2010|3410      |154.06    |90.93    |525344.6     |310071.3  |215273.3    |\n",
      "|Europe            |Ukraine|Cosmetics |Online      |M             |11/13/2014|270001733|1/1/2015  |8368      |437.2     |263.33   |3658489.6    |2203545.44|1454944.16  |\n",
      "|Europe            |Croatia|Beverages |Online      |C             |6/16/2016 |681941401|7/28/2016 |470       |47.45     |31.79    |22301.5      |14941.3   |7360.2      |\n",
      "+------------------+-------+----------+------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display records\n",
    "creditcardDF2.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a7e10a2c-2617-4fee-890f-2991cd825cef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Item Type: string (nullable = true)\n",
      " |-- Sales Channel: string (nullable = true)\n",
      " |-- Order Priority: string (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Order ID: long (nullable = true)\n",
      " |-- Ship Date: string (nullable = true)\n",
      " |-- Units Sold: integer (nullable = true)\n",
      " |-- Unit Price: double (nullable = true)\n",
      " |-- Unit Cost: double (nullable = true)\n",
      " |-- Total Revenue: double (nullable = true)\n",
      " |-- Total Cost: double (nullable = true)\n",
      " |-- Total Profit: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change column data type\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# change the data type from integer to long\n",
    "df = creditcardDF.withColumn(\"Order ID\", col(\"Order ID\").cast(\"long\"))\n",
    "df.printSchema() # display the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d6f1a6d5-8987-4297-b17c-5f0f5f74f27a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "|Region            |Country   |Item Type |Sales Channel|Order Priority|Order Date|Order ID |Ship Date |Units Sold|Unit Price|Unit Cost|Total Revenue|Total Cost|Total Profit|\n",
      "+------------------+----------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "|Sub-Saharan Africa|Burundi   |Vegetables|Online       |M             |11/17/2010|951380240|12/20/2010|3410      |154.06    |90.93    |525344.6     |310071.3  |215273.3    |\n",
      "|Europe            |Ukraine   |Cosmetics |Online       |M             |11/13/2014|270001733|1/1/2015  |8368      |437.2     |263.33   |3658489.6    |2203545.44|1454944.16  |\n",
      "|Europe            |Croatia   |Beverages |Online       |C             |6/16/2016 |681941401|7/28/2016 |470       |47.45     |31.79    |22301.5      |14941.3   |7360.2      |\n",
      "|Sub-Saharan Africa|Madagascar|Fruits    |Online       |L             |5/31/2016 |566935575|6/7/2016  |7690      |9.33      |6.92     |71747.7      |53214.8   |18532.9     |\n",
      "+------------------+----------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "creditcardDF.show(4, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4f000a26-d7d3-4df7-8a6d-84975915dd8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+----------+--------------+\n",
      "|Region            |Country|Item Type |Register_Site |\n",
      "+------------------+-------+----------+--------------+\n",
      "|Sub-Saharan Africa|Burundi|Vegetables|www.google.com|\n",
      "|Europe            |Ukraine|Cosmetics |www.google.com|\n",
      "|Europe            |Croatia|Beverages |www.google.com|\n",
      "+------------------+-------+----------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# adding columns to a dataframe\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# add a new column \"Register_Site\" with default value \"www.google.com\"\n",
    "dataDF = creditcardDF.withColumn(\"Register_Site\", F.lit(\"www.google.com\"))\n",
    "\n",
    "# display only a few columns\n",
    "dataDF.select(\"Region\",\"Country\", \"Item Type\", \"Register_Site\").show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7c72b0b3-73c7-44b9-9af0-9198a87837c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns :  15\n",
      "['Region', 'Country', 'Item Type', 'Sales Channel', 'Order Priority', 'Order Date', 'Order ID', 'Ship Date', 'Units Sold', 'Unit Price', 'Unit Cost', 'Total Revenue', 'Total Cost', 'Total Profit', 'Register_Site']\n",
      "Number of columns :  13\n",
      "['Region', 'Sales Channel', 'Order Priority', 'Order Date', 'Order ID', 'Ship Date', 'Units Sold', 'Unit Price', 'Unit Cost', 'Total Revenue', 'Total Cost', 'Total Profit', 'Register_Site']\n"
     ]
    }
   ],
   "source": [
    "# removing columns from a DataFrame\n",
    "\n",
    "# number of columns in a dataframe - before removing columns\n",
    "print(\"Number of columns : \", len(dataDF.columns))\n",
    "\n",
    "# columns - before dropping\n",
    "print(list(dataDF.columns))\n",
    "\n",
    "# drop columns - \"Country\", \"Item Type\"\n",
    "datanewDF = dataDF.drop(\"Country\", \"Item Type\")\n",
    "\n",
    "# number of columns in a dataframe - after removing columns\n",
    "print(\"Number of columns : \", len(datanewDF.columns))\n",
    "\n",
    "# columns - after dropping\n",
    "print(list(datanewDF.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f3d09adc-5eac-471a-b653-5862a94f96f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns :  14\n",
      "Number of columns :  15\n",
      "+------------------+-------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+---------+\n",
      "|            Region|Country| Item Type|Sales Channel|Order Priority|Order Date| Order ID| Ship Date|Units Sold|Unit Price|Unit Cost|Total Revenue|Total Cost|Total Profit|TotalSale|\n",
      "+------------------+-------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+---------+\n",
      "|Sub-Saharan Africa|Burundi|Vegetables|       Online|             M|11/17/2010|951380240|12/20/2010|      3410|    154.06|    90.93|     525344.6|  310071.3|    215273.3| 525344.6|\n",
      "|            Europe|Ukraine| Cosmetics|       Online|             M|11/13/2014|270001733|  1/1/2015|      8368|     437.2|   263.33|    3658489.6|2203545.44|  1454944.16|3658489.6|\n",
      "|            Europe|Croatia| Beverages|       Online|             C| 6/16/2016|681941401| 7/28/2016|       470|     47.45|    31.79|      22301.5|   14941.3|      7360.2|  22301.5|\n",
      "+------------------+-------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# arithmetic with dataframes\n",
    "# number of columns in a dataframe - before a adding a column\n",
    "print(\"Number of columns : \", len(creditcardDF.columns))\n",
    "\n",
    "# perform arithmetic operations on a dataframe column\n",
    "creditnewDF = creditcardDF.withColumn(\"TotalSale\", col(\"Units Sold\") * col(\"Unit Price\"))\n",
    "\n",
    "# number of columns in a dataframe - after adding columns\n",
    "print(\"Number of columns : \", len(creditnewDF.columns))\n",
    "\n",
    "# display records\n",
    "creditnewDF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e9f8b667-27c2-4717-8dc7-4d3af0755ba7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------------+-------------+--------------+----------+---------+---------+----------+----------+---------+-------------+----------+------------+\n",
      "|Region|    Country|      Item Type|Sales Channel|Order Priority|Order Date| Order ID|Ship Date|Units Sold|Unit Price|Unit Cost|Total Revenue|Total Cost|Total Profit|\n",
      "+------+-----------+---------------+-------------+--------------+----------+---------+---------+----------+----------+---------+-------------+----------+------------+\n",
      "|  Asia|   Malaysia|         Snacks|      Offline|             M| 10/6/2012|175033080|11/5/2012|      5033|    152.58|    97.44|    767935.14| 490415.52|   277519.62|\n",
      "|  Asia| Uzbekistan|Office Supplies|      Offline|             L| 3/10/2012|276595246|3/15/2012|      9535|    651.21|   524.96|   6209287.35| 5005493.6|  1203793.75|\n",
      "|  Asia|      Nepal|     Vegetables|      Offline|             C|  6/2/2014|443121373|6/19/2014|      8316|    154.06|    90.93|   1281162.96| 756173.88|   524989.08|\n",
      "|  Asia|      India|         Fruits|       Online|             H| 7/29/2010|658348691|8/22/2010|      8862|      9.33|     6.92|     82682.46|  61325.04|    21357.42|\n",
      "|  Asia|South Korea|         Fruits|      Offline|             L|  3/7/2010|769205892|3/17/2010|      3972|      9.33|     6.92|     37058.76|  27486.24|     9572.52|\n",
      "+------+-----------+---------------+-------------+--------------+----------+---------+---------+----------+----------+---------+-------------+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter a dataframe\n",
    "\n",
    "creditcardDF.where(col(\"Region\") == \"Asia\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f1d3e77c-0945-4686-876f-61b20457dc69",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------+-------------+--------------+----------+---------+---------+----------+----------+---------+-------------+----------+------------+\n",
      "|Region|    Country|Item Type|Sales Channel|Order Priority|Order Date| Order ID|Ship Date|Units Sold|Unit Price|Unit Cost|Total Revenue|Total Cost|Total Profit|\n",
      "+------+-----------+---------+-------------+--------------+----------+---------+---------+----------+----------+---------+-------------+----------+------------+\n",
      "|  Asia|      India|   Fruits|       Online|             H| 7/29/2010|658348691|8/22/2010|      8862|      9.33|     6.92|     82682.46|  61325.04|    21357.42|\n",
      "|  Asia|Philippines|Baby Food|       Online|             L| 2/23/2014|160127294|3/23/2014|      4079|    255.28|   159.42|   1041287.12| 650274.18|   391012.94|\n",
      "|  Asia| Bangladesh|Baby Food|       Online|             H| 8/17/2011|254927718| 9/7/2011|      7632|    255.28|   159.42|   1948296.96|1216693.44|   731603.52|\n",
      "|  Asia|    Vietnam|Baby Food|       Online|             C| 6/20/2011|881974112|7/11/2011|      4594|    255.28|   159.42|   1172756.32| 732375.48|   440380.84|\n",
      "|  Asia|     Taiwan|Household|       Online|             C| 1/23/2017|607261836|2/22/2017|      1127|    668.27|   502.54|    753140.29| 566362.58|   186777.71|\n",
      "+------+-----------+---------+-------------+--------------+----------+---------+---------+----------+----------+---------+-------------+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter a dataframe - multiple columns\n",
    "\n",
    "creditcardDF.where((col(\"Region\") == \"Asia\") & (col(\"Sales Channel\") == \"Online\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "39f77ec8-b262-482e-91ab-1dac97e27971",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| ID|   Month|\n",
      "+---+--------+\n",
      "|  1| January|\n",
      "|  2|February|\n",
      "|  1| January|\n",
      "|  3|   March|\n",
      "|  3|   March|\n",
      "|  3|   March|\n",
      "|  4|   April|\n",
      "|  4|   April|\n",
      "|  5|     May|\n",
      "|  5|     May|\n",
      "|  4|   April|\n",
      "|  6|    June|\n",
      "|  5|   April|\n",
      "+---+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 12:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# dropping rows\n",
    "testDF = [[1, \"January\"], [2, \"February\"], [1, \"January\"], [3, \"March\"], [3, \"March\"], [3, \"March\"], [4, \"April\"], [4, \"April\"], [5, \"May\"], [5, \"May\"],\n",
    "          [4, \"April\"], [6, \"June\"], [5, \"April\"]]\n",
    "\n",
    "# import the modules\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# define the schema\n",
    "schema = StructType([StructField(\"ID\", IntegerType()),StructField(\"Month\", StringType())])\n",
    "\n",
    "# create the dataframe by applying schema\n",
    "df = spark.createDataFrame(testDF,schema=schema) \n",
    "\n",
    "# display the records\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9249a718-8310-4fd4-bdc2-480954cab632",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| ID|   Month|\n",
      "+---+--------+\n",
      "|  1| January|\n",
      "|  2|February|\n",
      "|  3|   March|\n",
      "|  4|   April|\n",
      "|  5|     May|\n",
      "|  5|   April|\n",
      "|  6|    June|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display distinct rows\n",
    "df.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f7243602-fc64-4a89-93ae-c7623d79743d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| ID|   Month|\n",
      "+---+--------+\n",
      "|  1| January|\n",
      "|  2|February|\n",
      "|  3|   March|\n",
      "|  4|   April|\n",
      "|  5|     May|\n",
      "|  6|    June|\n",
      "+---+--------+\n",
      "\n",
      "+---+--------+\n",
      "| ID|   Month|\n",
      "+---+--------+\n",
      "|  1| January|\n",
      "|  2|February|\n",
      "|  3|   March|\n",
      "|  4|   April|\n",
      "|  5|     May|\n",
      "|  6|    June|\n",
      "|  5|   April|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop duplicate records based a column value\n",
    "df.dropDuplicates(['Month']).show()\n",
    "\n",
    "# drop duplicate records based multiple column values\n",
    "df.dropDuplicates(['Month', 'ID']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e2076389-ad17-49cc-9fbd-5fcfc35c7b72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "|            Region|Country| Item Type|Sales Channel|Order Priority|Order Date| Order ID| Ship Date|Units Sold|Unit Price|Unit Cost|Total Revenue|Total Cost|Total Profit|\n",
      "+------------------+-------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "|Sub-Saharan Africa|Burundi|Vegetables|       Online|             M|11/17/2010|951380240|12/20/2010|      3410|    154.06|    90.93|     525344.6|  310071.3|    215273.3|\n",
      "|            Europe|Ukraine| Cosmetics|       Online|             M|11/13/2014|270001733|  1/1/2015|      8368|     437.2|   263.33|    3658489.6|2203545.44|  1454944.16|\n",
      "|            Europe|Croatia| Beverages|       Online|             C| 6/16/2016|681941401| 7/28/2016|       470|     47.45|    31.79|      22301.5|   14941.3|      7360.2|\n",
      "+------------------+-------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+------------------+-------+----------+\n",
      "|            Region|Country|value_desc|\n",
      "+------------------+-------+----------+\n",
      "|Sub-Saharan Africa|Burundi|   Average|\n",
      "|            Europe|Ukraine|      Good|\n",
      "|            Europe|Croatia|   Average|\n",
      "+------------------+-------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rename existing columns\n",
    "newDF = creditcardDF.withColumnRenamed(\"Unit Price\", \"UnitPrice\").withColumnRenamed(\"Total Profit\", \"Total_Profit\")\n",
    "\n",
    "creditcardDF.show(3) # display records\n",
    "\n",
    "from pyspark.sql.functions import expr # define the modules\n",
    "\n",
    "# using select expression \n",
    "newDF.select(\"Region\", \"Country\",expr(\"CASE WHEN Total_Profit > 300000 THEN  'Good' ELSE 'Average' END AS value_desc\")).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1b786e55-1dca-4008-959a-6475ad544d90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      Name|Experience|\n",
      "+----------+----------+\n",
      "|Bill Gates|        23|\n",
      "|Henry Ford|      null|\n",
      "|  Tim Cook|      null|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *   # import the libraries\n",
    "\n",
    "# define a list\n",
    "list_data = [[\"Bill Gates\",23],[\"Henry Ford\", None], [\"Tim Cook\", None]]\n",
    "\n",
    "# define the schema\n",
    "schema = StructType([StructField(\"Name\", StringType()),StructField(\"Experience\", IntegerType())])\n",
    "\n",
    "# create a dataframe \n",
    "df = spark.createDataFrame(list_data,schema=schema)\n",
    "\n",
    "df.show() # display the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "023cfbc7-fa4a-4d00-8e31-573a584527a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      Name|Experience|\n",
      "+----------+----------+\n",
      "|Bill Gates|        23|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop null value rows\n",
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e556610c-a87e-4571-96d5-b5483ee33aed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      Name|Experience|\n",
      "+----------+----------+\n",
      "|Bill Gates|        23|\n",
      "|Henry Ford|        34|\n",
      "|  Tim Cook|        34|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fill null value with a constant value\n",
    "df.fillna(34).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7d55adcf-699a-4bfe-8c68-be02bd7e98ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|         Name|Experience|\n",
      "+-------------+----------+\n",
      "|Satya Nadella|        23|\n",
      "|   Henry Ford|      null|\n",
      "|     Tim Cook|      null|\n",
      "+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# replace a single value\n",
    "df.na.replace('Bill Gates', 'Satya Nadella').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "83976ceb-04fd-4eca-b648-6d87ea1b58b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      Name|Experience|\n",
      "+----------+----------+\n",
      "|   Satya N|        23|\n",
      "|Henry Ford|        40|\n",
      "|      Time|        40|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# replace multiple values and also fill 'null' with a constant value\n",
    "df.na.replace(['Bill Gates', 'Tim Cook'], ['Satya N', 'Time'], 'Name').fillna(40).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5ced3384-2f00-4499-a43b-1648eb9e1439",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----------------+\n",
      "|Region                           |max(Total_Profit)|\n",
      "+---------------------------------+-----------------+\n",
      "|Middle East and North Africa     |1682887.73       |\n",
      "|Australia and Oceania            |1631943.31       |\n",
      "|Europe                           |1726181.36       |\n",
      "|Sub-Saharan Africa               |1571089.32       |\n",
      "|Central America and the Caribbean|1631422.21       |\n",
      "|North America                    |1541620.46       |\n",
      "|Asia                             |1725485.88       |\n",
      "+---------------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rename the existing columns - \"Item Type\" to \"ItemType\" and \"Total Profit\" to \"Total_Profit\"\n",
    "newDF = creditcardDF.withColumnRenamed(\"Item Type\", \"ItemType\").withColumnRenamed(\"Total Profit\", \"Total_Profit\")\n",
    "\n",
    "# find maximum total_profit for each region and alias the column to \"Maximum\"\n",
    "newDF.groupBy(\"Region\").max(\"Total_Profit\").alias(\"Maximum\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "08a2da86-bc9d-4a08-9d2f-8f803b122b58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+---------------+\n",
      "|Region                           |count(ItemType)|\n",
      "+---------------------------------+---------------+\n",
      "|Middle East and North Africa     |132            |\n",
      "|Australia and Oceania            |76             |\n",
      "|Europe                           |255            |\n",
      "|Sub-Saharan Africa               |247            |\n",
      "|Central America and the Caribbean|93             |\n",
      "|North America                    |16             |\n",
      "|Asia                             |130            |\n",
      "+---------------------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count of items in each region\n",
    "newDF.groupBy(\"Region\").agg({'ItemType':'count'}).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "64406c97-d325-456a-9218-79962d40181b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|   Average Profit|\n",
      "+-----------------+\n",
      "|392951.5061011591|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg # include the library\n",
    "\n",
    "# find average of column - \"Total_Profit\" \n",
    "newDF.select(avg(\"Total_Profit\").alias(\"Average Profit\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "57f8dfd7-1c4c-42fa-960e-282adb8afba2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------------+---------+------------+\n",
      "|Region|    Country|      Item Type| Order ID|Total Profit|\n",
      "+------+-----------+---------------+---------+------------+\n",
      "|  Asia| Uzbekistan|Office Supplies|276595246|  1203793.75|\n",
      "|  Asia|South Korea|         Fruits|769205892|     9572.52|\n",
      "|  Asia|   Malaysia|         Snacks|175033080|   277519.62|\n",
      "+------+-----------+---------------+---------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# include the library\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# order the records by region - ascending\n",
    "creditcardDF.orderBy('Region', ascending=True).select(\"Region\",\"Country\", \"Item Type\", \"Order ID\", \"Total Profit\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0394bab2-4a2c-45a0-a479-58efe002eabd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+---------------+---------+------------+\n",
      "|            Region|             Country|      Item Type| Order ID|Total Profit|\n",
      "+------------------+--------------------+---------------+---------+------------+\n",
      "|Sub-Saharan Africa|            Botswana|        Clothes|680517470|   668083.68|\n",
      "|Sub-Saharan Africa|Central African R...|Office Supplies|668599021|   273078.75|\n",
      "|Sub-Saharan Africa|            Tanzania|  Personal Care|400304734|   198500.26|\n",
      "+------------------+--------------------+---------------+---------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# include the library\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# order the records by region - descending\n",
    "creditcardDF.orderBy('Region', ascending=False).select(\"Region\",\"Country\", \"Item Type\", \"Order ID\", \"Total Profit\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "66a560e9-bb14-43cf-a509-5331eb9da9e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+----------+-------------+--------------+----------+---------+----------+\n",
      "|Region            |Country   |Item Type |Sales Channel|Order Priority|Order Date|Order ID |Ship Date |\n",
      "+------------------+----------+----------+-------------+--------------+----------+---------+----------+\n",
      "|Sub-Saharan Africa|Burundi   |Vegetables|Online       |M             |11/17/2010|951380240|12/20/2010|\n",
      "|Europe            |Ukraine   |Cosmetics |Online       |M             |11/13/2014|270001733|1/1/2015  |\n",
      "|Europe            |Croatia   |Beverages |Online       |C             |6/16/2016 |681941401|7/28/2016 |\n",
      "|Sub-Saharan Africa|Madagascar|Fruits    |Online       |L             |5/31/2016 |566935575|6/7/2016  |\n",
      "+------------------+----------+----------+-------------+--------------+----------+---------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cache and persist\n",
    "from pyspark import StorageLevel\n",
    "\n",
    "# cache the dataframe in in-memory\n",
    "cacheDF = creditcardDF.cache()\n",
    "\n",
    "# read the records from cache\n",
    "cacheDF.select(\"Region\", \"Country\", \"Item Type\", \"Sales Channel\", \"Order Priority\", \\\n",
    "               \"Order Date\", \"Order ID\", \"Ship Date\").show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8e044dd3-1473-4d7d-9984-6e04ab410fa0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/07 12:50:54 WARN CacheManager: Asked to cache already cached data.\n",
      "+------------------+----------+----------+-------------+--------------+----------+---------+\n",
      "|Region            |Country   |Item Type |Sales Channel|Order Priority|Order Date|Order ID |\n",
      "+------------------+----------+----------+-------------+--------------+----------+---------+\n",
      "|Sub-Saharan Africa|Burundi   |Vegetables|Online       |M             |11/17/2010|951380240|\n",
      "|Europe            |Ukraine   |Cosmetics |Online       |M             |11/13/2014|270001733|\n",
      "|Europe            |Croatia   |Beverages |Online       |C             |6/16/2016 |681941401|\n",
      "|Sub-Saharan Africa|Madagascar|Fruits    |Online       |L             |5/31/2016 |566935575|\n",
      "+------------------+----------+----------+-------------+--------------+----------+---------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cache and persist\n",
    "from pyspark import StorageLevel\n",
    "\n",
    "# persist the dataframe in both memo\n",
    "persistDF = creditcardDF.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "# read the records from saved dataframe\n",
    "persistDF.select(\"Region\", \"Country\", \"Item Type\", \"Sales Channel\", \"Order Priority\", \\\n",
    "               \"Order Date\", \"Order ID\").show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0c0fd966-fae9-4c57-bb2e-aa3da3514963",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions :  1\n",
      "Number of partitions :  2\n",
      "Number of partitions :  1\n"
     ]
    }
   ],
   "source": [
    "# coalesce vs repartition\n",
    "print(\"Number of partitions : \", creditcardDF.rdd.getNumPartitions())\n",
    "\n",
    "# increase the number of partitions\n",
    "cDF = creditcardDF.repartition(2)\n",
    "\n",
    "# number of partitions after repatitioning\n",
    "print(\"Number of partitions : \", cDF.rdd.getNumPartitions())\n",
    "\n",
    "# reduce the number of partitions\n",
    "cDF = cDF.coalesce(1)\n",
    "\n",
    "# number of partitions after coalesce\n",
    "print(\"Number of partitions : \", cDF.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "99e34e44-83db-4fe1-8f5b-4b96d242c36b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# aggregates the Item Type count by region, brings the data to a single partition\n",
    "writeDF = newDF.groupBy(\"Region\").agg({'ItemType':'count'}).coalesce(1)  \n",
    "\n",
    "# write to DBFS - mode: \"overwrite\" replaces the existing file and \"append\" adds the content\n",
    "writeDF.write.option(\"header\",\"true\").option(\"sep\",\",\").mode(\"overwrite\").csv(\"Aggregate/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f551f510-3b77-4d2f-877b-22ef8779589a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %fs ls \"Aggregate/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b47ca6e6-e7ea-45fc-ae6a-a1fd9602beb1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+---------------+\n",
      "|Region                           |count(ItemType)|\n",
      "+---------------------------------+---------------+\n",
      "|Middle East and North Africa     |132            |\n",
      "|Australia and Oceania            |76             |\n",
      "|Europe                           |255            |\n",
      "|Sub-Saharan Africa               |247            |\n",
      "|Central America and the Caribbean|93             |\n",
      "|North America                    |16             |\n",
      "|Asia                             |130            |\n",
      "+---------------------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read the csv file\n",
    "# note : the name of part file has to be manually added \n",
    "newDF = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\") \\\n",
    "   .load(\"Aggregate/part-00000-2917f169-8e91-460d-9355-4027cb1cf460-c000.csv\")\n",
    "\n",
    "# display the records\n",
    "newDF.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "da8dc63f-0f6b-4f7a-8d1f-6e9c3b000acf",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+--------------+\n",
      "|Region                           |SalesPerson   |\n",
      "+---------------------------------+--------------+\n",
      "|Middle East and North Africa     |Mohammed Saif |\n",
      "|Australia and Oceania            |George Carlin |\n",
      "|Europe                           |Stuart Broad  |\n",
      "|Sub-Saharan Africa               |Abdalla       |\n",
      "|Central America and the Caribbean|Chris Gayle   |\n",
      "|North America                    |George Bush   |\n",
      "|Asia                             |Tatyaso Martin|\n",
      "+---------------------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark SQL\n",
    "# create a DataFrame\n",
    "from pyspark.sql.types import *   # import the library\n",
    "leader_data = [[\"Middle East and North Africa\",\"Mohammed Saif\"],[\"Australia and Oceania\", \"George Carlin\"], \\\n",
    "               [\"Europe\", \"Stuart Broad\"], [\"Sub-Saharan Africa\", \"Abdalla\"], [\"Central America and the Caribbean\", \"Chris Gayle\"], \\\n",
    "               [\"North America\", \"George Bush\"], [\"Asia\", \"Tatyaso Martin\"]]\n",
    "\n",
    "# define the schema\n",
    "schema = StructType([StructField(\"Region\", StringType()), StructField(\"SalesPerson\", StringType())])\n",
    "\n",
    "# create a dataframe and display the records\n",
    "df = spark.createDataFrame(leader_data,schema=schema)\n",
    "df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3b89e0f5-e238-4595-b5c6-288d925e7822",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+--------------+\n",
      "|Region                           |SalesPerson   |\n",
      "+---------------------------------+--------------+\n",
      "|Middle East and North Africa     |Mohammed Saif |\n",
      "|Australia and Oceania            |George Carlin |\n",
      "|Europe                           |Stuart Broad  |\n",
      "|Sub-Saharan Africa               |Abdalla       |\n",
      "|Central America and the Caribbean|Chris Gayle   |\n",
      "|North America                    |George Bush   |\n",
      "|Asia                             |Tatyaso Martin|\n",
      "+---------------------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"sales_table\")  # convert dataframe to view\n",
    "spark.sql(\"select * from sales_table\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2725b9ad-3462-4b6c-902c-c243934d2f2e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|Region|SalesPerson   |\n",
      "+------+--------------+\n",
      "|Asia  |Tatyaso Martin|\n",
      "+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from sales_table where Region = 'Asia'\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a1f92b14-db99-4d83-be32-66f1c620bf6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------+\n",
      "|Region               |SalesPerson  |\n",
      "+---------------------+-------------+\n",
      "|Australia and Oceania|George Carlin|\n",
      "|North America        |George Bush  |\n",
      "+---------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from sales_table where SalesPerson like '%George%'\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "36e24746-4d5a-45d0-801f-31d5e443c083",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       7|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from sales_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2c569f97-0848-4013-a96e-2598e5ed04f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "|Region            |Country|Item Type |Sales Channel|Order Priority|Order Date|Order ID |Ship Date |Units Sold|Unit Price|Unit Cost|Total Revenue|Total Cost|Total Profit|\n",
      "+------------------+-------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "|Sub-Saharan Africa|Burundi|Vegetables|Online       |M             |11/17/2010|951380240|12/20/2010|3410      |154.06    |90.93    |525344.6     |310071.3  |215273.3    |\n",
      "+------------------+-------+----------+-------------+--------------+----------+---------+----------+----------+----------+---------+-------------+----------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "creditcardDF.createOrReplaceTempView(\"creditcard\")\n",
    "\n",
    "spark.sql(\"select * from creditcard\").show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7e463526-9da4-416b-99f7-15bfc22a4b5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----------------+\n",
      "|Region                           |max(TotalRevenue)|\n",
      "+---------------------------------+-----------------+\n",
      "|Middle East and North Africa     |6160781.13       |\n",
      "|Australia and Oceania            |6580454.69       |\n",
      "|Europe                           |6617209.54       |\n",
      "|Sub-Saharan Africa               |6263026.44       |\n",
      "|Central America and the Caribbean|6354579.43       |\n",
      "|North America                    |6216247.54       |\n",
      "|Asia                             |6557065.24       |\n",
      "+---------------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# renaming a column using DSL\n",
    "newDF = creditcardDF.withColumnRenamed(\"Total Revenue\", \"TotalRevenue\")\n",
    "\n",
    "# create a temp view\n",
    "\n",
    "newDF.createOrReplaceTempView(\"creditcard\")\n",
    "\n",
    "# apply aggregations on the table data\n",
    "spark.sql(\"select Region, max(TotalRevenue) from creditcard group by Region\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6c056825-0116-40f6-854c-60781a43a101",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----------------+\n",
      "|Region                           |max(TotalRevenue)|\n",
      "+---------------------------------+-----------------+\n",
      "|Asia                             |6557065.24       |\n",
      "|Australia and Oceania            |6580454.69       |\n",
      "|Central America and the Caribbean|6354579.43       |\n",
      "|Europe                           |6617209.54       |\n",
      "|Middle East and North Africa     |6160781.13       |\n",
      "|North America                    |6216247.54       |\n",
      "|Sub-Saharan Africa               |6263026.44       |\n",
      "+---------------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select Region, max(TotalRevenue) from creditcard group by Region order by Region\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8aa3c643-8e24-4fac-a5a0-58151a6ce249",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----------------+\n",
      "|Region                           |max(TotalRevenue)|\n",
      "+---------------------------------+-----------------+\n",
      "|Sub-Saharan Africa               |6263026.44       |\n",
      "|North America                    |6216247.54       |\n",
      "|Middle East and North Africa     |6160781.13       |\n",
      "|Europe                           |6617209.54       |\n",
      "|Central America and the Caribbean|6354579.43       |\n",
      "|Australia and Oceania            |6580454.69       |\n",
      "|Asia                             |6557065.24       |\n",
      "+---------------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select Region, max(TotalRevenue) from creditcard group by Region order by Region desc\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "52995ca8-d478-4fb8-8e8b-0375b8476f18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+--------------------+-------------+\n",
      "|Region                      |Country             |SalesPerson  |\n",
      "+----------------------------+--------------------+-------------+\n",
      "|Middle East and North Africa|United Arab Emirates|Mohammed Saif|\n",
      "|Middle East and North Africa|Azerbaijan          |Mohammed Saif|\n",
      "|Middle East and North Africa|Yemen               |Mohammed Saif|\n",
      "|Middle East and North Africa|Bahrain             |Mohammed Saif|\n",
      "|Middle East and North Africa|Jordan              |Mohammed Saif|\n",
      "+----------------------------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join (inner) creditcard and sales_table, display the results\n",
    "spark.sql(\"\"\"select a.Region, a.Country, b.SalesPerson\n",
    "       from creditcard a\n",
    "       join sales_table b\n",
    "       on trim(a.Region) = trim(b.Region)\"\"\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8bb7b7a0-536d-4a86-9145-7a32251f8fe4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------------+\n",
      "|Region|Country |SalesPerson   |\n",
      "+------+--------+--------------+\n",
      "|Asia  |Nepal   |Tatyaso Martin|\n",
      "|Asia  |Mongolia|Tatyaso Martin|\n",
      "|Asia  |Brunei  |Tatyaso Martin|\n",
      "|Asia  |Laos    |Tatyaso Martin|\n",
      "|Asia  |Mongolia|Tatyaso Martin|\n",
      "+------+--------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join (inner) creditcard and sales_table, apply a where condition, display the results\n",
    "df = spark.sql(\"\"\"select a.Region, a.Country, b.SalesPerson\n",
    "       from creditcard a\n",
    "       join sales_table b\n",
    "       on trim(a.Region) = trim(b.Region)\n",
    "       where trim(a.Region) = \"Asia\"\n",
    "       \"\"\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e872da30-7b57-4cb3-8fdc-9851b0ceb6ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# write the results in to DBFS\n",
    "df = spark.sql(\"\"\"select a.Region, a.Country, b.SalesPerson\n",
    "       from creditcard a\n",
    "       join sales_table b\n",
    "       on trim(a.Region) = trim(b.Region)\n",
    "       where trim(a.Region) = \"Asia\"\n",
    "       \"\"\")\n",
    "\n",
    "\n",
    "df.coalesce(1).write.option(\"header\",\"true\").mode(\"overwrite\").csv(\"spark/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7d73b5aa-d4ba-422c-b424-ac36ab7d5f6e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## %fs ls \"spark/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6ddc8330-b855-42c1-b2a9-30b4c265cb2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------+\n",
      "|Region|Country   |SalesPerson   |\n",
      "+------+----------+--------------+\n",
      "|Asia  |Nepal     |Tatyaso Martin|\n",
      "|Asia  |Mongolia  |Tatyaso Martin|\n",
      "|Asia  |Brunei    |Tatyaso Martin|\n",
      "|Asia  |Laos      |Tatyaso Martin|\n",
      "|Asia  |Mongolia  |Tatyaso Martin|\n",
      "|Asia  |Indonesia |Tatyaso Martin|\n",
      "|Asia  |Bhutan    |Tatyaso Martin|\n",
      "|Asia  |Tajikistan|Tatyaso Martin|\n",
      "|Asia  |India     |Tatyaso Martin|\n",
      "|Asia  |Maldives  |Tatyaso Martin|\n",
      "+------+----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read the csv file from stored location\n",
    "newDF = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\") \\\n",
    ".load(\"spark/part-00000-8c322dab-e10d-438d-abeb-9024e2cf7a7b-c000.csv\")\n",
    "\n",
    "newDF.show(10, False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "dataframeFromCSV",
   "notebookOrigID": 1387049276820103,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
