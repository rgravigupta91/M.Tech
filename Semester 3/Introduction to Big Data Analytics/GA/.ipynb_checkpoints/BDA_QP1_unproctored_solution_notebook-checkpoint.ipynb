{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "68d36cc0-c87f-450f-97c5-022ac8a81c41",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import statements\n",
    "from pyspark.context import SparkConf, SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.pop(\"PYSPARK_SUBMIT_ARGS\", None)\n",
    "os.environ.pop(\"SPARK_SUBMIT_ARGS\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m conf = SparkConf().setAppName(\u001b[33m\"\u001b[39m\u001b[33mTestApp\u001b[39m\u001b[33m\"\u001b[39m).setMaster(\u001b[33m\"\u001b[39m\u001b[33mlocal[*]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m sc = \u001b[43mSparkContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#spark = SparkSession(sc) \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python\\Python312\\Lib\\site-packages\\pyspark\\context.py:515\u001b[39m, in \u001b[36mSparkContext.getOrCreate\u001b[39m\u001b[34m(cls, conf)\u001b[39m\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext._lock:\n\u001b[32m    514\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext._active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext._active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    517\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext._active_spark_context\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python\\Python312\\Lib\\site-packages\\pyspark\\context.py:201\u001b[39m, in \u001b[36mSparkContext.__init__\u001b[39m\u001b[34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway.gateway_parameters.auth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    197\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    198\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m is not allowed as it is a security risk.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    199\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    203\u001b[39m     \u001b[38;5;28mself\u001b[39m._do_init(\n\u001b[32m    204\u001b[39m         master,\n\u001b[32m    205\u001b[39m         appName,\n\u001b[32m   (...)\u001b[39m\u001b[32m    215\u001b[39m         memory_profiler_cls,\n\u001b[32m    216\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python\\Python312\\Lib\\site-packages\\pyspark\\context.py:436\u001b[39m, in \u001b[36mSparkContext._ensure_initialized\u001b[39m\u001b[34m(cls, instance, gateway, conf)\u001b[39m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext._lock:\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext._gateway:\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m         SparkContext._gateway = gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m         SparkContext._jvm = SparkContext._gateway.jvm\n\u001b[32m    439\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python\\Python312\\Lib\\site-packages\\pyspark\\java_gateway.py:104\u001b[39m, in \u001b[36mlaunch_gateway\u001b[39m\u001b[34m(conf, popen_kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m proc.poll() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isfile(conn_info_file):\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isfile(conn_info_file):\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkRuntimeError(\n\u001b[32m    108\u001b[39m         error_class=\u001b[33m\"\u001b[39m\u001b[33mJAVA_GATEWAY_EXITED\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    109\u001b[39m         message_parameters={},\n\u001b[32m    110\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setAppName(\"TestApp\").setMaster(\"local[*]\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "#spark = SparkSession(sc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b39ac901-f136-43bd-b2da-e563007728c7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Q1.  Print Spark version  (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1b52cd57-c657-4bb3-a726-3932d8855a04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mspark\u001b[49m.version)\n",
      "\u001b[31mNameError\u001b[39m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c505e6e3-a3f0-4597-8dde-dffa5f6d12e7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Q2. Read adult_data into a Spark-dataframe , databricks_datasets path is - 'dbfs:/databricks-datasets/adult/adult.data'  (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fa6a12f7-8fdc-43c7-88cf-6a768cc098f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read  the data from  dbfs:/databricks-datasets/adult/adult.data  into Saprk dataframe  \n",
    "df=spark.read.format(\"csv\").option(\"header\", \"false\").option(\"inferschema\",\"True\").load('dbfs:/databricks-datasets/adult/adult.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f6801fca-7abd-4815-b310-b4bdad1c9375",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Q3. Rename columns of spark dataframe same as given below list  ( 1 mark)\n",
    "column_names = [\n",
    "     \"age\",\n",
    "     \"workclass\",\n",
    "     \"final_weight\",\n",
    "     \"education\",\n",
    "     \"education_num\",\n",
    "     \"marital_status\",\n",
    "     \"occupation\",\n",
    "     \"relationship\",\n",
    "     \"race\",\n",
    "     \"sex\",\n",
    "     \"capital_gain\",\n",
    "     \"capital_loss\",\n",
    "     \"hours_per_week\",\n",
    "     \"native_country\",\n",
    "     \"income_class\"\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9e29de44-d694-4f39-b085-f58f08331099",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "column_names = [\n",
    "     \"age\",\n",
    "     \"workclass\",\n",
    "     \"final_weight\",\n",
    "     \"education\",\n",
    "     \"education_num\",\n",
    "     \"marital_status\",\n",
    "     \"occupation\",\n",
    "     \"relationship\",\n",
    "     \"race\",\n",
    "     \"sex\",\n",
    "     \"capital_gain\",\n",
    "     \"capital_loss\",\n",
    "     \"hours_per_week\",\n",
    "     \"native_country\",\n",
    "     \"income_class\"\n",
    " ]\n",
    "\n",
    "for new_col, old_col in zip(column_names, df.columns):\n",
    "    df = df.withColumnRenamed(old_col, new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7b04e11e-dbbd-47c5-a2ee-3edeecdcfb49",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#### Q4. Check if spark-dataframe has any columns with missing/null values and drop such columns  (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b90a3892-e5e6-4575-87c9-3ac0026f3187",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+---+---------+------------+---------+-------------+--------------+----------+------------+----+---+------------+------------+--------------+--------------+------------+\n",
       "|age|workclass|final_weight|education|education_num|marital_status|occupation|relationship|race|sex|capital_gain|capital_loss|hours_per_week|native_country|income_class|\n",
       "+---+---------+------------+---------+-------------+--------------+----------+------------+----+---+------------+------------+--------------+--------------+------------+\n",
       "|  0|        0|           0|        0|            0|             0|         0|           0|   0|  0|           0|           0|             0|             0|           0|\n",
       "+---+---------+------------+---------+-------------+--------------+----------+------------+----+---+------------+------------+--------------+--------------+------------+\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+---+---------+------------+---------+-------------+--------------+----------+------------+----+---+------------+------------+--------------+--------------+------------+\n|age|workclass|final_weight|education|education_num|marital_status|occupation|relationship|race|sex|capital_gain|capital_loss|hours_per_week|native_country|income_class|\n+---+---------+------------+---------+-------------+--------------+----------+------------+----+---+------------+------------+--------------+--------------+------------+\n|  0|        0|           0|        0|            0|             0|         0|           0|   0|  0|           0|           0|             0|             0|           0|\n+---+---------+------------+---------+-------------+--------------+----------+------------+----+---+------------+------------+--------------+--------------+------------+\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "\n",
    "df.select([count(when(isnull(c), c)).alias(c) for c in df.columns]).show()\n",
    "\n",
    "# df = df.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5e7394e2-4a69-405a-a3a3-3de5dca620a5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Q5. Show the datatypes(schema) of each Spark-dataframe columns without using any for loop (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8e10fd26-00e6-4946-b615-e9744dd52624",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "root\n",
       " |-- age: integer (nullable = true)\n",
       " |-- workclass: string (nullable = true)\n",
       " |-- final_weight: double (nullable = true)\n",
       " |-- education: string (nullable = true)\n",
       " |-- education_num: double (nullable = true)\n",
       " |-- marital_status: string (nullable = true)\n",
       " |-- occupation: string (nullable = true)\n",
       " |-- relationship: string (nullable = true)\n",
       " |-- race: string (nullable = true)\n",
       " |-- sex: string (nullable = true)\n",
       " |-- capital_gain: double (nullable = true)\n",
       " |-- capital_loss: double (nullable = true)\n",
       " |-- hours_per_week: double (nullable = true)\n",
       " |-- native_country: string (nullable = true)\n",
       " |-- income_class: string (nullable = true)\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "root\n |-- age: integer (nullable = true)\n |-- workclass: string (nullable = true)\n |-- final_weight: double (nullable = true)\n |-- education: string (nullable = true)\n |-- education_num: double (nullable = true)\n |-- marital_status: string (nullable = true)\n |-- occupation: string (nullable = true)\n |-- relationship: string (nullable = true)\n |-- race: string (nullable = true)\n |-- sex: string (nullable = true)\n |-- capital_gain: double (nullable = true)\n |-- capital_loss: double (nullable = true)\n |-- hours_per_week: double (nullable = true)\n |-- native_country: string (nullable = true)\n |-- income_class: string (nullable = true)\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4e2283de-2513-49c3-889e-939ceba9a3e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#### Q6. Convert all string columns of Spark-dataframe into indexes using  StringIndexer transformer.( reomove original string columns from data-frame and  also name the target-indexed column as label). (3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6bea0d2b-e1c1-493b-9a56-e683d4441db0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+---+------------+-------------+------------+------------+--------------+-----------------+-----------------+----------------------+------------------+--------------------+------------+-----------+----------------------+-----+\n",
       "|age|final_weight|education_num|capital_gain|capital_loss|hours_per_week|workclass_indexed|education_indexed|marital_status_indexed|occupation_indexed|relationship_indexed|race_indexed|sex_indexed|native_country_indexed|label|\n",
       "+---+------------+-------------+------------+------------+--------------+-----------------+-----------------+----------------------+------------------+--------------------+------------+-----------+----------------------+-----+\n",
       "|39 |77516.0     |13.0         |2174.0      |0.0         |40.0          |4.0              |2.0              |1.0                   |3.0               |1.0                 |0.0         |0.0        |0.0                   |0.0  |\n",
       "|50 |83311.0     |13.0         |0.0         |0.0         |13.0          |1.0              |2.0              |0.0                   |2.0               |0.0                 |0.0         |0.0        |0.0                   |0.0  |\n",
       "|38 |215646.0    |9.0          |0.0         |0.0         |40.0          |0.0              |0.0              |2.0                   |9.0               |1.0                 |0.0         |0.0        |0.0                   |0.0  |\n",
       "|53 |234721.0    |7.0          |0.0         |0.0         |40.0          |0.0              |5.0              |0.0                   |9.0               |0.0                 |1.0         |0.0        |0.0                   |0.0  |\n",
       "|28 |338409.0    |13.0         |0.0         |0.0         |40.0          |0.0              |2.0              |0.0                   |0.0               |4.0                 |1.0         |1.0        |9.0                   |0.0  |\n",
       "+---+------------+-------------+------------+------------+--------------+-----------------+-----------------+----------------------+------------------+--------------------+------------+-----------+----------------------+-----+\n",
       "only showing top 5 rows\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+---+------------+-------------+------------+------------+--------------+-----------------+-----------------+----------------------+------------------+--------------------+------------+-----------+----------------------+-----+\n|age|final_weight|education_num|capital_gain|capital_loss|hours_per_week|workclass_indexed|education_indexed|marital_status_indexed|occupation_indexed|relationship_indexed|race_indexed|sex_indexed|native_country_indexed|label|\n+---+------------+-------------+------------+------------+--------------+-----------------+-----------------+----------------------+------------------+--------------------+------------+-----------+----------------------+-----+\n|39 |77516.0     |13.0         |2174.0      |0.0         |40.0          |4.0              |2.0              |1.0                   |3.0               |1.0                 |0.0         |0.0        |0.0                   |0.0  |\n|50 |83311.0     |13.0         |0.0         |0.0         |13.0          |1.0              |2.0              |0.0                   |2.0               |0.0                 |0.0         |0.0        |0.0                   |0.0  |\n|38 |215646.0    |9.0          |0.0         |0.0         |40.0          |0.0              |0.0              |2.0                   |9.0               |1.0                 |0.0         |0.0        |0.0                   |0.0  |\n|53 |234721.0    |7.0          |0.0         |0.0         |40.0          |0.0              |5.0              |0.0                   |9.0               |0.0                 |1.0         |0.0        |0.0                   |0.0  |\n|28 |338409.0    |13.0         |0.0         |0.0         |40.0          |0.0              |2.0              |0.0                   |0.0               |4.0                 |1.0         |1.0        |9.0                   |0.0  |\n+---+------------+-------------+------------+------------+--------------+-----------------+-----------------+----------------------+------------------+--------------------+------------+-----------+----------------------+-----+\nonly showing top 5 rows\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexers = StringIndexer(inputCols = ['workclass','education',\"marital_status\",\"occupation\",\n",
    "                                     \"relationship\",\"race\",\"sex\" , \"native_country\", 'income_class'],\n",
    "                         \n",
    "                         outputCols =['workclass_indexed', 'education_indexed', \n",
    "                                     \"marital_status_indexed\",\"occupation_indexed\",\"relationship_indexed\",\n",
    "                                     \"race_indexed\",\"sex_indexed\" ,'native_country_indexed' ,\"label\"]).fit(df)\n",
    "df = indexers.transform(df)\n",
    "\n",
    "cols = ('workclass','education',\"marital_status\",\"occupation\",\n",
    "                                     \"relationship\",\"race\",\"sex\" , \"native_country\", 'income_class')\n",
    "\n",
    "df =df.drop(*cols)\n",
    "\n",
    "df.show(5, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "557e5fde-dd9d-4d0b-9ace-eadbac4891c1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Q7. Using vectorAssembler combines all columns (except  label)  of Sparkdataframe into single column named features (3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a35dfd77-3de4-4c28-9dba-489a4f01b3a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+---+------------+-------------+------------+------------+--------------+-----------------+-----------------+----------------------+------------------+--------------------+------------+-----------+----------------------+-----+-------------------------------------------------------------------+\n",
       "|age|final_weight|education_num|capital_gain|capital_loss|hours_per_week|workclass_indexed|education_indexed|marital_status_indexed|occupation_indexed|relationship_indexed|race_indexed|sex_indexed|native_country_indexed|label|features                                                           |\n",
       "+---+------------+-------------+------------+------------+--------------+-----------------+-----------------+----------------------+------------------+--------------------+------------+-----------+----------------------+-----+-------------------------------------------------------------------+\n",
       "|39 |77516.0     |13.0         |2174.0      |0.0         |40.0          |4.0              |2.0              |1.0                   |3.0               |1.0                 |0.0         |0.0        |0.0                   |0.0  |[39.0,77516.0,13.0,2174.0,0.0,40.0,2.0,0.0,0.0,4.0,3.0,1.0,1.0,0.0]|\n",
       "|50 |83311.0     |13.0         |0.0         |0.0         |13.0          |1.0              |2.0              |0.0                   |2.0               |0.0                 |0.0         |0.0        |0.0                   |0.0  |(14,[0,1,2,5,6,9,10],[50.0,83311.0,13.0,13.0,2.0,1.0,2.0])         |\n",
       "|38 |215646.0    |9.0          |0.0         |0.0         |40.0          |0.0              |0.0              |2.0                   |9.0               |1.0                 |0.0         |0.0        |0.0                   |0.0  |(14,[0,1,2,5,10,11,12],[38.0,215646.0,9.0,40.0,9.0,2.0,1.0])       |\n",
       "|53 |234721.0    |7.0          |0.0         |0.0         |40.0          |0.0              |5.0              |0.0                   |9.0               |0.0                 |1.0         |0.0        |0.0                   |0.0  |(14,[0,1,2,5,6,7,10],[53.0,234721.0,7.0,40.0,5.0,1.0,9.0])         |\n",
       "|28 |338409.0    |13.0         |0.0         |0.0         |40.0          |0.0              |2.0              |0.0                   |0.0               |4.0                 |1.0         |1.0        |9.0                   |0.0  |[28.0,338409.0,13.0,0.0,0.0,40.0,2.0,1.0,1.0,0.0,0.0,0.0,4.0,9.0]  |\n",
       "+---+------------+-------------+------------+------------+--------------+-----------------+-----------------+----------------------+------------------+--------------------+------------+-----------+----------------------+-----+-------------------------------------------------------------------+\n",
       "only showing top 5 rows\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+---+------------+-------------+------------+------------+--------------+-----------------+-----------------+----------------------+------------------+--------------------+------------+-----------+----------------------+-----+-------------------------------------------------------------------+\n|age|final_weight|education_num|capital_gain|capital_loss|hours_per_week|workclass_indexed|education_indexed|marital_status_indexed|occupation_indexed|relationship_indexed|race_indexed|sex_indexed|native_country_indexed|label|features                                                           |\n+---+------------+-------------+------------+------------+--------------+-----------------+-----------------+----------------------+------------------+--------------------+------------+-----------+----------------------+-----+-------------------------------------------------------------------+\n|39 |77516.0     |13.0         |2174.0      |0.0         |40.0          |4.0              |2.0              |1.0                   |3.0               |1.0                 |0.0         |0.0        |0.0                   |0.0  |[39.0,77516.0,13.0,2174.0,0.0,40.0,2.0,0.0,0.0,4.0,3.0,1.0,1.0,0.0]|\n|50 |83311.0     |13.0         |0.0         |0.0         |13.0          |1.0              |2.0              |0.0                   |2.0               |0.0                 |0.0         |0.0        |0.0                   |0.0  |(14,[0,1,2,5,6,9,10],[50.0,83311.0,13.0,13.0,2.0,1.0,2.0])         |\n|38 |215646.0    |9.0          |0.0         |0.0         |40.0          |0.0              |0.0              |2.0                   |9.0               |1.0                 |0.0         |0.0        |0.0                   |0.0  |(14,[0,1,2,5,10,11,12],[38.0,215646.0,9.0,40.0,9.0,2.0,1.0])       |\n|53 |234721.0    |7.0          |0.0         |0.0         |40.0          |0.0              |5.0              |0.0                   |9.0               |0.0                 |1.0         |0.0        |0.0                   |0.0  |(14,[0,1,2,5,6,7,10],[53.0,234721.0,7.0,40.0,5.0,1.0,9.0])         |\n|28 |338409.0    |13.0         |0.0         |0.0         |40.0          |0.0              |2.0              |0.0                   |0.0               |4.0                 |1.0         |1.0        |9.0                   |0.0  |[28.0,338409.0,13.0,0.0,0.0,40.0,2.0,1.0,1.0,0.0,0.0,0.0,4.0,9.0]  |\n+---+------------+-------------+------------+------------+--------------+-----------------+-----------------+----------------------+------------------+--------------------+------------+-----------+----------------------+-----+-------------------------------------------------------------------+\nonly showing top 5 rows\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_col = ['age',\n",
    " 'final_weight',\n",
    " 'education_num',\n",
    " 'capital_gain',\n",
    " 'capital_loss',\n",
    " 'hours_per_week',\n",
    " 'education_indexed',\n",
    " 'race_indexed',\n",
    " 'sex_indexed',\n",
    " 'workclass_indexed',\n",
    " 'occupation_indexed',\n",
    " 'marital_status_indexed',\n",
    " 'relationship_indexed',\n",
    " 'native_country_indexed']\n",
    "\n",
    "assembler = VectorAssembler(inputCols= features_col, outputCol= \"features\")\n",
    "df_assembled = assembler.transform(df)\n",
    "df_assembled.show(5, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ed05fb2c-b5b8-4b5f-b799-2a1d26dd51b9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Q8.  Split the vectorised spark dataframe into training and test sets  (with one third being held for  testing) ( 3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "17611a96-a1b0-4fe8-ae33-753bdb19aef4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_test =  df_assembled.randomSplit([0.67,0.33], seed = 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "278d97b9-89dd-4bbb-aa92-6030b5f3b507",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#### Q9. Train default logistic regression  model with   'featuresCol' as  features and  features as ' label'  (3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ed9c6422-d8a9-4a79-914e-957e4addc37a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Build the LogisticRegression object 'lr' by setting the required parameters\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# fit the LogisticRegression object on the training data\n",
    "lrmodel = lr.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "04f3deac-9690-4617-bb3d-04961c7e54c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#### Q10. Find accuracy of   logistic regression model  on test set ( 3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "347b4e6d-0344-4737-bc6a-d648bbb89f1e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy =  0.8349021084337349\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Accuracy =  0.8349021084337349\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This LogisticRegressionModel can be used as a transformer to perform prediction on the testing data\n",
    "predictonDF = lrmodel.transform(df_test)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "# Calculate the accracy and print its value\n",
    "accuracy = predictonDF.filter(predictonDF.label == predictonDF.prediction).count()/float(predictonDF.count())\n",
    "print(\"Accuracy = \", accuracy)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3bc3d993-b00b-4079-b7fa-d313a7fcb8f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "GL_ASA",
   "notebookOrigID": 3712024255696062,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
