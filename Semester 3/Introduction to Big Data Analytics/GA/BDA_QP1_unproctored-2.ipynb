{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b55151aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "# import statements\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cd7a6a",
   "metadata": {},
   "source": [
    "#### Q1.  Print Spark version  (1 mark)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a91eee",
   "metadata": {},
   "source": [
    "#### Q2. Read adult_data into a Spark-dataframe , databricks_datasets path is - 'dbfs:/databricks-datasets/adult/adult.data'  (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7776a8e8",
   "metadata": {},
   "source": [
    "#### Q3. Rename columns of spark dataframe same as given below list  ( 1 mark)\n",
    "column_names = [\n",
    "     \"age\",\n",
    "     \"workclass\",\n",
    "     \"final_weight\",\n",
    "     \"education\",\n",
    "     \"education_num\",\n",
    "     \"marital_status\",\n",
    "     \"occupation\",\n",
    "     \"relationship\",\n",
    "     \"race\",\n",
    "     \"sex\",\n",
    "     \"capital_gain\",\n",
    "     \"capital_loss\",\n",
    "     \"hours_per_week\",\n",
    "     \"native_country\",\n",
    "     \"income_class\"\n",
    " ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d70a70a",
   "metadata": {},
   "source": [
    "#### Q4. Check if spark-dataframe has any columns with missing/null values and drop such columns  (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8a6077",
   "metadata": {},
   "source": [
    "#### Q5. Show the datatypes(schema) of each Spark-dataframe columns without using any for loop (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b17699c",
   "metadata": {},
   "source": [
    "#### Q6. Convert all string columns of Spark-dataframe into indexes using  StringIndexer transformer.( reomove  string columns from data-frame and name the target indexed column as label). (3 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb08cc0",
   "metadata": {},
   "source": [
    "#### Q7. Using vectorAssembler combines all columns (except  label)  of Sparkdataframe into single column named features (3 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e9abdb",
   "metadata": {},
   "source": [
    "#### Q8.  Split the vectorised spark dataframe into training and test sets  (with one third being held for  testing) ( 3 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeaf758",
   "metadata": {},
   "source": [
    "#### Q9. Train default logistic regression  model with   'featuresCol' as  features and  features as ' label'  (3 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe2f28d",
   "metadata": {},
   "source": [
    "#### Q10. Find accuracy of   logistic regression model  on test set ( 3 marks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
